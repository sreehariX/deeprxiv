'use client';

import { useState, useEffect, useRef } from 'react';
import Link from 'next/link';
import { ArrowLeft, Image as ImageIcon, ExternalLink, X, Play, FileText, BookOpen, Menu } from 'lucide-react';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import remarkMath from 'remark-math';
import rehypeKatex from 'rehype-katex';
import 'katex/dist/katex.min.css';

// Custom CSS for hiding scrollbars and responsive margins
const customStyles = `
  .scrollbar-hide {
    -ms-overflow-style: none;  /* Internet Explorer 10+ */
    scrollbar-width: none;  /* Firefox */
  }
  .scrollbar-hide::-webkit-scrollbar {
    display: none;  /* Safari and Chrome */
  }
  .main-content {
    margin-left: 0;
    margin-right: 0;
  }
  @media (min-width: 768px) {
    .main-content {
      margin-left: 352px;
      margin-right: 0;
    }
  }
  @media (min-width: 1024px) {
    .main-content {
      margin-left: 416px;
      margin-right: 512px;
    }
  }
`;

// Types for better TypeScript support
interface ImageData {
  id: string;
  page: number;
  original_position?: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
  expanded_position?: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
  path?: string;
  url?: string;
}

interface SubSection {
  id: string;
  title: string;
  content: string;
  citations?: string[];
  page_number?: number;
}

interface Section {
  id: string;
  title: string;
  content: string;
  citations?: string[];
  page_number?: number;
  subsections?: SubSection[];
}

// Paper data
const paperData = {
  id: 8,
  arxiv_id: '2505.17033',
  title: 'Boosting Binomial Exotic Option Pricing with Tensor Networks',
  authors: 'Maarten van Damme, Rishi Sreedhar, Martin Ganahl',
  abstract: 'Pricing of exotic financial derivatives, such as Asian and multi-asset American basket options, poses significant challenges for standard numerical methods such as binomial trees or Monte Carlo methods. While the former often scales exponentially with the parameters of interest, the latter often requires expensive simulations to obtain sufficient statistical convergence. This work combines the binomial pricing method for options with tensor network techniques, specifically Matrix Product States (MPS), to overcome these challenges. Our proposed methods scale linearly with the parameters of interest and significantly reduce the computational complexity of pricing exotics compared to conventional methods. For Asian options, we present two methods: a tensor train cross approximation-based method for pricing, and a variational pricing method using MPS, which provides a stringent lower bound on option prices. For multi-asset American basket options, we combine the decoupled trees technique with the tensor train cross approximation to efficiently handle baskets of up to m= 8 correlated assets. All approaches scale linearly in the number of discretization steps N for Asian options, and the number of assets m for multi-asset options. Our numerical experiments underscore the high potential of tensor network methods as highly efficient simulation and optimization tools for financial engineering.',
  processed: true
};

// Sections data
const sectionsData: Section[] = [{"id": "foundation-and-context", "title": "Foundation and Context: Understanding Exotic Option Pricing Challenges and Tensor Networks", "content": "## Foundation and Context: Understanding Exotic Option Pricing Challenges and Tensor Networks\n\nThis section lays the essential groundwork to understand the complex problem of pricing exotic financial options and introduces tensor networks as an innovative computational tool to tackle these challenges. We focus on two classes of exotic options\u2014Asian options, whose payoffs depend on the average price of the underlying asset, and multi-asset American basket options, whose payoffs depend on multiple correlated assets. The section explains why standard numerical methods such as binomial trees and Monte Carlo simulations struggle due to the curse of dimensionality, motivating the use of tensor network techniques like Matrix Product States (MPS).\n\nThe material connects foundational financial concepts, such as option types and stochastic asset models, with advanced mathematical tools like the Feynman-Kac formula and tensor decompositions. This foundation is critical for appreciating the methodology developed later in the paper, where binomial pricing is combined with tensor approximations to achieve exponentially improved computational efficiency in pricing exotics (see pages 2\u20138 for detailed derivations and Figure 1 for the binomial tree illustration).\n\n---\n\n### Core Concepts in Exotic Option Pricing\n\n**Options Overview:**  \nAn *option* is a financial contract granting the right, but not the obligation, to buy (*call*) or sell (*put*) an underlying asset at a predetermined strike price $K$ within a specified timeframe. Options are typically classified as:\n\n- **Vanilla options:** Standard payoff structures, such as European or American call and put options.\n- **Exotic options:** More complex derivatives with non-standard payoffs or features, including path-dependence or multiple underlying assets.\n\nOptions are further categorized by exercise style: *European* options can be exercised only at maturity $T$, whereas *American* options can be exercised at any time before expiry, adding complexity to valuation.\n\n**Path Dependence and Multi-Asset Payoffs:**  \nAsian options are typical path-dependent derivatives, where the payoff depends on the average price $\\langle S_T \\rangle$ of the underlying asset over the option\'s life:\n\n$$\nv_A = \\max(\\langle S_T \\rangle - K, 0).\n$$\n\nSuch path dependence increases computational difficulty, as the payoff cannot be determined solely by the terminal price $S_T$ but depends on the entire asset price trajectory $S_t$, $t \\in [0,T]$.\n\nMulti-asset American basket options depend on several assets $S_1, S_2, ..., S_m$, with payoffs often based on the minimum, maximum, or average of these asset prices:\n\n$$\n\\begin{aligned}\nv_{\\max} &= \\max\\left(K - \\max(S_1, ..., S_m), 0 \\right), \\\\\nv_{\\min} &= \\max\\left(K - \\min(S_1, ..., S_m), 0 \\right), \\\\\nv_{\\text{avg}} &= \\max\\left(K - \\frac{1}{m}\\sum_{i=1}^m S_i, 0 \\right).\n\\end{aligned}\n$$\n\nThis multi-dimensional dependency exacerbates the curse of dimensionality, as the computational cost grows exponentially with the number of assets $m$ and time steps $N$.\n\n**Risk-Neutral Pricing and the Feynman-Kac Formula:**  \nUnder the risk-neutral measure, the theoretical value $V(t,K|S_0)$ of an option with payoff $v(S_T,K)$ is given by the discounted expected payoff:\n\n$$\nV(t,K|S_0) = e^{-r(T - t)} \\mathbb{E}\\big[ v(S_T, K) \\mid S_0 \\big],\n$$\n\nwhere $r$ is the risk-free interest rate and the expectation integrates over all stochastic asset price paths $S_t$ (page 2, Eq. (1)). Asset dynamics are often modeled as geometric Brownian motion:\n\n$$\ndS_t = r S_t dt + \\sigma S_t dW_t,\n$$\n\nwhere $\\sigma$ is volatility and $dW_t$ is a Brownian increment, possibly multi-dimensional and correlated among assets with covariance matrix $\\Sigma$ (Eqs. (2)\u2013(4)).\n\nHowever, for path-dependent or multi-asset options, the Feynman-Kac formula translates into expectations over high-dimensional stochastic processes, making direct application computationally intractable.\n\n---\n\n### Challenges with Conventional Methods\n\n**Binomial Trees:**  \nThe binomial pricing model discretizes time into $N$ steps and simulates the asset price as a recombining tree with up and down moves (Figure 1, page 3). While robust for vanilla options, it scales as $O(2^N)$ for path-dependent options like Asian options, and as $O(2^{Nm})$ for multi-asset baskets, quickly becoming infeasible.\n\n**Monte Carlo Simulations:**  \nMonte Carlo methods sample many random price paths to estimate the expected payoff. Though flexible and dimension-independent in principle, they often require a very large number of samples for convergence, especially for options with complex path-dependent payoffs or high volatility, leading to substantial computational cost (pages 4\u20135, discussion around Figure 3).\n\n---\n\n### Tensor Networks: Matrix Product States (MPS)\n\n**What Are Tensor Networks?**  \nTensor networks are data structures designed to efficiently represent and manipulate very high-dimensional tensors, avoiding the exponential growth of storage by decomposing large tensors into networks of smaller, interconnected tensors.\n\n**Matrix Product State (MPS) or Tensor Train Format:**  \nAn $N$-dimensional tensor $M_{x_1 x_2 \\ldots x_N}$ of indices $x_i \\in \\{0,\\ldots, d_i\\}$ can be represented as:\n\n$$\nM_{x_1 x_2 \\ldots x_N} = \\sum_{\\alpha_1, \\ldots, \\alpha_{N-1}} A^{(1)}_{x_1, \\alpha_1} A^{(2)}_{\\alpha_1, x_2, \\alpha_2} \\cdots A^{(N)}_{\\alpha_{N-1}, x_N},\n$$\n\nwhere each $A^{(i)}$ is a smaller tensor and the $\\alpha_i$ are auxiliary indices of dimension $D_i$ called the *bond dimension* (Eq. (7), page 3). The maximum bond dimension $D = \\max_i D_i$ controls the expressivity and computational cost.\n\n**Key Advantages:**\n\n- *Linear scaling*: Memory and computational requirements scale linearly with $N$ (number of dimensions), instead of exponentially.\n- *Control over approximation*: Increasing the bond dimension $D$ improves the approximation accuracy.\n- *Efficient algorithms*: Well-established contraction and optimization methods exist for MPS, enabling high-dimensional function approximation and integration (pages 3\u20134).\n\nThis makes MPS ideal for representing multivariate functions like the joint distribution of asset price paths or payoff functions in exotic options.\n\n---\n\n### Technical Details and Methodological Innovations\n\n**Asian Option Pricing Using MPS and TTcross (pages 4\u20136):**  \nThe authors represent the price paths of the binomial model as $N$-bit binary strings $x = x_1 x_2 \\ldots x_N$, with $x_k \\in \\{0,1\\}$ representing an up or down move. The joint path probability $p(x)$ has a simple product form, but the payoff\'s path dependence leads to complexity in summation:\n\n$$\nV(0,K|S_0) = e^{-rT} \\sum_{x} p(x) v_A(x),\n$$\n\nwhere $v_A(x)$ represents the Asian option payoff (Eq. (15), page 4).\n\nUsing the *tensor-train cross approximation* (TTcross), the authors approximate the function $p(x)v_A(x)$ as an MPS, enabling efficient summation by tensor contraction (Figure 2). This method achieves significantly faster convergence than Monte Carlo for moderate $N$ (Figure 3).\n\n**Variational MPS Optimization (pages 5\u20137):**  \nA second, novel approach uses variational optimization over a binary MPS ansatz $\\psi_x$ to maximize a lower bound on the option price. The optimization problem is:\n\n$$\nK = e^{-rT} \\sum_x \\psi_x p(x) \\tilde{v}_A(x),\n$$\n\nwhere $\\tilde{v}_A(x)$ replaces the max function in the payoff with a linear function, ensuring a lower bound (Eqs. (18)\u2013(20)). The ansatz $\\psi_x$ is parametrized as an MPS with binary constraints, and the cost function $K$ is maximized by sweeping over tensors one at a time (Eq. (31) and discussion around Eqs. (35)\u2013(37)). This approach provides a rigorous lower bound and converges rapidly with bond dimension, as shown in Figure 4.\n\n**Multi-Asset American Basket Options (pages 7\u20138):**  \nTo handle multiple correlated assets, the authors apply a *decoupled trees* approach. By transforming correlated log-asset prices $X_t$ using Cholesky decomposition into uncorrelated variables $Y_t = G^{-1} X_t$ (Eq. (40)), they model each $Y_t$ with independent binomial trees (Eq. (42)). The multi-dimensional payoff function (e.g., basket max payoff) is efficiently represented and manipulated using MPS within this framework, overcoming exponential scaling in the number of assets $m$.\n\n---\n\n### Significance and Broader Research Connections\n\nThis approach offers a substantial advancement in pricing complex exotic options by breaking the *curse of dimensionality* that plagues traditional numerical methods. The use of tensor networks, especially the MPS format, enables linear scaling with respect to the number of discretization steps $N$ for Asian options and the number of assets $m$ for basket options, representing a major computational breakthrough (see Section IV and results in Figures 3\u20136).\n\nThe integration of tensor network techniques, originally developed in quantum many-body physics and chemistry for compressing high-dimensional wavefunctions, into quantitative finance is innovative. This cross-disciplinary application showcases the potential of tensor networks as a versatile tool beyond their origins, now making inroads into financial engineering, risk management, and computational finance.\n\nThis work complements and extends recent efforts applying machine learning and high-dimensional optimization methods in finance, providing both new theoretical insights and practical algorithms with provable error bounds (pages 1\u20132, references [7\u201316]).\n\n---\n\n## Summary\n\nThe section \"Foundation and Context\" thoroughly prepares the reader to understand the challenges in exotic option pricing\u2014particularly path dependence and multiple correlated assets\u2014and how tensor networks, notably MPS, provide an innovative, efficient solution. By combining risk-neutral pricing theory, stochastic asset modeling, and advanced tensor methods, the paper sets the stage for novel algorithms that dramatically reduce computational cost and improve pricing accuracy, underlying the methodological contributions developed in subsequent sections.", "page_number": 1, "citations": ["https://marketsportfolio.com/feynman-kac-equation-finance/", "https://en.wikipedia.org/wiki/Feynman%E2%80%93Kac_formula", "http://www.stat.uchicago.edu/~lalley/Courses/391/Lecture12.pdf", "https://www.daytrading.com/feynman-kac-formula-finance", "https://dornsife.usc.edu/jin-ma/wp-content/uploads/sites/250/2023/06/MaHu-SPApublished.pdf"], "subsections": []}, {"id": "introduction-to-options-and-payoffs", "title": "Introduction to Options and Exotic Payoff Structures", "content": "## Introduction\n\nThis section introduces readers to the fundamentals of financial options and the increasingly important role of exotic payoff structures in modern finance. Options are contracts that grant the right\u2014but not the obligation\u2014to buy (call) or sell (put) an underlying asset at a specified price within a set time frame. Their flexibility allows investors to manage risk, speculate on price movements, and construct sophisticated trading strategies[3][4].\n\nUnderstanding options and their payoff structures is crucial for several reasons. First, it enables accurate pricing and risk assessment, which are central to sound investment decisions and financial market stability. Second, many modern investment strategies and risk management tools rely on the ability to price complex options involving multiple assets or path-dependent payoffs. Finally, as financial markets evolve, exotic options\u2014such as Asian and basket options\u2014are becoming more prevalent, necessitating advanced modeling and computational methods[1][3].\n\nThis section fits into the broader research by laying the necessary groundwork for the rest of the paper, which focuses on using tensor network methods for pricing exotic options efficiently. By establishing a clear understanding of standard and exotic options, as well as the mathematical and computational challenges involved, readers are better equipped to appreciate the innovations and techniques introduced in later sections (see page 2)[3][4].\n\n## Core Content\n\n**Key Concepts and Definitions**\n\nFinancial options come in two basic types: call options and put options. A call option gives the holder the right to buy an underlying asset at a predetermined strike price $K$ on or before a specified expiry date. Conversely, a put option gives the right to sell the underlying asset under similar terms[3]. The payoff of a call option at maturity is typically given by:\n\n$$\nv(S) = \\max(S - K, 0)\n$$\n\nwhere $S$ is the underlying asset price at expiry and $K$ is the strike price (page 2)[3].\n\nOptions can also be categorized by their payoff structure and features:\n- **Vanilla options:** Standard options with straightforward payoffs, widely traded in global markets[3].\n- **Exotic options:** Customized options with complex payoffs, such as path-dependent features or multi-asset dependencies. Examples include Asian and basket options, which are central to the paper\u2019s focus (page 2)[3].\n\n**Mathematical Formalism of Option Pricing**\n\nOption pricing relies on modeling the stochastic process governing the underlying asset price. The conventional assumption is geometric Brownian motion, described by the stochastic differential equation:\n\n$$\ndS_t = S_t r dt + \\sigma S_t dW_t\n$$\n\nwhere $S_t$ is the asset price at time $t$, $r$ is the risk-free rate, $\\sigma$ is the volatility, and $dW_t$ is a Wiener process[3][4].\n\nThe expected payoff of an option is discounted to the present using the risk-neutral measure, and the option\u2019s value is given by the Feynman-Kac formula:\n\n$$\nV(t, K | S_0) = e^{-r(T-t)} \\mathbb{E}[v(S_T, K) | S_0]\n$$\n\nwhere $\\mathbb{E}[\\cdot]$ denotes the risk-neutral expectation over all possible price paths[1][2][3]. This formula underpins both analytical and numerical pricing methods.\n\n**Exotic Payoff Structures**\n\nExotic options introduce complexity beyond vanilla structures:\n- **Asian options:** The payoff depends on the average price of the underlying asset over a specified period, rather than the price at expiry. For an Asian call, the payoff is:\n\n  $$\n  v_A = \\max(\\langle S_T \\rangle - K, 0)\n  $$\n\n  where $\\langle S_T \\rangle$ is the average price (page 3)[3].\n- **Basket options:** The payoff is based on a function (min, max, or average) of multiple underlying assets. Typical payoffs include:\n\n  $$\n  v_{\\text{max}} = \\max(K - \\max(S_1, \\dots, S_m), 0)\n  $$\n  $$\n  v_{\\text{min}} = \\max(K - \\min(S_1, \\dots, S_m), 0)\n  $$\n  $$\n  v_{\\text{avg}} = \\max(K - \\text{avg}(S_1, \\dots, S_m), 0)\n  $$\n\n  (page 3)[3].\n\n**Why Exotic Options Are Challenging**\n\nThe computational complexity of pricing exotic options grows exponentially with the number of time steps or underlying assets\u2014a phenomenon known as the curse of dimensionality. This is illustrated in Figure 1 (page 6), which shows the binomial pricing model as a recombinant tree for a single asset. However, for Asian or basket options, the number of possible paths or asset combinations becomes untenably large for traditional methods, necessitating advanced techniques such as Monte Carlo simulation or, as proposed in the paper, tensor network approaches[3][4].\n\n## Technical Details\n\n**Implementation Specifics and Algorithms**\n\nThe paper introduces several advanced methods to price exotic options efficiently:\n\n1. **Binomial Pricing and Curse of Dimensionality**\n   - **Single-Asset Model:** The binomial tree models price evolution as a sequence of up and down moves at discrete time intervals. The probability of each move is determined by the parameters $u$, $d$, $p_u$, and $p_d$ (see Table I, page 6)[3].\n   - **Path-Dependence:** For Asian options, the binomial model must track the entire path history, making it exponentially complex.\n   - **Multi-Asset Case:** For basket options, the binomial model must represent all possible combinations of price movements for each asset, again leading to exponential complexity[3].\n\n2. **Matrix Product States (MPS) and Tensor Networks**\n   - **Tensor Representation:** Tensor networks, especially matrix product states (MPS), can efficiently represent high-dimensional data by exploiting low-rank structure. An MPS for a function of $N$ variables is written as:\n     $$\n     f(x_1, \\dots, x_N) = \\sum_{\\alpha_1, \\dots, \\alpha_{N-1}} A^{x_1}_{\\alpha_1} A^{x_2}_{\\alpha_1 \\alpha_2} \\dots A^{x_N}_{\\alpha_{N-1}}\n     $$\n     where $A^{x_i}$ are order-3 tensors and $\\alpha_i$ are auxiliary indices (page 3)[3].\n   - **Linear Scaling:** The memory and computational cost scale only linearly with the number of variables, overcoming the curse of dimensionality for many practical cases (page 3)[3].\n\n3. **Algorithmic Approaches**\n   - **TTcross Method:** Approximates the product of the path probability and payoff as an MPS, then contracts the network to compute the option price. This is represented in Figure 2 (page 7), where the tensor network encodes the function $p(x)v_A(x)$ and its contraction yields the option price[3].\n   - **Variational Method:** Uses an MPS to represent a binary tensor that approximates the optimal exercise region, maximizing the lower bound of the option price. The optimization proceeds via a sweeping algorithm, similar to DMRG, updating one tensor at a time (page 7)[3].\n\n**Parameter Choices and Design Decisions**\n\n- **Discretization:** The number of time steps $N$ and assets $m$ determine the size of the problem.\n- **Bond Dimension:** The bond dimension $D$ controls the accuracy and computational cost of the MPS approximation. Larger $D$ gives more accurate results but increases runtime (page 6)[3].\n- **Comparison with Monte Carlo:** The convergence and accuracy of the new methods are compared to standard Monte Carlo simulations, as shown in Figures 3, 4, 5, and 6 (pages 7\u20138)[3].\n\n**Pseudocode Example**\n\n\`\`\`python\n# Example: Simplified MPS-based option pricing\ndef mps_option_price(N, D, S0, K, r, sigma, T):\n    # Initialize MPS with bond dimension D\n    mps = initialize_mps(N, D)\n    # Train MPS to approximate payoff and probability product\n    train_mps(mps, N, D)\n    # Contract MPS to compute option price\n    price = contract_mps(mps)\n    return price\n\`\`\`\nThis illustrates the high-level structure, though actual implementations involve tensor library operations and specific training routines (page 6)[3].\n\n## Significance & Connections\n\n**Novelty and Importance**\n\nThe integration of tensor network (MPS) methods into financial option pricing is a significant advance. Traditional methods, such as binomial trees or Monte Carlo simulations, face severe performance limitations when pricing exotic options due to the curse of dimensionality[3][4]. Tensor networks, originally developed for quantum physics, offer a way to compress and manipulate high-dimensional data efficiently, enabling accurate pricing of path-dependent and multi-asset options at linear or sub-exponential cost (page 3)[3].\n\n**Connection to Broader Research**\n\nThe use of tensor networks in option pricing builds on decades of research in computational physics and quantum chemistry. The paper leverages this expertise to address a longstanding problem in quantitative finance, demonstrating the value of cross-disciplinary collaboration[3]. The techniques and results presented have broad implications for financial engineering, risk management, and algorithmic trading.\n\n**Contributions and Implications**\n\n- **Linear Scaling:** The proposed methods scale linearly with the number of time steps (Asian options) or assets (basket options), making large-scale pricing tractable (page 3)[3].\n- **Accuracy and Efficiency:** Numerical experiments show that the new methods can outperform Monte Carlo in terms of both speed and accuracy, especially for high-dimensional or high-volatility problems (Figures 5 and 6, pages 7\u20138)[3].\n- **Versatility:** The methods are easily extended to other complex payoffs and can be adapted to incorporate additional features, such as early exercise (American options) or different averaging schemes[3].\n\n**Real-World Impact**\n\nEfficient pricing of exotic options enables better risk management, more accurate portfolio valuation, and the development of innovative financial products. The approaches described in the paper have the potential to transform the way complex derivatives are valued and traded, contributing to more robust and efficient financial markets[3][4].\n\n## Summary Table: Key Features of Option Pricing Methods\n\n| Feature                | Binomial Tree          | Monte Carlo         | MPS/Tensor Network  |\n|------------------------|-----------------------|---------------------|---------------------|\n| Scaling with $N$       | Exponential           | Sub-exponential     | Linear              |\n| Path-Dependence        | Difficult             | Standard            | Efficient           |\n| Multi-Asset            | Difficult             | Standard            | Efficient           |\n| Accuracy               | High (small $N$)      | Varies              | High                |\n| Computational Cost     | High (large $N$)      | Moderate            | Low (large $N$)     |\n\nThis table highlights the advantages of using tensor network methods for exotic option pricing (page 3)[3].", "page_number": 2, "citations": ["https://en.wikipedia.org/wiki/Feynman%E2%80%93Kac_formula", "http://hsrm-mathematik.de/WS201516/master/option-pricing/Feynman-Kac-Formula.pdf", "http://math.uchicago.edu/~may/REU2022/REUPapers/Li,Daniel.pdf", "https://marketsportfolio.com/feynman-kac-equation-finance/", "https://www.youtube.com/watch?v=o7deOrWRC2I"], "subsections": []}, {"id": "tensor-networks-overview", "title": "Tensor Networks and Matrix Product States: A Primer", "content": "## Tensor Networks and Matrix Product States: A Primer\n\nThis section provides a comprehensive introduction to tensor networks with a focus on Matrix Product States (MPS), also known as tensor trains (TT). These techniques are fundamental for efficiently representing and manipulating high-dimensional tensors, which often arise in complex option pricing problems. Understanding MPS is essential for appreciating how tensor networks can overcome the curse of dimensionality that hampers conventional methods like binomial trees or Monte Carlo simulations in financial engineering. The insights gained here lay the groundwork for advanced applications presented later in this paper, such as pricing Asian and multi-asset basket options using tensor network methods.\n\nTensor networks, particularly MPS, are powerful because they represent high-dimensional data structures using sequences of interconnected low-dimensional tensors, significantly reducing memory and computational demands. This approach enables practical handling of problems with many variables, which would otherwise be infeasible. In the broader context, MPS is a well-explored ansatz in physics and numerical analysis for managing many-body quantum states and is now making impactful inroads into financial mathematics by providing scalable algorithms for option pricing (see pages 2\u20134, Fig. 2).\n\n---\n\n### Core Concepts of Matrix Product States\n\nConsider an $N$-dimensional tensor $M_{x_1 x_2 \\ldots x_N}$, where each index $x_k$ takes values in a discrete set $\\{0, 1, \\ldots, d_k\\}$. The tensor may represent a multivariate function such as a payoff or probability distribution depending on $N$ discrete variables. The direct storage of such a tensor requires memory scaling exponentially with $N$ (the \"curse of dimensionality\").\n\nThe MPS representation factorizes this tensor into a product of $N$ smaller tensors (or \"cores\"):\n\n$$\nM_{x_1 x_2 \\ldots x_N} = \\sum_{\\alpha_1, \\ldots, \\alpha_{N-1}} A^{[1]}_{x_1, \\alpha_1} A^{[2]}_{\\alpha_1, x_2, \\alpha_2} \\cdots A^{[N-1]}_{\\alpha_{N-2}, x_{N-1}, \\alpha_{N-1}} A^{[N]}_{\\alpha_{N-1}, x_N}.\n$$\n\nHere, each $A^{[k]}$ is an order-3 tensor except for the boundaries which are order-2, with indices:\n\n- $x_k$: the *physical* index corresponding to the original $k^\\text{th}$ dimension of $M$,\n- $\\alpha_{k-1}, \\alpha_k$: the *bond* or *ancillary* indices that connect neighboring tensors.\n\nThe maximum size of the bond indices, called the **bond dimension** $D = \\max_k D_k$, controls the expressiveness and the memory cost of the MPS. The total memory cost grows roughly linearly with $N$ as $O(N d D^2)$ instead of exponentially as $O(d^N)$, for uniform $d_k = d$[3][4][2].\n\nThis factorization can be visually understood using tensor network diagrams, where tensors are nodes and edges represent contracted indices (Fig. 2 in the paper shows such a diagram for an MPS encoding the product of the path probability and option payoff function). Contracting all bond indices yields a scalar or tensor quantity efficiently.\n\n**Why MPS Is Useful in Finance:**  \nFor complex financial derivatives like Asian or basket options, the payoff depends on an $N$-dimensional path or basket state. Using MPS, one can approximate these multivariate functions accurately with manageable computational effort, enabling linear scaling in $N$ at fixed bond dimension $D$ (pages 3\u20134).\n\n---\n\n### Mathematical Foundations and Key Equations\n\nThe MPS representation is expressed as:\n\n\\[\nM_{x_1 x_2 \\ldots x_N} = A^{[1]}_{x_1 \\alpha_1} A^{[2]}_{\\alpha_1 x_2 \\alpha_2} \\cdots A^{[N]}_{\\alpha_{N-1} x_N},\n\\]\n\nwhere summation over bond indices $\\alpha_k$ is implied.\n\n- Each tensor $A^{[k]}$ has dimensions $(D_{k-1}, d_k, D_k)$, with $D_0 = D_N = 1$.\n- The bond dimension $D_k$ controls the complexity and accuracy; larger $D_k$ allows representing more correlations between indices.\n\nThe paper exemplifies this by approximating functions like $p(x) v_A(x)$ (path probability times Asian option payoff) with an MPS (Equations 7, 16 on pages 3\u20134). The function is thus represented by a set of tensors $\\{A_i\\}$, enabling efficient evaluation and manipulation.\n\nTypical operations, such as summing over all paths for option pricing (Equation 15, page 4),\n\n\\[\nV(t=0, K|S_0) = e^{-rT} \\sum_{x} p(x) v_A(x),\n\\]\n\nare performed by contracting the MPS with trivial vectors, which is of complexity linear in $N$ and polynomial in $D$ (Fig. 2b).\n\n---\n\n### Implementation and Methodological Details\n\nOn the implementation level, the paper uses well-established algorithms such as the **TT-cross approximation** to obtain MPS representations from black-box functions. This is crucial because directly computing and storing large tensors is infeasible.\n\nThe **TT-cross method** iteratively samples entries of the target tensor, building an MPS approximation with controlled bond dimension $D$ (page 4). This approach balances accuracy and computational cost, providing excellent approximations of the payoff functions.\n\nFor optimization, the variational methods parameterize certain binary tensors as MPS and optimize the parameters using sweep algorithms similar to the Density Matrix Renormalization Group (DMRG). This involves updating one tensor at a time while keeping others fixed, a procedure efficiently implementable through tensor network contractions (Equations 31\u201337 on pages 5\u20136).\n\nPseudocode for the sweeping optimization can be stated as:\n\n\`\`\`python\ninitialize MPS tensors A_i with bond dimension D\nrepeat until convergence:\n    for site k in [1, ..., N]:\n        compute gradient of cost function w.r.t. A_k\n        update A_k via constrained optimization to maximize payoff\n        compress tensors to control bond dimension if necessary\n\`\`\`\n\nParameter choices such as bond dimension $D$ reflect a trade-off between approximation accuracy and computational cost. The paper shows numerical evidence that increasing $D$ rapidly improves accuracy (Figure 4), highlighting practical feasibility on typical parameter ranges (pages 5\u20136).\n\n---\n\n### Significance and Broader Connections\n\nThe use of MPS in option pricing is innovative because it breaks the exponential complexity barrier inherent in classical binomial methods for path-dependent and multi-asset options. Its ability to scale linearly with the number of discretization steps $N$ or assets $m$ (at fixed $D$) offers a practical approach to problems that were previously computationally prohibitive (pages 3\u20134).\n\nThis method fits within a broad research trend leveraging tensor networks outside physics, extending into machine learning and finance. The key contribution lies in adapting and optimizing tensor network algorithms for financial derivatives\u2014opening new avenues for accurate, scalable pricing of exotic options (Asian, American basket, etc.) where Monte Carlo methods struggle, especially in high volatility regimes (Figs. 3, 5, and 6 on pages 4\u20137).\n\nBy demonstrating effective approximation of payoff functions and probability distributions as MPS and showing explicit algorithms for optimization, this paper paves the way for further integration of tensor networks into financial engineering toolkits, promising significant improvements in computational efficiency and pricing accuracy.\n\n---\n\nThis primer equips readers with the foundational understanding of MPS necessary to grasp the advanced tensor network methods for option pricing introduced in subsequent sections, bridging theoretical concepts and practical computational strategies in modern quantitative finance.", "page_number": 3, "citations": ["https://tensornetwork.readthedocs.io/en/latest/basic_mps.html", "https://www.ggi.infn.it/sft/SFT_2022/Banuls-TNS-Lecture_Notes_220208.pdf", "https://pennylane.ai/qml/demos/tutorial_mps", "https://tensornetwork.org/mps/", "https://muellergroup.lassp.cornell.edu/bt2020chap1.pdf"], "subsections": []}, {"id": "methodology-and-approach", "title": "Methodology and Approach: Applying Tensor Networks to Binomial Exotic Option Pricing", "content": "Below is a comprehensive, educationally structured deep-dive into the methodology for applying tensor networks to binomial exotic option pricing, following your outlined structure and requirements.\n\n## Introduction: Scope and Importance\n\nThis section explores how tensor networks\u2014specifically Matrix Product States (MPS)\u2014can be combined with the binomial option pricing model to efficiently price exotic options, such as Asian options and American basket options. As detailed on pages 1\u20132 of the paper, traditional approaches to pricing these options suffer from exponential computational scaling as the number of time steps or underlying assets increases, a problem known as the curse of dimensionality[arXiv:2505.17033]. By leveraging tensor networks, particularly MPS, the authors introduce methods that scale linearly in the number of assets or time steps for a fixed bond dimension, making exotic option pricing both tractable and scalable for real-world applications[arXiv:2505.17033][1].\n\nThe significance of this approach lies in its potential to dramatically reduce the computational cost and memory requirements for pricing complex financial derivatives, which is essential for risk management, algorithmic trading, and financial engineering. This work stands at the intersection of computational finance, numerical optimization, and quantum-inspired algorithms, demonstrating a novel bridge between classical and quantum computing paradigms[2][arXiv:2505.17033].\n\n## Core Content: Technical Foundations and Methodology\n\n### Overview of the Classical Binomial Option Pricing Model\n\nThe binomial option pricing model (BOPM) discretizes the time evolution of an underlying asset price into a series of discrete steps, forming a tree where each node represents a possible price at a given point in time[4][5][3]. The asset price at each step can either move up or down by a specified factor, leading to a recombining tree:\n\n$$\nS_{t_{k+1}} = \n\\begin{cases}\nu S_{t_k} & \\text{with probability } p_u \\\\\nd S_{t_k} & \\text{with probability } p_d = 1 - p_u\n\\end{cases}\n$$\n\nwhere $u$ and $d$ are the up and down factors, and $p_u$, $p_d$ are the corresponding probabilities. This process is illustrated in Figure 1 of the paper for a three-period model (page 4).\n\n### Challenges in Pricing Exotic Options\n\nPricing **path-dependent** (e.g., Asian) or **multi-asset** (e.g., basket) options using the BOPM leads to exponential growth in computational complexity as the number of time steps or assets increases[arXiv:2505.17033]. For example, the number of possible paths in an $N$-step binomial model is $2^N$, and for $m$ assets, the complexity is $(2^N)^m$\u2014a clear manifestation of the curse of dimensionality.\n\n### Tensor Networks and Matrix Product States (MPS)\n\nTensor networks are data structures designed to efficiently represent and manipulate high-dimensional arrays. The **Matrix Product State** (MPS), also known as the tensor train, is a widely used form of tensor network that can approximate high-dimensional functions with linear memory scaling in the number of variables for a fixed bond dimension[arXiv:2505.17033].\n\nAn $N$-dimensional tensor $M_{x_1x_2...x_N}$ in MPS form is:\n\n$$\nM_{x_1x_2...x_N} = \\sum_{\\alpha_1,...,\\alpha_{N-1}} A^1_{x_1\\alpha_1} A^2_{x_2\\alpha_1\\alpha_2} \\cdots A^N_{x_N\\alpha_{N-1}}\n$$\n\nwhere $A^i$ are order-3 tensors, and $\\alpha$ indices are auxiliary (virtual) indices. The **bond dimension** $D$ controls the expressiveness of the approximation.\n\n### Tensor Network Approaches to Asian Option Pricing\n\n#### 1. Tensor-Train Cross (TTcross) Approximation\n\nTo price Asian options, the authors represent the product of path probabilities and payoffs as an MPS. For an $N$-period model, paths are binary strings $x = x_1x_2...x_N$, with $x_k \\in \\{0,1\\}$. The asset price at expiry, path probability, and payoff are:\n\n$$\nS_T(x) = S_0 \\prod_{k=1}^N d^{1-x_k} u^{x_k}\n$$\n\n$$\np(x) = \\prod_{k=1}^N p_u^{x_k} (1-p_u)^{1-x_k}\n$$\n\n$$\n\\langle S_T(x) \\rangle = \\frac{S_0}{N} \\sum_{i=1}^N \\prod_{k=1}^i d^{1-x_k} u^{x_k}\n$$\n\n$$\nv_A(x) = \\max\\left(\\langle S_T(x) \\rangle - K, 0\\right)\n$$\n\nThe option price is then the discounted expectation of the payoff:\n\n$$\nV(t=0, K|S_0) = e^{-rT} \\sum_{x} p(x) v_A(x)\n$$\n\nThis sum is intractable for large $N$ due to the path dependence. The TTcross method approximates $p(x)v_A(x)$ as an MPS, enabling efficient computation of the sum using tensor network contraction (Figure 2a and 2b, page 4\u20135)[arXiv:2505.17033].\n\n#### 2. Variational Optimization with Binary MPS\n\nThe second approach uses a variational optimization where a binary tensor $\\psi_{x_1...x_N}$ is optimized to maximize:\n\n$$\nK = e^{-rT} \\sum_{x} \\psi_{x_1...x_N} p(x) \\tilde{v}_A(x)\n$$\n\nwhere $\\tilde{v}_A(x) = \\langle S_T(x) \\rangle - K$. By enforcing $\\psi_{x_1...x_N} \\in \\{0,1\\}$, this approach finds a lower bound on the true option price. The binary tensor is parametrized as an MPS, allowing efficient optimization (page 6)[arXiv:2505.17033].\n\n### Multi-Asset American Basket Option Pricing\n\nFor multi-asset American basket options, the authors use a **decoupled trees** approach. The correlated asset prices are transformed into uncorrelated variables via Cholesky decomposition of the covariance matrix:\n\n$$\n\\Sigma = GG^T\n$$\n\n$$\nY_t = G^{-1} X_t\n$$\n\nEach transformed variable $Y^i_t$ follows an independent binomial tree, and the asset prices are reconstructed as $S_{t_k} = \\exp(G Y_{t_k})$. This transformation allows the use of independent binomial trees for each asset, combined with TTcross approximations to maintain linear scaling in the number of assets (page 7\u20138)[arXiv:2505.17033].\n\nThe payoff for a max-basket put option at expiry is:\n\n$$\nv(Y_N) = \\max\\left(K - \\max\\left(e^{G Y_N}\\right), 0\\right)\n$$\n\n## Technical Details: Implementation and Algorithmic Choices\n\n### Tensor-Train Cross (TTcross) Implementation\n\nThe TTcross algorithm proceeds as follows:\n\n1. **Path Encoding:** Represent all possible paths as binary strings.\n2. **Function Approximation:** Use TTcross to approximate the function $p(x)v_A(x)$ as an MPS.\n3. **Summation:** Efficiently contract the MPS to compute the sum, resulting in the option price (Figure 2, page 5).\n\nThis approach is implemented in a vectorized, parallel fashion using the TensorNetwork package, with bond dimensions ranging from $D=30$ to $D=250$ in numerical experiments (page 5)[arXiv:2505.17033].\n\n### Variational Optimization Algorithm\n\nThe variational approach uses a sweeping algorithm inspired by the Density Matrix Renormalization Group (DMRG):\n\n1. **Binary MPS Initialization:** Define a binary MPS for $\\psi_{x_1...x_N}$.\n2. **Tensor Update:** Optimize one tensor at a time, keeping others fixed.\n3. **Greedy Decomposition:** Use a greedy algorithm to keep the bond dimension manageable.\n4. **Cost Function Maximization:** Repeat steps 2\u20133 until convergence (page 6\u20137)[arXiv:2505.17033].\n\n### Multi-Asset Pricing Algorithm\n\nFor multi-asset options:\n\n1. **Cholesky Decomposition:** Compute $G$ from the covariance matrix $\\Sigma$.\n2. **Transformation:** Convert correlated asset prices to uncorrelated variables using $Y_t = G^{-1} X_t$.\n3. **Independent Trees:** Build independent binomial trees for each $Y^i_t$.\n4. **Reconstruction:** Reconstruct asset prices via $S_{t_k} = \\exp(G Y_{t_k})$.\n5. **TTcross Approximation:** Use TTcross to approximate the joint probability and payoff, and contract to compute the option price (page 7\u20138)[arXiv:2505.17033].\n\n## Significance and Broader Connections\n\nThe integration of tensor networks and binomial option pricing represents a significant advance in computational finance. The key innovations are:\n\n- **Linear Scaling:** The methods scale linearly with the number of time steps or assets for a fixed bond dimension, overcoming the exponential scaling of traditional approaches.\n- **Efficient State Preparation:** The use of MPS allows for efficient preparation of quantum-like states, a crucial step for potential quantum algorithms in finance[2][arXiv:2505.17033].\n- **Robust Lower Bounds:** The variational approach provides rigorous lower bounds on option prices, which is valuable for risk management and hedging strategies.\n- **Decoupled Trees:** The decoupled trees approach, combined with TTcross, enables efficient pricing of multi-asset options with correlated assets.\n\nThe numerical results, presented in Figures 3, 4, 5, and 6 (pages 5\u20138), demonstrate that the tensor network approaches outperform Monte Carlo methods in high-volatility or high-dimensional regimes, achieving faster convergence and lower errors[arXiv:2505.17033].\n\nThis work connects to ongoing research in quantum computing and machine learning for finance, demonstrating that tensor networks are not only a powerful classical tool but also a bridge to future quantum-enhanced algorithms. The implications are broad: scalable, efficient pricing of complex financial derivatives is now within reach, opening new possibilities for real-time risk assessment and decision-making in global markets[2][arXiv:2505.17033].", "page_number": 4, "citations": ["https://arxiv.org/abs/2505.17033", "https://www.themoonlight.io/en/review/time-series-generation-for-option-pricing-on-quantum-computers-using-tensor-network", "https://www.gibiansky.com/blog/economics/binomial-options-pricing-model/index.html", "https://www.investopedia.com/terms/b/binomialoptionpricing.asp", "https://www.acte.in/binomial-option-pricing-model-article"], "subsections": []}, {"id": "binomial-pricing-basics-and-limitations", "title": "Binomial Pricing Model: Foundations and Scaling Challenges", "content": "## Binomial Pricing Model: Foundations and Scaling Challenges\n\nThis section explores the classical binomial model for option pricing, its theoretical foundations, and the computational challenges that arise when this model is applied to exotic options such as Asian or multi-asset basket options. Understanding the binomial model is essential for appreciating both the power and the limitations of traditional numerical methods in quantitative finance, and for recognizing the need for advanced computational techniques to overcome the curse of dimensionality\u2014a fundamental obstacle in pricing complex derivatives[5][3][1].\n\n### Introduction and Context\n\nThe binomial option pricing model is a cornerstone in quantitative finance, providing a discrete-time framework for valuing options. It discretizes the continuous evolution of an underlying asset price into a series of time steps, each characterized by two possible outcomes: an up-move or a down-move. This approach allows practitioners to visualize the evolution of asset prices and to evaluate options by considering possible future scenarios at each step[1][5]. The model is widely used for vanilla options but faces significant limitations when pricing exotic options, where the number of possible states grows exponentially with the number of time steps or underlying assets[3][5].\n\nThis section is central to the research paper because it sets the stage for understanding why classic methods fail for exotic options, motivating the introduction of tensor network techniques. These techniques\u2014such as Matrix Product States (MPS)\u2014are designed to break the curse of dimensionality, making it computationally feasible to price high-dimensional or path-dependent options[3][5].\n\n### Learning Objectives\n\nBy the end of this section, readers will be able to:\n\n- **Explain the core principles of the binomial option pricing model.**\n- **Describe how the model is implemented for both single-asset and multi-asset options.**\n- **Identify the computational challenges that arise with exotic options.**\n- **Understand how tensor networks, specifically MPS, can overcome these challenges.**\n- **Connect these concepts to broader research in financial engineering and computational physics.**\n\n---\n\n## Core Methodology\n\n### Binomial Model Basics\n\nThe binomial model assumes that the price of an underlying asset can move to one of two possible values at each discrete time step: up ($u$) or down ($d$), with associated probabilities ($p_u$, $p_d$)[1][5]. The lifetime $T$ of the option is divided into $N + 1$ equally spaced points, with each step $\\Delta t = T/N$. The asset price at each step $k$ is determined by:\n\n$$\nS_{t_{k+1}} = \n\\begin{cases}\nu S_{t_k} & \\text{with probability } p_u \\\\\nd S_{t_k} & \\text{with probability } p_d = 1 - p_u\n\\end{cases}\n$$\n\nThis process is visualized as a binary tree (see Figure 1 in the paper, page 3), where each node represents a possible value of the asset at a given time step[3].\n\n### Parameter Choices: CRR and RB Schemes\n\nTwo common parameterization schemes are:\n\n- **Cox-Ross-Rubinstein (CRR):**\n  - $u = e^{\\sigma \\sqrt{\\Delta t}}$\n  - $d = \\frac{1}{u}$\n  - $p_u = \\frac{e^{r\\Delta t} - d}{u - d}$\n- **Rendleman-Bartter (RB):**\n  - $u = e^{(r - \\frac{1}{2}\\sigma^2)\\Delta t + \\sigma \\sqrt{\\Delta t}}$\n  - $d = e^{(r - \\frac{1}{2}\\sigma^2)\\Delta t - \\sigma \\sqrt{\\Delta t}}$\n  - $p_u = p_d = \\frac{1}{2}$\n\nThese choices ensure that the discrete model converges to the continuous Black-Scholes model as $\\Delta t \\rightarrow 0$[3] (see Table I in the paper, page 3).\n\n### Pricing Exotic Options: Challenges and State Space Explosion\n\nFor vanilla options, the binomial model is straightforward and computationally efficient. However, for exotic options such as Asian options (which depend on the average price over time) or multi-asset basket options, the number of possible states grows exponentially with the number of time steps ($N$) or assets ($m$). This is known as the curse of dimensionality[3][5].\n\nFor example, with $N$ time steps for an Asian option, the number of possible paths is $2^N$, making brute-force calculation intractable for large $N$. Similarly, for a basket of $m$ assets, the state space grows as $(2^N)^m$, rendering standard binomial methods impractical[3][5].\n\n### Mathematical Formulations\n\nThe value of an Asian call option at time $t=0$ is given by the expectation under the risk-neutral measure:\n\n$$\nV(t=0, K|S_0) = e^{-rT} \\mathbb{E}\\left[\\max\\left(\\frac{1}{N}\\sum_{k=1}^N S_{t_k} - K, 0\\right)\\right]\n$$\n\nwhere $S_{t_k}$ is the asset price at step $k$, and $K$ is the strike price (see Equation 11 in the paper, page 3). This expectation requires summing over all possible paths, which is computationally infeasible for large $N$ due to the exponential growth of the state space[3][5].\n\n---\n\n## Technical Details\n\n### Implementation and Algorithm\n\nThe binomial pricing algorithm proceeds as follows:\n\n1. **Construct the binomial tree** for the underlying asset, up to the final time step $N$.\n2. **Calculate option payoffs** at each terminal node.\n3. **Work backwards through the tree**, computing the option value at each node by discounting the expected value from the next time step.\n4. **For exotic options**, track additional state variables (e.g., running average for Asian options), increasing the state space.\n\n**Pseudocode for Binomial Pricing (Single Asset):**\n\n\`\`\`python\nfor k in N-1, ..., 0:\n    for node in nodes_at_step(k):\n        value_at_node = discount * (p_u * value_up + p_d * value_down)\n\`\`\`\n\nFor exotic options, the state space grows, and the algorithm becomes:\n\n\`\`\`python\nfor k in N-1, ..., 0:\n    for state in all_possible_states_at_step(k):\n        value = discount * (p_u * value_up(state) + p_d * value_down(state))\n\`\`\`\n\nThis approach is only feasible for small $N$ or $m$ due to exponential scaling (see page 3, Section IV)[3][5].\n\n### Parameter Choices and Design Decisions\n\nThe choice between CRR and RB schemes is motivated by the need for convergence to the Black-Scholes model and computational stability. The CRR scheme is more common for vanilla options, while the RB scheme is sometimes preferred for multi-asset options due to its symmetry and ease of implementation[3] (see Table I, page 3).\n\n### Tensor Networks and MPS: Breaking the Curse of Dimensionality\n\nTo address the state space explosion, the paper introduces tensor network techniques, specifically Matrix Product States (MPS), which can efficiently represent high-dimensional state spaces with manageable memory requirements[3][5]. The MPS formalism allows for linear scaling with $N$ or $m$ for a fixed bond dimension $D$:\n\n$$\nM_{x_1 x_2 \\dots x_N} = \\sum_{\\alpha_1, \\dots, \\alpha_{N-1}} A^{x_1}_{\\alpha_1} A^{x_2}_{\\alpha_1 \\alpha_2} \\dots A^{x_N}_{\\alpha_{N-1}}\n$$\n\nwhere $A^{x_k}$ are order-3 tensors, and $D$ is the bond dimension (see Equation 7, page 3)[3].\n\n---\n\n## Significance and Connections\n\n### Why This Approach is Important\n\nThe binomial model is foundational in finance, but its limitations for exotic options have long been recognized. The introduction of tensor network techniques, as detailed in this paper, represents a significant advance in computational finance. By leveraging MPS, the authors achieve linear scaling in the number of time steps or assets, making it feasible to price complex options that were previously intractable[3][5].\n\n### Connection to Broader Research\n\nTensor networks, originally developed for quantum many-body physics, are now being applied to high-dimensional problems in finance, machine learning, and data science. This cross-disciplinary approach highlights the potential for collaboration between physics and finance to solve real-world problems that require efficient handling of large state spaces[3][5].\n\n### Key Innovations and Contributions\n\n- **Linear scaling with time steps or assets** for exotic option pricing.\n- **Efficient approximation of high-dimensional expectations** using MPS.\n- **Novel variational and TTCross-based methods** for pricing Asian options (see Figures 2\u20136, pages 3\u20136).\n- **Decoupled trees and Cholesky decomposition** for multi-asset basket options (see Section IV.B, pages 7\u20138)[3][5].\n\n### Implications for the Field\n\nThe ability to price exotic options efficiently opens new possibilities for risk management, portfolio optimization, and the design of complex financial products. The techniques introduced in this paper are likely to inspire further research at the intersection of computational physics and quantitative finance[3][5].\n\n---\n\n## Summary Table: Binomial Model vs. Tensor Network Approach\n\n| Feature                | Binomial Model                | Tensor Network Approach         |\n|------------------------|-------------------------------|--------------------------------|\n| Scalability            | Exponential (state space)     | Linear (fixed bond dimension)  |\n| Applicability          | Vanilla options, small N/m    | Exotic, path-dependent, large N/m |\n| Computational Cost     | High for exotic options       | Manageable for large N/m       |\n| Mathematical Basis     | Discrete-time, discrete-value | High-dimensional arrays, MPS   |\n| Innovation             | Classical, widely used        | Novel, inspired by physics     |\n\n---\n\n## Closing Remarks\n\nThis section has provided a comprehensive overview of the binomial option pricing model, its implementation, and its limitations for exotic options. The integration of tensor network techniques, as detailed in the paper, addresses the curse of dimensionality and represents a significant step forward in computational finance. For further details, see the detailed algorithms, parameter choices, and numerical results in Sections IV and V of the paper (pages 3\u20138)[3][5].", "page_number": 4, "citations": ["https://www.investopedia.com/terms/b/binomialoptionpricing.asp", "https://en.wikipedia.org/wiki/Binomial_options_pricing_model", "https://www.kent.ac.uk/learning/documents/slas-documents/Binomial_models.pdf", "https://gregorygundersen.com/blog/2023/06/03/binomial-options-pricing-model/", "https://www.thefinanalytics.com/post/binomial-model-a-discrete-path-to-pricing-options"], "subsections": []}, {"id": "asian-option-pricing-with-mps", "title": "Asian Option Pricing Using Tensor-Train Cross Approximation and Variational MPS", "content": "Here is a comprehensive educational breakdown for the section:  \n**Asian Option Pricing Using Tensor-Train Cross Approximation and Variational MPS**\n\n---\n\n## Introduction\n\nThis section covers two novel approaches for pricing Asian options within the binomial framework, utilizing tensor network techniques\u2014specifically the Tensor-Train Cross (TTcross) approximation and a variational approach with Binary Matrix Product States (MPS). Asian options, where the payoff depends on the average price of the underlying asset over time, are notorious for their computational complexity due to path dependence, making them difficult to price efficiently with traditional methods like Monte Carlo or standard binomial models, which suffer from exponential scaling in the number of time steps[1][2].\n\nUnderstanding these approaches is crucial because they demonstrate how tensor networks can be adapted to financial engineering, offering significant speedups and new tools for pricing complex derivatives. These methods fit into the broader research landscape by providing scalable, efficient alternatives to classical simulation techniques, with practical implications for risk management and trading in financial markets[1][2].\n\n---\n\n## Core Content\n\n### Tensor Networks and Matrix Product States (MPS)\n\nA **tensor network** is a data structure for efficiently representing and manipulating high-dimensional arrays. The **Matrix Product State (MPS)**, also known as the tensor train, is a type of tensor network that factorizes an $N$-dimensional array into a chain of smaller tensors:\n\n$$\nM_{x_1x_2\\ldots x_N} = \\sum_{\\alpha_1,\\ldots,\\alpha_{N-1}} A^{x_1}_{\\alpha_1} A^{x_2}_{\\alpha_1\\alpha_2} \\cdots A^{x_N}_{\\alpha_{N-1}}\n$$\n\nwhere $A^{x_k}_{\\alpha_{k-1}\\alpha_k}$ are tensors with indices for the $k$-th variable and auxiliary indices $\\alpha_k$. The key advantage is that the memory required scales linearly with $N$ instead of exponentially, thus mitigating the \"curse of dimensionality\" present in traditional approaches for exotic option pricing (see page 3 of the paper for details)[1][2].\n\n### Asian Option Pricing with TTcross\n\nFor Asian options, the price is determined by the average of the underlying asset\'s price over time:\n\n$$\n\\text{Asian Call Payoff: } v_A(x) = \\max\\left(\\frac{1}{N}\\sum_{i=1}^N S_{t_i} - K, 0\\right)\n$$\n\nwhere $S_{t_i}$ is the asset price at time $t_i$ and $K$ is the strike price (page 4-5). The option value is given by the expectation of the payoff under the risk-neutral measure:\n\n$$\nV(t=0,K|S_0) = e^{-rT} \\sum_x p(x) v_A(x)\n$$\n\nwhere $p(x)$ is the probability of a path $x$ in the binomial tree (page 5). Direct computation of this sum is intractable due to exponential growth in the number of possible paths.\n\nThe TTcross method approximates the product $p(x)v_A(x)$ as an MPS, enabling efficient summation via tensor contractions (page 5, Figure 2). This method is shown to be much faster than Monte Carlo, with convergence speedups of 50\u2013100x in walltime for moderate time steps (page 5, Figure 3)[1][2].\n\n### Variational Approach with Binary MPS\n\nThe second method introduces a **variational approach** using a binary MPS tensor $\\psi_{x_1\\ldots x_N} \\in \\{0,1\\}$ to maximize a cost function that provides a lower bound on the option price (page 6):\n\n$$\nK = e^{-rT} \\sum_x \\psi_{x_1\\ldots x_N} p(x) \\tilde{v}_A(x)\n$$\nwhere $\\tilde{v}_A(x) \\leq v_A(x)$ is a surrogate payoff, and maximization of $K$ with respect to $\\psi$ yields the option price.\n\nBecause a general binary MPS is hard to parametrize, the authors specify a special form that allows efficient optimization using a sweeping algorithm inspired by Density Matrix Renormalization Group (DMRG) techniques (page 6, Appendix A). This algorithm updates one tensor at a time, controlling the bond dimension to balance accuracy and computational cost.\n\n---\n\n## Technical Details\n\n### Algorithm Overview\n\n**TTcross Method for Asian Option Pricing**\n\n1. **Represent the product $p(x)v_A(x)$ as an MPS**:\n   - Use the TTcross algorithm to construct the MPS approximation.\n2. **Contract the MPS**:\n   - Sum over all possible paths using efficient tensor network contraction techniques.\n   - The result is the option price: $V = \\sum_x p(x)v_A(x)$ (see Figure 2, page 5).\n\n**Pseudocode for TTcross MPS Construction**\n\n\`\`\`python\n# Input: Number of time steps N, payoff function v_A, path probabilities p\n# Output: MPS tensors A_1, ..., A_N\n\ndef TTcross_Asian(N, v_A, p):\n    # Initialize MPS tensors\n    MPS = []\n    for i in range(N):\n        # Use TTcross to build the i-th tensor A_i\n        A_i = TTcross_step(p, v_A, i)\n        MPS.append(A_i)\n    return MPS\n\n# Perform tensor contraction to get the option price\nprice = contract(MPS)\n\`\`\`\n\n**Variational Method with Binary MPS**\n\n1. **Initialize a binary MPS tensor** $\\psi$ with random or structured values.\n2. **Optimize** by sweeping through the MPS chain, updating each tensor in turn to maximize the cost function $K$ (page 6-7, Appendix B).\n3. **Constrain tensor updates** to maintain binary values and control the bond dimension, approximating the true price from below.\n\n**Pseudocode for Variational MPS Optimization**\n\n\`\`\`python\n# Input: N, p, v_A_tilde, initial MPS psi\n# Output: Optimized MPS and lower bound on price\n\ndef variational_Asian(N, p, v_A_tilde, psi):\n    for c in 1..N:\n        # Update tensor at position c\n        V_c = update_step(psi, p, v_A_tilde, c)\n        # Enforce binary constraints and bond dimension\n        psi[c] = enforce_binary_constraints(V_c)\n    price = evaluate_cost(psi, p, v_A_tilde)\n    return psi, price\n\`\`\`\n\n### Parameter Choices and Design Decisions\n\n- **Bond dimension**: Controls the accuracy and computational cost. Higher bond dimensions yield better approximations but require more memory and time (Figures 4\u20136, pages 6\u20137).\n- **Initialization**: The initial choice of MPS affects convergence, but the influence diminishes with increasing bond dimension.\n- **Sweeping algorithm**: Inspired by DMRG, it optimizes each tensor in sequence, ensuring efficient exploration of the optimization landscape (page 6).\n- **Binary constraints**: Enforced by decomposing the updated tensor into a binary part and a residual, with a greedy algorithm to maintain tractability (Appendix B, page 6).\n\n---\n\n## Significance & Connections\n\nThese tensor network approaches represent a significant advance for exotic option pricing. The **TTcross method** leverages low-rank tensor decompositions to approximate high-dimensional sums efficiently, while the **variational MPS approach** provides rigorous lower bounds and rapid convergence, especially under high volatility (Figures 5\u20136, pages 6\u20137). These methods address the curse of dimensionality that plagues traditional numerical techniques for path-dependent and multi-asset options, opening new avenues for scalable and accurate pricing.\n\nThe use of MPS and tensor networks in finance draws on their success in quantum physics and machine learning, highlighting the interdisciplinary nature of modern computational finance. The paper\u2019s results show that tensor-network-based methods can outperform Monte Carlo, particularly in high-dimensional or volatile scenarios, and are readily adapted to related problems such as multi-asset American basket option pricing (pages 7\u20138)[1][2].\n\n---\n\n## References to Paper Features\n\n- **Figures 3, 4, 5, and 6** on pages 5\u20137 illustrate the convergence behavior, robustness, and performance comparison with Monte Carlo for different numbers of time steps and volatilities.\n- **Sections IV.A.1 and IV.A.2** on pages 5\u20137 detail the algorithms and results for both methods.\n- **Table I** on page 4 summarizes binomial pricing parameters for reference.\n- **Figures 2a and 2b** visualize the tensor network contractions for MPS-based pricing.\n\n---\n\n## Summary Table: Key Features\n\n| Method                   | Key Innovation                | Computational Advantage         | Application Context          |\n|--------------------------|-------------------------------|-------------------------------|------------------------------|\n| TTcross MPS              | Low-rank tensor approximation | 50\u2013100x faster than Monte Carlo| Asian options, path-dependent|\n| Variational Binary MPS   | Binary optimization, DMRG-like| Rapid, rigorous lower bounds   | High volatility, exact lower bound|\n\n---\n\n## Educational Takeaways\n\n- **Tensor networks** (MPS) allow efficient representation and manipulation of high-dimensional data, making them ideal for exotic option pricing.\n- **TTcross** and **variational MPS** methods significantly outperform standard Monte Carlo for moderate to high numbers of time steps, especially under high volatility.\n- **Sweeping algorithms** and **binary constraints** ensure robust optimization and tractability.\n- **These methods** are directly applicable to other complex financial instruments, expanding the toolkit for quantitative finance[1][2].", "page_number": 4, "citations": ["https://arxiv.org/abs/2505.17033", "https://inspirehep.net/literature/2924436", "https://proceedings.neurips.cc/paper_files/paper/2022/file/5bd9fbb3a5a985f80c16ddd0ec1dfc43-Paper-Conference.pdf", "https://par.nsf.gov/servlets/purl/10352916", "https://infoscience.epfl.ch/bitstreams/e59ce42b-b078-46f1-a45c-6c3e7df10495/download"], "subsections": []}, {"id": "american-basket-option-pricing-with-tensor-networks", "title": "American Basket Option Pricing via Decoupled Trees and TTcross Approximation", "content": "## American Basket Option Pricing via Decoupled Trees and TTcross Approximation\n\n### Learning Objectives and Context\n\nThis section extends tensor network methods\u2014specifically, the use of matrix product states (MPS) and the tensor train cross (TTcross) approximation\u2014to the pricing of American-style basket options involving multiple correlated assets. After reading this section, you will understand:\n\n- **How to decouple correlated asset dynamics** into uncorrelated variables using the Cholesky decomposition of the covariance matrix.\n- **How to represent complex, high-dimensional payoff functions efficiently** using tensor networks, avoiding the exponential scaling that plagues traditional binomial tree approaches.\n- **How to handle early exercise features** in American options through backward induction, and how to maintain computational efficiency even as these features break the tensor structure.\n- **The practical advantages and computational efficiency** of this combined approach, as demonstrated in numerical experiments up to eight assets.\n\nThis topic is crucial for advancing computational finance because it addresses the \u201ccurse of dimensionality\u201d\u2014the main bottleneck in pricing multi-asset options\u2014by leveraging tensor network techniques originally developed in quantum physics and machine learning. It fits within the broader research direction of using innovative data structures and algorithms to solve high-dimensional problems in finance.\n\n### Core Concepts and Methodological Choices\n\n#### Curse of Dimensionality in Basket Option Pricing\n\nPricing a basket option with $m$ assets using standard binomial trees requires tracking all possible combinations of asset prices at each time step, leading to exponential growth in complexity, i.e., $O(2^m)$ for a binary choice per asset. This makes the method impractical for baskets with more than a handful of assets.\n\n#### Decoupling Correlated Assets via Cholesky Decomposition\n\nThe first major innovation is to transform the correlated asset log-price dynamics into uncorrelated variables. If each asset $S^i_t$ follows geometric Brownian motion:\n$$\ndS^i_t = S^i_t (r\\,dt + \\sigma_i\\,dW^i_t),\n$$\nwhere $W^i_t$ are correlated Brownian motions, then the log-price $X^i_t = \\ln S^i_t$ evolves as:\n$$\ndX^i_t = \\left(r - \\frac{1}{2}\\sigma_i^2\\right)dt + \\sigma_i\\,dW^i_t.\n$$\nThe Cholesky decomposition of the covariance matrix $\\Sigma = GG^T$ allows us to define uncorrelated variables:\n$$\nY_t = G^{-1}X_t,\n$$\nwhich evolve as:\n$$\ndY_t = \\alpha\\,dt + d\\overline{W}_t,\n$$\nwhere $\\alpha = G^{-1}(r\\,\\mathbf{1} - \\frac{1}{2}\\sigma^2)$, and $\\overline{W}_t$ are independent Brownian motions. In the binomial approximation, each uncorrelated variable $Y^i_t$ can be modeled by an independent binomial tree.\n\n#### Tensor Network Representation of Payoffs\n\nThe payoff function at expiration for a (max) basket put option is:\n$$\nv(Y_{N}) = \\max\\left(K - \\max\\left(e^{G Y_{N}}\\right), 0\\right),\n$$\nwhere $Y_{N}$ is a vector of the transformed, discretized log-prices at maturity. Representing this function explicitly is intractable for large $m$ due to the exponential number of combinations.\n\nTo overcome this, the approach uses a **tensor train (or matrix product state, MPS)** representation of the payoff. MPS/TTcross decomposes the multi-dimensional tensor into a product of lower-dimensional tensors:\n$$\nT_{x_1, \\ldots, x_m} \\approx A_{x_1} A_{x_2} \\cdots A_{x_m},\n$$\nwhere $A_{x_i}$ are matrices for each state $x_i$ of the $i$-th asset. This reduces memory and computation from exponential to linear in $m$. The TTcross algorithm constructs this MPS representation efficiently from samples, avoiding the need for an explicit full tensor.\n\n#### Early Exercise and Backward Induction\n\nAmerican options allow early exercise at any time before maturity. In the binomial framework, this is handled by backward induction: at each node, the option value is the maximum of the payoff if exercised immediately and the discounted expected value if held until the next time step:\n$$\nV_t = \\max\\left(\\text{payoff}_t, e^{-r\\Delta t} \\mathbb{E}[V_{t+1}]\\right).\n$$\nThe max operation breaks the MPS structure, so after each backward step, the result is re-projected into MPS form using TTcross to maintain computational efficiency.\n\n### Technical Details and Algorithms\n\n#### Step-by-Step Procedure\n\n**1. Transform Correlated Assets:**\n- **Input:** $m$ asset log-prices $X_t$ with covariance $\\Sigma$.\n- **Cholesky Decomposition:** Compute $G$ such that $\\Sigma = GG^T$.\n- **Uncorrelated Variables:** Set $Y_t = G^{-1}X_t$.\n- **Discretize:** Model each $Y^i_t$ with an independent binomial tree, using e.g., the Rendleman-Bartter scheme:\n  $$\n  u_i = \\alpha_i\\Delta t + \\sqrt{\\Delta t},\\quad d_i = \\alpha_i\\Delta t - \\sqrt{\\Delta t},\n  $$\n  with probabilities $(p^u_i, p^d_i) = (\\frac{1}{2}, \\frac{1}{2})$ for all $i$.\n\n**2. Construct MPS Representation of Payoff:**\n- **Sample Paths:** Generate sample paths for $Y_{N}$.\n- **Apply Payoff:** Compute $v(Y_{N})$ for each sample.\n- **TTcross Approximation:** Approximate $v(Y_{N})$ as an MPS using TTcross.\n\n**3. Backward Induction with Early Exercise:**\n- **Initialize:** At maturity, set $V(Y_N) = v(Y_N)$.\n- **Backward Step:** For each time step $t = N-1$ to $0$:\n  - **Conditional Expectation:** Compute $V(Y_t) = e^{-r\\Delta t} \\mathbb{E}[V(Y_{t+1}) \\mid Y_t]$.\n  - **Early Exercise:** Set $V(Y_t) = \\max(\\text{payoff}_t, e^{-r\\Delta t} \\mathbb{E}[V(Y_{t+1}) \\mid Y_t])$.\n  - **MPS Projection:** After each max operation, use TTcross to project $V(Y_t)$ back into MPS form, preserving computational efficiency.\n\n**Pseudocode Illustration**\n\n\`\`\`python\n# Step 1: Decouple correlated assets via Cholesky\nG = cholesky(Sigma)\nY = inv(G) @ X\n\n# Step 2: Build MPS approximation of payoff at maturity\nV_maturity = MPS.from_TTcross(sampling_function=lambda Y: max(K - max(e^{G @ Y}), 0))\n\n# Step 3: Backward induction with early exercise\nV = V_maturity\nfor t in reversed(range(N)):\n    V = max(payoff[t], discount_factor * conditional_expectation(V))\n    V = TTcross_to_MPS(V)\n\`\`\`\n\n#### Parameter Choices and Design Decisions\n\n- **Bond Dimension ($D$):** Controls the accuracy and memory usage of the MPS. Larger $D$ gives better accuracy but increases computational cost.\n- **TTcross Sampling:** The number of samples and the sampling method affect the accuracy of the MPS approximation. In practice, adaptive sampling is used for efficiency.\n- **Early Exercise Handling:** The max operation destroys the MPS structure, requiring re-approximation at each step, but TTcross allows this to be done efficiently.\n\n### Significance, Innovations, and Connections\n\n#### Why This Approach Is Important\n\n- **Overcomes Curse of Dimensionality:** By using MPS and TTcross, the method scales linearly in the number of assets $m$, not exponentially, making it feasible to price large baskets.\n- **Handles Early Exercise Efficiently:** Most tensor network approaches struggle with non-linear operations like max. Here, TTcross projection at each step maintains efficiency and accuracy.\n- **Validated Numerically:** Numerical experiments with up to 8 assets show rapid, monotonic convergence of option prices as bond dimension increases, confirming the practical utility of the method.\n\n#### Connections to Related Work\n\n- **Traditional Methods:** Standard binomial trees and Monte Carlo methods for multi-asset options are either computationally prohibitive or require extensive simulation[3][4].\n- **Other Tensor Network Approaches:** Previous work has mainly focused on European options or path-dependent options like Asians. This is one of the first methods to efficiently price American basket options using tensor networks.\n- **Broader Impact:** The approach opens the door to efficient pricing of other exotic options with multiple underlying assets and complex payoff structures.\n\n#### Implications for the Field\n\n- **Enables New Pricing Tools:** Financial engineers can now price multi-asset American options with much larger baskets than previously possible.\n- **Cross-Disciplinary Impact:** The use of tensor networks from quantum physics in finance demonstrates the power of interdisciplinary research.\n- **Future Directions:** This methodology can be extended to other types of derivatives and adapted to include additional features like stochastic volatility or interest rates.\n\n### Summary Table: Key Innovations and Results\n\n| Feature/Innovation                                  | Description                                                                 | Result/Impact                |\n|-----------------------------------------------------|------------------------------------------------------------------------------|------------------------------|\n| Cholesky Decomposition                             | Transforms correlated assets into uncorrelated variables                    | Enables independent trees    |\n| TTcross/MPS Representation                         | Approximates high-dimensional payoffs efficiently                            | Linear scaling in $m$        |\n| Backward Induction with TTcross Reprojection        | Handles early exercise while maintaining MPS structure                      | Efficient American pricing   |\n| Numerical Validation                                | Demonstrates rapid convergence with increasing bond dimension                | Practical for $m \\leq 8$     |\n\n### Page References and Figure/Table Citations\n\n- **Cholesky decomposition and decoupled dynamics:** See \"American basket option pricing with matrix product states,\" p. 7-8.\n- **TTcross approximation of payoff:** See Algorithm 1 on p. 8, and related discussion.\n- **Backward induction and early exercise handling:** See p. 8, and Fig. 2 for analogous tensor network diagrams (for Asian options, but the structure is similar for baskets).\n- **Numerical experiments and convergence:** See discussion of numerical experiments for baskets with up to 8 assets, and comparison with Monte Carlo and standard methods (not shown in detail in this snippet, but referenced in the broader context).\n\n---\n\nThis section provides a comprehensive, educational breakdown of the research paper\u2019s approach to American basket option pricing using decoupled trees and TTcross approximation, making it accessible to advanced researchers while maintaining technical rigor and connecting to the broader landscape of computational finance.", "page_number": 8, "citations": ["https://www.risk.net/journal-of-computational-finance/2447114/accelerated-trinomial-trees-applied-to-american-basket-options-and-american-options-under-the-bates-model", "https://daniellinders.com/wp-content/uploads/2019/02/american-basket-option-pricing-final.pdf", "https://www.bacheliercongress.com/2010/talks/Wed/GGSuite/bfs272Borovkova.pdf", "https://www.globalcapital.com/article/k6b8ltrm42jx/equity-basket-swaps-and-options-part-ii", "https://pure.uva.nl/ws/files/43829402/American_basket_option_pricing_Quantitative_Finance.pdf"], "subsections": []}, {"id": "results-and-analysis", "title": "Results and Analysis: Performance Evaluation of Tensor Network Methods in Exotic Option Pricing", "content": "## Results and Analysis: Performance Evaluation of Tensor Network Methods in Exotic Option Pricing\n\nThis section details the empirical evaluation of tensor network-based methods for pricing exotic financial derivatives, focusing on their accuracy, efficiency, and convergence characteristics as compared to the classical Monte Carlo approach. Understanding these results is crucial for appreciating how tensor network techniques overcome the computational challenges posed by high-dimensional problems like Asian and American basket options, which are otherwise hampered by exponential complexity or slow convergence in traditional methods. These findings link directly to the broader research goal of enhancing option pricing efficacy using Matrix Product States (MPS) and related tensor network approximations embedded within binomial pricing frameworks (as introduced on page 3-7) [1].\n\n---\n\n### Core Concepts and Performance Comparison\n\n#### Tensor Networks in Option Pricing\n\nTensor networks, specifically the Matrix Product State (MPS) format, provide efficient representations of high-dimensional tensors by decomposing them into products of lower-dimensional tensors with controlled bond dimension $D$ (see Eq. (7) on page 3). This transforms the exponentially scaling problem of pricing path-dependent or basket options into a linearly scaling one with respect to parameters such as time steps $N$ or number of assets $m$. The bond dimension $D$ balances expressivity and computational cost, with higher $D$ providing better approximations at increased cost.\n\n#### Asian Option Pricing: TTcross vs Variational MPS vs Monte Carlo\n\nTwo tensor network methodologies were benchmarked for Asian options, which are path-dependent and whose payoff depends on the arithmetic average of asset prices over $N$ discrete time steps:\n\n- **TTcross Method (Sec. IV A.1, page 4-5):** Utilizes the tensor-train cross approximation to represent the product $p(x) v_A(x)$ (the probability-weighted payoff) as an MPS and then contracts this tensor network efficiently to approximate the option price (Eqs. (15)-(16)).\n\n- **Variational MPS Method (Sec. IV A.2, page 5-7):** Formulates pricing as a variational optimization problem over a binary MPS ansatz $\\psi(x)$ that encodes the payoff domain, optimized through a sweeping procedure akin to the DMRG algorithm (Eq. (29)-(31)).\n\nFigures 3, 4, and 5 illustrate the performance comparisons:\n\n- **Figure 3 (page 5):** Shows that TTcross achieves faster convergence in pricing error with respect to walltime than Monte Carlo for moderate time steps ($N=25,30,50$). For smaller $N$, TTcross requires roughly 50-100 times less walltime than Monte Carlo to reach comparable error levels.\n\n- **Figure 5 (page 7):** Compares the pricing errors of TTcross, Variational MPS, and Monte Carlo for $N=25$ and $N=50$, confirming that tensor network methods outperform Monte Carlo in lower $N$, while Monte Carlo regains competitiveness at higher dimensionalities.\n\n- **Figure 6 (page 7):** Demonstrates the impact of asset volatility $\\sigma$ on convergence. When volatility is high ($\\sigma=2$), tensor network methods significantly outperform Monte Carlo, whereas at low volatility ($\\sigma=0.5$), Monte Carlo performs comparatively better. This supports the intuition that tensor networks handle \"difficult\" parameter regimes (high volatility, low time steps) more efficiently.\n\nThese results collectively show that tensor network approaches are particularly advantageous when the option pricing problem is challenging due to increased volatility or path-dependence, aligning with the theoretical prediction of linear scaling in $N$ for fixed bond dimension.\n\n#### American Basket Option Pricing\n\nFor multi-asset American basket options involving early exercise features and asset correlations, the tensor network approach scales linearly with both the discretization steps $N$ and number of assets $m$ (Sec. IV B, page 7-9). Through a decoupling technique using Cholesky decomposition (Eq. (40)-(43)), correlated asset dynamics are transformed into independent binomial trees, each approximated by an MPS with increasing bond dimension. The numerical experiments on baskets of size $m=4$ and $8$ confirm fast monotonic convergence of option prices with increasing bond dimension, even under the complexity of early exercise (Fig. 8 and related tables). This scaling behavior contrasts with the exponential computational blow-up of classical binomial pricing, highlighting the practical scalability of the proposed method.\n\n---\n\n### Technical Details on Implementation and Methodology\n\n#### Algorithmic Steps for Asian Options\n\n- **TTcross Approximation:** Utilizes a vectorized, parallel implementation of tensor-train cross approximation (based on the TensorNetwork package, page 4) to approximate the tensor representing $p(x)v_A(x)$ as an MPS with bond dimension $D$ (Eqs. (16), (21)-(27)).\n\n- **Variational Optimization:** Uses a sweeping algorithm optimizing binary MPS tensors $\\psi$ to maximize the expected payoff (Eq. (29)-(30)). The optimization updates one tensor at a time, employing a mixed-integer constrained least squares problem to maintain the binary structure of the tensors (Eqs. (33)-(37)).\n\n  The key update step for tensor $A_c$ involves computing the gradient of the cost function (Eq. (35)) and approximating the resulting tensor while controlling bond dimension to avoid exponential growth (page 6-7).\n\n- **Parameter Choices:** Bond dimensions were varied from $D=30$ to $250$ for TTcross, and similarly for variational MPS, to observe convergence trends (Figures 4-6). The initial asset price $S_0=100$, strike $K=100$, time $T=1$, risk-free rate $r=0.1$, and asset volatility $\\sigma$ were fixed unless otherwise specified (page 4-7).\n\n#### Multi-Asset Basket Option Pricing\n\n- **Decoupled Trees:** Based on the Rendleman-Bartter binomial model discretization (Eq. (42)) for each uncorrelated asset variable after Cholesky factorization of the covariance matrix $\\Sigma$ (Eqs. (40)-(41)) (page 7-8).\n\n- **Tensor Network Representation:** The multidimensional option price function is represented as an MPS, with increasing bond dimension controlling approximation quality as asset count $m$ grows.\n\n- **Convergence and Scalability:** The tensor network contractions and optimizations are linear in both $N$ and $m$ (page 8-9), a key implementation advantage over classical exponential scaling binomial trees.\n\n---\n\n### Significance and Broader Connections\n\nThese results demonstrate a significant breakthrough in financial engineering by leveraging tensor network methods\u2014originally developed in quantum many-body physics\u2014to address computational bottlenecks in exotic option pricing. Notably, the:\n\n- **Linear Scaling:** With respect to time steps $N$ and asset count $m$, tensor networks bypass the curse of dimensionality that plagues binomial and Monte Carlo methods in complex option pricing.\n\n- **Superior Efficiency in Challenging Regimes:** As Figures 5 and 6 show, tensor network techniques are more efficient in high volatility and path-dependent contexts where Monte Carlo methods struggle, providing both accuracy and computational speedups (page 5-7).\n\n- **Innovative Variational MPS Formulation:** The variational method introduces a novel parametrization for binary MPS representing indicator functions over the payoff domain, expanding the methodological toolkit beyond standard TTcross approximations (pages 5-7).\n\n- **Broader Impact:** This work connects with ongoing research on quantum-enhanced financial algorithms and machine learning approaches for derivative pricing [2][5]. It sets the stage for leveraging tensor network methods in both classical and quantum finance computational architectures, potentially transforming risk management and trading technology.\n\nIn summary, the empirical performance evaluation strongly validates tensor network methods as powerful and scalable tools for efficiently pricing complex exotic derivatives, overcoming classical computational limitations and enabling new avenues in quantitative finance.\n\n---\n\n**References to the paper:** Performance results and figures are detailed on pages 4-9, with Figures 3, 4, 5, and 6 illustrating convergence benchmarks of tensor network methods against Monte Carlo sampling. Algorithms and mathematical formulations underpinning these methods are described primarily in sections IV A and IV B, pages 3-9 [1].", "page_number": 4, "citations": ["https://arxiv.org/abs/2505.17033", "https://25677273.fs1.hubspotusercontent-eu1.net/hubfs/25677273/Cirdan%20Capital%20Case%20Study-Tensor%20Networks%20applied%20to%20Speeding%20up%20Exotic%20Options%20Pricing-2.pdf", "https://www.bayes.citystgeorges.ac.uk/__data/assets/pdf_file/0007/494080/DeepLearningExoticOptionPricingLSVOL_KB_CassBusinessSchool_2019.pdf", "https://terraquantum.swiss/news/terra-quantum-and-cirdan-capital", "https://www.themoonlight.io/en/review/time-series-generation-for-option-pricing-on-quantum-computers-using-tensor-network"], "subsections": []}, {"id": "asian-option-performance-comparison", "title": "Asian Option Pricing: TTcross and Variational Methods vs Monte Carlo", "content": "Below is an expanded, educational breakdown for the section \u201cAsian Option Pricing: TTcross and Variational Methods vs Monte Carlo.\u201d The content is structured for clarity and pedagogical effectiveness, referencing specific page numbers, figures, and equations from the paper, and maintaining rigorous technical accuracy.\n\n---\n\n## Learning Objectives and Context\n\nThis section provides a detailed comparison of three computational approaches for pricing Asian options in a binomial setting: Monte Carlo sampling, Tensor Train Cross Approximation (TTcross), and a novel variational approach using matrix product states (MPS). The discussion centers on their relative efficiency in terms of error convergence and computational walltime, as well as the reliability of the resulting price estimates.\n\n**Why is this important for the paper?**  \nPricing Asian options\u2014where the payoff depends on the average price of the underlying asset over a period\u2014is a classic challenge in quantitative finance due to its path-dependent nature. Traditional methods, such as Monte Carlo and binomial trees, face computational bottlenecks as the number of time steps increases. The paper\u2019s tensor network approach addresses these challenges, offering faster convergence and rigorous error bounds.\n\n## Core Concepts and Mathematical Foundations\n\n**Asian Options and Path Dependence**\n\nAn Asian call option\u2019s payoff is given by:\n$$\nv_A = \\max\\left(\\langle S_T \\rangle - K, 0\\right)\n$$\nwhere $\\langle S_T \\rangle$ represents the arithmetic average of the underlying asset price $S_t$ over the option\u2019s life. This averaging introduces path dependence, since the payoff depends not just on the final price but on all intermediate values (see page 4).\n\n**Pricing Framework**\n\nThe binomial pricing model discretizes time into $N$ steps, with the asset price $S$ moving either up or down at each step. The theoretical value of the option, given by the Feynman-Kac formula, is:\n$$\nV(t, K | S_0) = e^{-r(T-t)}\\mathbb{E} \\left[ \\max\\left(\\frac{1}{N}\\sum_{k=1}^N S_k - K, 0\\right) \\right]\n$$\nwhere $\\mathbb{E}$ denotes the expectation over all possible asset price paths, and $r$ is the risk-neutral interest rate (page 4).\n\n**Monte Carlo Sampling**\n\nMonte Carlo methods estimate this expectation by sampling paths and averaging payoffs. For each sample path $x = x_1x_2\\dots x_N$ (where $x_i$ denotes an up or down move), the payoff is computed as:\n$$\nv_A(x) = \\max\\left(\\frac{S_0}{N}\\sum_{i=1}^N \\prod_{k=1}^i d^{1-x_k}u^{x_k} - K, 0\\right)\n$$\nEach path\u2019s probability is:\n$$\np(x) = \\prod_{k=1}^N p_u^{x_k}(1 - p_u)^{1-x_k}\n$$\nand the option price is estimated as:\n$$\nV(0, K | S_0) \\approx e^{-rT}\\frac{1}{N_s}\\sum_{i=1}^{N_s} v_A(x_i)\n$$\nfor $N_s$ samples (page 5).\n\n**Tensor Networks and TTcross Approximation**\n\nTensor networks, specifically matrix product states (MPS), efficiently represent high-dimensional sums by breaking them into products of low-dimensional tensors. The TTcross method approximates the joint distribution $p(x)v_A(x)$ as an MPS, allowing efficient computation of the option price via tensor contraction (page 5, Fig. 2a and 2b).\n\n**Variational Method via MPS**\n\nThe variational approach uses a binary MPS ansatz to maximize the restricted sum of positive payoffs, providing a lower bound on the option price. This is analogous to DMRG in physics, where the state is optimized by sweeping through each tensor site and updating to maximize the expected payoff (page 6, Eq. 29\u201335).\n\n## Methodology and Implementation Details\n\n**TTcross Implementation**\n\n1. **Path Encoding:** Asset trajectories are encoded as bit strings $x$ (page 5).\n2. **MPS Construction:** The product $p(x)v_A(x)$ is approximated as an MPS using TTcross, with each tensor representing a time step.\n3. **Tensor Contraction:** The option price is obtained by contracting the MPS with a vector of ones, summing over all paths (page 5, Fig. 2b).\n4. **Parameter Choices:** Computations are repeated across bond dimensions $D$ (typically 30\u2013250), and the results are averaged over independent runs.\n\n**Variational Method Implementation**\n\n1. **Binary MPS:** The indicator function $\\psi_{x_1\\dots x_N} \\in \\{0,1\\}$ selects paths with positive payoff.\n2. **Sweeping Optimization:** Tensors are optimized one at a time, similar to the DMRG algorithm.\n3. **Bond Dimension:** The method\u2019s accuracy improves with larger bond dimension, converging to the exact price (page 6, Fig. 4).\n4. **Lower Bound:** The variational method naturally provides a lower bound on the option price, ensuring conservative valuation.\n\n**Monte Carlo Sampling Details**\n\n- **Sampling:** $N_s$ paths are sampled from $p(x)$, and the payoff is averaged.\n- **Convergence:** Error decreases as $1/\\sqrt{N_s}$, requiring many samples for high accuracy (page 5).\n\n\`\`\`\n\n// Pseudocode: TTcross MPS Approximation for Asian Option Pricing\nfor path x in paths:\n    encode x as a bit string\n    compute p(x) and v_A(x)\n    construct MPS approximation for p(x)v_A(x) using TTcross\ncontract MPS with vector of ones to get option price\n\`\`\`\n\n## Results and Performance Comparison\n\n**Convergence and Walltime**\n\n- **Figure 3:** TTcross achieves lower pricing error than Monte Carlo for the same walltime, especially for moderate time steps ($N=25, 30$), due to its efficient tensor contraction (page 6, Fig. 3).\n- **Figure 5:** Both TTcross and variational methods reduce error by an order of magnitude faster than Monte Carlo for $N=25$; for larger $N$, Monte Carlo remains competitive (page 7, Fig. 5).\n- **Volatility Dependence:** At high volatility ($\\sigma=2$), tensor methods outperform Monte Carlo by more than an order of magnitude; at low volatility, Monte Carlo is efficient (page 7, Fig. 6).\n\n**Reliability and Lower Bounds**\n\n- **Variational Method:** Produces a rigorous lower bound on the option price, offering additional reliability over stochastic estimates (page 6, Eqs. 19\u201320).\n- **Robustness:** The method\u2019s accuracy is robust to initialization and converges rapidly with increasing bond dimension (page 6, Fig. 4).\n\n## Technical and Algorithmic Insights\n\n**Why Tensor Networks?**\n\nTensor networks overcome the curse of dimensionality by representing high-dimensional sums as products of low-dimensional tensors. This allows efficient computation even for large $N$, making them suitable for path-dependent options like Asian options (pages 3\u20135).\n\n**Choosing the Right Method**\n\n- **For Moderate $N$ and High Volatility:** TTcross and variational methods are preferred for speed and accuracy.\n- **For Large $N$ or Low Volatility:** Monte Carlo remains practical and competitive (page 7, Fig. 5\u20136).\n\n**Parameter Selection**\n\n- **Bond Dimension:** Larger $D$ improves accuracy but increases computational cost. The choice is a trade-off between speed and precision.\n- **Sweeping Algorithm:** The variational method\u2019s sweeping procedure ensures efficient optimization, analogous to DMRG in physics (page 6).\n\n## Significance and Broader Connections\n\n**Novelty and Impact**\n\nThe use of TTcross and variational MPS methods for Asian option pricing represents a significant advance in computational finance. These techniques reduce the computational complexity from exponential to linear in $N$ for a fixed bond dimension, enabling efficient pricing of path-dependent options that were previously intractable (pages 7\u20138).\n\n**Connection to Related Work**\n\nTraditional methods for Asian option pricing include Monte Carlo simulation and control variate techniques[1][2][3], but these can be slow or require many samples for accurate results. The paper\u2019s approach builds on advances in tensor network theory from quantum physics and machine learning, highlighting the interdisciplinary potential of these tools[2][3].\n\n**Implications for the Field**\n\nThe results suggest that tensor network methods could replace or supplement Monte Carlo for a wide range of exotic option pricing problems, especially those with high dimensionality or strong path dependence. This opens new avenues for risk management, portfolio optimization, and real-time pricing in financial markets.\n\n---\n\n## Summary Table: Performance Comparison\n\n| Method         | Error Convergence | Walltime Efficiency | Best Use Case                | Lower Bound Guarantee |\n|----------------|------------------|---------------------|------------------------------|----------------------|\n| Monte Carlo    | $1/\\sqrt{N_s}$   | Poor for high $\\sigma$ | Large $N$, low $\\sigma$      | No                   |\n| TTcross        | Fast, robust     | Excellent for $N=25$ | Moderate $N$, high $\\sigma$  | No                   |\n| Variational    | Fast, lower bound| Excellent for $N=25$ | Moderate $N$, high $\\sigma$  | Yes                  |\n\n---\n\n## Key Takeaways\n\n- **Tensor network methods (TTcross, variational MPS) offer significant speedups and error reduction for Asian option pricing, especially for moderate time steps and high asset volatility.**\n- **The variational method provides a rigorous lower bound on the option price, enhancing reliability.**\n- **These innovations connect computational finance with advances in quantum physics and machine learning, demonstrating the potential for cross-disciplinary impact in financial engineering.**\n\n---\n\n**References to Paper Sections:**  \n- **Introduction to Asian options and tensor networks:** Pages 1\u20135\n- **Mathematical formulation and MPS:** Pages 3\u20135, Eqs. 7\u201315\n- **TTcross implementation:** Pages 5\u20136, Fig. 2, 3\n- **Variational method and algorithms:** Pages 6\u20137, Eqs. 19\u201335, Fig. 4\n- **Performance comparison:** Pages 7\u20138, Fig. 5, 6\n\n**Related External References:**  \n- **Monte Carlo and control variates for Asian options:** [1][2][3]\n- **Comparison of numerical and simulation methods:** [1][2][3]", "page_number": 4, "citations": ["https://www.scirp.org/journal/paperinformation?paperid=72116", "https://www.mathworks.com/help/fininst/black-scholes-model-to-price-asian-options-using-different-pricing-methods.html", "https://eudl.eu/pdf/10.4108/eai.28-10-2022.2328407", "https://www.quantstart.com/articles/Asian-option-pricing-with-C-via-Monte-Carlo-Methods/", "https://www.iccs-meeting.org/archive/iccs2019/papers/115380317.pdf"], "subsections": []}, {"id": "american-basket-option-pricing-results", "title": "American Basket Option Pricing: Convergence and Scalability", "content": "## Section: American Basket Option Pricing \u2014 Convergence and Scalability\n\n### Introduction\n\nThis section explores the practical evaluation and implementation of cutting-edge numerical methods for pricing American basket put options on multi-asset portfolios. Specifically, it analyzes the convergence properties and computational scaling of the tensor train cross (TTcross) approximation method, which leverages tensor network techniques\u2014specifically matrix product states (MPS)\u2014for efficient option pricing[2]. The section is central to understanding the core innovation of the paper and its broader impact on quantitative finance.\n\nAmerican basket options are complex derivatives that grant the holder the right, but not the obligation, to sell a basket of assets at a predetermined price, exercisable at any time before maturity. Pricing such options is computationally challenging due to the curse of dimensionality and the need for repeated early exercise evaluations[2][4]. The TTcross method addresses these challenges by enabling near-exact pricing with linear computational scaling, while efficiently incorporating early exercise features[2].\n\nThis topic is important for readers seeking to understand how advanced numerical techniques from computational physics (tensor networks) are being adapted to solve real-world financial engineering problems, overcoming limitations of traditional binomial trees and Monte Carlo simulation[2].\n\n### Core Content\n\n#### Key Concepts and Definitions\n\n- **American Basket Options:** These are multi-asset options exercisable at any time up to maturity, with payoffs depending on the minimum, maximum, or average value of a basket of underlying assets.\n- **Binomial Tree Methods:** Standard approaches for option pricing that discretize asset price movements into up and down steps. For multi-asset options, these methods become intractable due to exponential scaling in the number of assets[2].\n- **Matrix Product States (MPS):** A type of tensor network that efficiently represents high-dimensional probability distributions using data structures akin to linked matrices. MPS allows for linear scaling with respect to the number of assets or time steps, breaking the curse of dimensionality[2].\n- **TTcross Approximation:** A technique to approximate high-dimensional functions as MPS by iteratively refining the bond dimension, which controls the accuracy and computational cost of the MPS approximation[2].\n\n#### Mathematical Formulations and Examples\n\nConsider a basket of $m$ assets with log-prices $Y_t$ and Cholesky-decomposed correlation, leading to uncorrelated random walks:\n\n$$\nY_t = G^{-1} X_t\n$$\n\nwhere $G$ is a lower triangular matrix, $X_t$ the vector of log asset prices, and $Y_t$ the decoupled asset price innovations[2]. The decoupling allows each asset\'s price path to be modeled independently, simplifying the representation:\n\n$$\ndY_j^t = \\alpha_j dt + d\\overline{W}_j^t\n$$\n\nwhere $\\alpha_j$ is a drift term and $d\\overline{W}_j^t$ are uncorrelated Wiener processes[2].\n\nThe payoff for a max-basket put option at maturity $T$ is:\n\n$$\nv(Y_N) = \\max\\left(K - \\max(e^{GY_N}), 0\\right)\n$$\n\nwhere $Y_N$ is the vector of asset log-prices at time $T$, and $K$ is the strike price[2].\n\n#### Convergence and Scalability\n\nFigure 7 in the paper (referenced on page 11) shows how the calculated option prices converge monotonically with increasing MPS bond dimension. This bond dimension controls the accuracy of the MPS approximation: higher values increase precision but also computational effort. For smaller baskets (e.g., $m=4$), results closely match brute-force exact binomial prices, confirming the method\'s accuracy[2].\n\nA key advantage is the linear scaling in the number of assets $m$, in stark contrast to the exponential scaling of standard binomial trees. This allows for practical pricing of larger baskets (e.g., $m=8$), which would be infeasible with traditional methods[2].\n\n#### Early Exercise Integration\n\nEarly exercise features are naturally integrated through repeated MPS approximations at each time step, applying the optimal exercise condition (i.e., comparing the expected payoff from holding versus immediate exercise), as detailed on page 13[2]. This process is computationally efficient within the MPS framework and does not require explicit storage of all possible asset paths, a major bottleneck for conventional methods[2][4].\n\n#### Example\n\nConsider a 4-asset basket. Standard binomial methods would require tracking $2^{(4 \\times N)}$ price paths, where $N$ is the number of time steps. The decoupled tree and MPS approach only requires $O(m \\times N \\times D)$ operations, where $D$ is the bond dimension, typically much smaller than $2^{mN}$[2].\n\n### Technical Details\n\n#### Implementation Specifics\n\nThe TTcross-MPS approach proceeds as follows (pages 10\u201313):\n\n1. **Decouple Correlated Assets:** Use Cholesky decomposition to transform asset log-prices into uncorrelated variables.\n2. **Build Independent Binomial Trees:** For each uncorrelated asset, construct a binomial tree, representing possible price paths.\n3. **Compute Payoff Function:** Evaluate the basket payoff (e.g., put) at each tree node.\n4. **Approximate as MPS:** Use TTcross to approximate the payoff and transition probabilities as an MPS, enabling efficient contraction.\n5. **Iterative Early Exercise:** At each time step, update the MPS to reflect the optimal exercise decision.\n\n#### Algorithmic Pseudocode\n\n\`\`\`python\ndef american_basket_put(m, N, K, r, sigma, rho):\n    # 1. Decouple assets via Cholesky\n    G = cholesky(rho)\n    Y = X @ inv(G)\n    # 2. Build independent binomial trees\n    trees = [build_binomial_tree(alpha[i], sigma[i], N) for i in range(m)]\n    # 3. Compute payoff at maturity\n    payoff = lambda y: max(K - max(exp(G @ y)), 0)\n    # 4. Approximate as MPS\n    mps = ttcross_approximation(payoff, trees)\n    # 5. Iterate backward for early exercise\n    for t in reversed(range(N)):\n        mps = update_mps_for_early_exercise(mps, t)\n    return contract_mps(mps)\n\`\`\`\n\n#### Parameter Choices and Design Decisions\n\n- **Bond Dimension ($D$):** Controls the trade-off between accuracy and computational cost. Experimentally, values of $D$ between 30 and 250 are sufficient for practical convergence (pages 10\u201311)[2].\n- **Discretization Steps ($N$):** The number of time steps in the binomial tree. Higher $N$ gives better accuracy but increases computational cost.\n- **Correlation Handling:** Cholesky decomposition ensures that asset correlations are correctly modeled while maintaining computational tractability[2].\n\n### Significance and Connections\n\n#### Innovations and Contributions\n\n- **Breaking the Curse of Dimensionality:** The TTcross-MPS method enables efficient pricing of multi-asset American options by reducing computational complexity from exponential to linear in the number of assets, a major breakthrough for practical applications (pages 2\u20133)[2].\n- **Practical Applicability:** The method is validated for baskets up to $m=8$ correlated assets, a regime where traditional methods fail (page 12)[2].\n- **Integration of Early Exercise:** The repeated MPS approximation at each time step efficiently captures the early exercise feature without explicit path enumeration (page 13)[2].\n\n#### Broader Research Context\n\nThis work builds on advances in tensor network methods from quantum physics and machine learning, demonstrating their value in quantitative finance. It addresses longstanding challenges in pricing exotic options and opens new avenues for applying tensor-based methods to high-dimensional probabilistic models[2].\n\n#### Connections to Other Sections\n\n- **Asian Option Pricing:** The paper also applies tensor network methods to path-dependent Asian options, showing similar scalability and efficiency benefits (pages 6\u20139)[2].\n- **Monte Carlo Benchmarking:** The results are benchmarked against Monte Carlo simulation, highlighting superior convergence for high-dimensional or high-volatility scenarios (pages 6\u20137, Fig. 5\u20136)[2].\n\n#### Implications\n\nThe TTcross-MPS approach represents a significant advance for financial engineering, enabling efficient risk management and pricing of complex multi-asset derivatives. Its linear scaling and accurate handling of early exercise features make it a promising tool for both research and industry applications[2].\n\n---\n\n> **Summary:**  \n> This section provides a comprehensive, accessible introduction to the TTcross-MPS method for American basket option pricing, explaining its mathematical foundations, algorithmic implementation, and practical significance. By leveraging tensor network techniques, the method overcomes traditional limitations and sets a new standard for efficient, scalable pricing of complex derivatives[2].", "page_number": 9, "citations": ["https://daniellinders.com/wp-content/uploads/2019/02/american-basket-option-pricing-final.pdf", "https://arxiv.org/html/2505.17033v1", "https://arxiv.org/pdf/2302.08041", "https://lirias.kuleuven.be/retrieve/563125", "https://www.diva-portal.org/smash/get/diva2:300858/FULLTEXT01.pdf"], "subsections": []}, {"id": "impact-and-future-directions", "title": "Impact and Future Directions: Advancing Computational Finance with Tensor Networks", "content": "## Impact and Future Directions: Advancing Computational Finance with Tensor Networks\n\nThis section discusses the profound impact of employing tensor network methods, particularly matrix product states (MPS) and tensor train cross (TTcross) approximations, in the model pricing of complex financial derivatives such as Asian and American basket options. It evaluates how these quantum-inspired computational techniques overcome fundamental challenges in traditional option pricing and outlines promising futures for this interdisciplinary approach. Understanding these advancements is essential because they represent a paradigm shift in computational finance, enabling scalable, efficient, and rigorous pricing of high-dimensional, path-dependent options \u2014 a class of problems that has historically been computationally prohibitive.\n\nPositioned within the broader research landscape, this section connects tensor network methods, originally developed for quantum many-body physics, with quantitative finance problems characterized by the curse of dimensionality. This fusion not only enhances option pricing methods but also opens avenues for applying such techniques to other exotic derivatives, alternative stochastic models, and beyond finance into combinatorial optimization and machine learning[1][4].\n\n---\n\n### Core Concepts and Methodological Advances\n\nAt the heart of this work is the combination of classical binomial pricing models with tensor network representations, specifically MPS and TTcross algorithms. Traditional binomial approaches discretize the option\u2019s lifetime into \\(N\\) time steps, modeling asset price dynamics as recombining trees. However, for exotic options such as Asian options (which depend on the average asset price over time) and American basket options (which depend on multiple correlated assets), standard binomial approaches suffer from **exponential complexity** in either the number of time steps or the number of assets. This exponential growth poses intractable computational demands as problem size increases.\n\nTensor networks circumvent this by efficiently encoding high-dimensional tensors representing payoff functions and probability distributions as networks of lower-dimensional tensors. The **Matrix Product State (MPS)** ansatz expresses an \\(N\\)-dimensional tensor \\(M_{x_1 x_2 \\ldots x_N}\\) as a product of matrices (or rank-3 tensors) that scale linearly with \\(N\\) at fixed bond dimension \\(D\\):\n\n$$\nM_{x_1 x_2 \\ldots x_N} \\approx A^{x_1}_1 A^{x_2}_2 \\ldots A^{x_N}_N,\n$$\n\nwhere each \\(A^{x_k}_k\\) is a tensor of dimension related to the bond dimension \\(D\\) (page 3, Eq. 7). This linear scaling contrasts starkly with the exponential storage and computation demands of naive methods, effectively avoiding the *curse of dimensionality*.\n\nTwo main tensor network-based methods were introduced for Asian option pricing:\n\n- **TTcross Approximation:** It approximates the product of path probabilities and payoffs \\(p(x) v_A(x)\\) (where \\(x\\) is a binary string encoding up/down asset price moves) directly as an MPS. This representation allows efficient contraction (summation over all paths) to compute option prices with linear scaling in the number of steps \\(N\\) (page 4, Eq. 16). Figure 2 illustrates this tensor network contraction, where the payoff-weighted path probabilities are encoded as a chain of tensors contracted to produce the scalar option price.\n\n- **Variational MPS Approach:** This method formulates option pricing as a variational optimization problem that seeks a binary MPS tensor \\(\\psi_{x_1 \\ldots x_N}\\) to maximize a cost function representing a lower bound on the option price (page 5-6, Eqs. 28-30). The approach uses a sweeping algorithm akin to the Density Matrix Renormalization Group (DMRG) to optimize the MPS tensors one site at a time, systematically converging to accurate lower bounds as the bond dimension increases. Figure 4 demonstrates how the option price converges toward exact binomial prices as bond dimension grows.\n\nThese tensor network methods are compared with traditional Monte Carlo (MC) simulations (Figures 3, 5, 6). The results show:\n\n- For smaller \\(N\\) or higher volatility \\(\\sigma\\), TTcross and variational MPS methods outperform MC in terms of convergence speed and accuracy per unit wall time, offering error reductions by an order of magnitude or more.\n- MC gains efficiency at higher \\(N\\) and lower volatility due to its sampling nature.\n\nThis interplay between volatility, dimensionality, and method efficiency provides key insights into when tensor network methods are most beneficial.\n\n---\n\n### Technical Implementation Details\n\nImplementation of these methods involves several crucial design choices:\n\n- **Parameter Selection:** The bond dimension \\(D\\) controls the expressiveness of the MPS ansatz. Larger values of \\(D\\) allow more accurate representations but increase computational cost. Experiments use \\(D\\) ranging from 30 to 250, balancing accuracy and cost (pages 4-6).\n\n- **Binary MPS Representation:** For the variational approach, the binary nature of \\(\\psi\\) is preserved through a special tensor decomposition (Eq. 32), enforcing constraints (Eqs. 33 & 34) to ensure entries are within \\(\\{0,1\\}\\). This nontrivial parametrization supports efficient optimization but only guarantees a lower bound on option prices due to its limited expressiveness at finite \\(D\\).\n\n- **Optimization Algorithm:** The variational method uses a sweeping DMRG-like algorithm that iteratively updates one tensor \\(A^{x_c}_c\\) at a time while fixing others (page 6). The update involves:\n\n\`\`\`markdown\nAlgorithm: Variational MPS Optimization Sweep\n1. Initialize MPS tensors \\( \\{A^{x_k}_k\\} \\) with bond dimension \\(D\\).\n2. For each site \\(c\\) in 1 to \\(N\\):\n   a. Compute the effective tensor \\(V^{x_c}_{\\alpha_{c-1}\\alpha_c}\\) gradient.\n   b. Solve the mixed-integer constrained optimization to approximate:\n      \\( V^{x_c}_c \\approx L^{x_c}_c M \\),\n      ensuring \\(L^{x_c}_c\\) obeys binary constraints.\n   c. Update \\(A^{x_c}_c \\leftarrow L^{x_c}_c\\).\n3. Repeat until convergence or maximum sweeps reached.\n\`\`\`\n\n- **Decoupled Trees for Multi-Asset Options:** For pricing American basket options, the authors adopt the decoupled trees technique, transforming correlated multi-asset dynamics into independent binomial trees via Cholesky decomposition (page 7, Eqs. 38-43). This reduces complexity but inherits some limitations from the underlying approximation framework.\n\nFigure 1 and Table I provide visual and parametric details on the binomial discretization schemes (CRR and RB) used throughout.\n\n---\n\n### Significance and Broader Connections\n\nThis research delivers a novel integration of quantum-inspired tensor network methods into computational finance, with significant contributions:\n\n- **Breaking the Exponential Barrier:** By combining binomial pricing with MPS and TTCross approximations, the authors achieve linear scaling in the number of discretization steps \\(N\\) for Asian options and in the number of assets \\(m\\) for basket options, drastically reducing computational cost and enabling pricing for larger, more realistic problem instances (page 2 and 4).\n\n- **Providing Rigorous Lower Bounds:** The variational MPS method offers a mathematically grounded lower bound on option prices, a feature absent in Monte Carlo methods that often rely on statistical sampling with noisy estimates (page 5). This adds reliability, crucial in risk-sensitive financial decision-making.\n\n- **Interdisciplinary Innovation:** The work bridges quantum physics, numerical tensor methods, and financial engineering, fostering cross-fertilization that can inspire new algorithmic advances. Such quantum-inspired methods have potential applications beyond finance, e.g., in combinatorial optimization and machine learning problem domains that also suffer from high dimensionality and complex dependencies[1][4].\n\n- **Limitations and Future Work:** The methods show regime-specific performance, excelling particularly at small time steps and high volatility but less so at very large \\(N\\). Extending the approach to other exotic options like barrier and look-back types, refining MPS parameterizations for better binary tensor representations, and adapting to alternative stochastic models constitute important avenues for future research (page 8).\n\nIn summary, these tensor network-based approaches represent a significant step forward in enabling scalable, accurate pricing of complex financial derivatives. They illustrate how tools from quantum many-body physics can reshape quantitative finance, with promising implications for algorithmic finance and beyond.\n\n---\n\nThis comprehensive examination of the impact and future directions of tensor networks in computational finance elucidates key innovations, technical strategies, and multidisciplinary potential, empowering researchers and practitioners to harness these methods for advancing the state of the art in option pricing and high-dimensional stochastic optimization.", "page_number": 10, "citations": ["https://arxiv.org/html/2408.05011v1", "http://arxiv.org/pdf/2408.05011", "https://www.quera.com/glossary/tensor-networks", "https://quantumzeitgeist.com/quantum-inspired-algorithms-tensor-network-methods/", "https://multiversecomputing.com/papers/quantum-inspired-tensor-neural-networks-for-option-pricing"], "subsections": []}, {"id": "significance-and-limitations", "title": "Significance and Limitations of Tensor Network Methods", "content": "## Significance and Limitations of Tensor Network Methods\n\nThis section elucidates the critical role and inherent boundaries of tensor network methods, specifically Matrix Product States (MPS), in pricing exotic financial options. Understanding these aspects is vital to appreciate the methodological advances introduced in the paper **\u201cBoosting Binomial Exotic Option Pricing with Tensor Networks\u201d** and how these advances address traditional computational bottlenecks in financial engineering. This discussion situates tensor networks within the broader research context of overcoming the curse of dimensionality in option pricing, paving the way for scalable, efficient algorithms for complex derivatives such as Asian and multi-asset American basket options.\n\n---\n\n### Introduction\n\nPricing exotic options, such as Asian or basket options, involves evaluating expectations over complex, high-dimensional stochastic processes that exhibit path dependence or multiple underlying assets. Traditional numerical methods either scale exponentially with the number of time discretization steps or assets \u2014 the so-called *curse of dimensionality* \u2014 or require extensive simulation, such as Monte Carlo methods, which can be computationally expensive and slow to converge. This section covers how tensor network methods offer significant computational advantages by reducing complexity from exponential to linear scaling in key parameters, while also delineating the practical limitations and scenarios where classical techniques may still prevail.\n\nThe significance of this topic lies in framing the contributions of the proposed tensor network approaches in the paper and guiding practitioners on when these methods are most effective. It highlights the importance of these approaches in advancing quantitative finance, where rapid, accurate pricing of complex derivatives is essential for risk management and trading strategies.\n\n---\n\n### Core Content\n\n#### Key Concepts and Methodological Advances\n\n**Tensor networks** are sophisticated data structures for representing and manipulating high-dimensional tensors efficiently. The paper focuses on the *Matrix Product State* (MPS) representation, also known as the tensor train format, which decomposes an $N$-dimensional tensor \\( M_{x_1 x_2 \\ldots x_N} \\) into a product of lower-rank tensors:\n\n$$\nM_{x_1 x_2 \\ldots x_N} = A^{x_1}_1 A^{x_2}_2 \\ldots A^{x_N}_N,\n$$\n\nwhere each \\( A^{x_k}_k \\) is a tensor with controlled bond dimension $D$ that governs the expressiveness and memory requirements (refer to Eq. (7), page 3 of the paper)[1]. Crucially, the MPS format scales **linearly** with $N$ at fixed $D$, contrasting with the exponential scaling of storing the full tensor.\n\nIn the context of **Asian option pricing**, whose payoff depends on the average price over multiple time steps \\( N \\), the paper presents two tensor network methods:\n\n1. **Tensor Train Cross (TTcross) Approximation**: This method approximates the function \\( p(x)v_A(x) \\), where \\( p(x) \\) is the path probability and \\( v_A(x) \\) the Asian payoff, as an MPS. The expectation integral for the option price then reduces to a tensor contraction efficiently computable in linear time (Eq. (16), Fig. 2, pages 4\u20135)[1]. Figure 3 (page 5) demonstrates the superior convergence of TTcross relative to Monte Carlo, achieving similar accuracy with roughly 50\u2013100 times less computational walltime for moderate $N$.\n\n2. **Variational MPS Method**: Here, the problem is recast as a variational optimization, maximizing a cost function over a binary MPS ansatz \\(\\psi_x\\) to obtain a rigorous **lower bound** on the option price (Eqs. (29)\u2013(31), pages 5\u20137)[1]. The optimization leverages sweeping updates akin to the Density Matrix Renormalization Group (DMRG) algorithm, allowing scalable and accurate pricing with controllable bond dimension (Fig. 4, page 7 shows convergence with increasing $D$).\n\nFor **multi-asset American basket options**, the paper combines MPS with the **decoupled trees technique** to handle up to \\( m = 8 \\) correlated assets by transforming correlated dynamics into uncorrelated variables and applying tensor network methods for the multi-dimensional binomial trees (Section IV B, pages 7\u20138)[1].\n\n#### Mathematical Foundations\n\nIn the binomial model, asset paths are discretized into sequences \\( x = (x_1, ..., x_N) \\) with \\( x_k \\in \\{0,1\\} \\) indicating up/down moves, and the option price at time zero is given by the discounted expectation:\n\n$$\nV(0, K|S_0) = e^{-rT} \\sum_x p(x) v(x).\n$$\n\nThe core challenge is to efficiently approximate and sum over the exponentially many paths \\(x\\). Tensor networks enable representing \\( p(x) v(x) \\) as an MPS and evaluating sums by tensor contractions with computational effort scaling as \\( O(N D^3) \\), where $D$ is the bond dimension (Section IV A, pages 4\u20137)[1].\n\n---\n\n### Technical Details\n\n#### Implementation Specifics and Algorithmic Procedures\n\nThe TTcross method constructs an approximate MPS representation of the high-dimensional function \\( p(x) v_A(x) \\) through an adaptive sampling of tensor elements, exploiting tensor train cross approximation algorithms . This approach avoids explicit storage of the entire tensor, making it computationally scalable for large \\(N\\).\n\nThe variational approach optimizes the lower bound by representing the binary indicator tensor \\(\\psi_x\\) as an MPS with tensors \\( \\{A_k^{x_k}\\} \\) obeying binary constraints (Eqs. (28)\u2013(34), pages 5\u20137)[1]. The cost function gradient with respect to each tensor is computed using tensor network calculus (Eq. (35)), and a mixed-integer constrained optimization problem is solved approximately (Eq. (37)) via a greedy heuristic detailed in the paper\u2019s Appendix B. The sweeping DMRG-like algorithm updates tensors site-by-site to optimize the lower bound estimate iteratively.\n\nAlgorithm (pseudocode) for variational optimization step:\n\n\`\`\`pseudo\nInitialize MPS tensors {A_k} with bond dimension D\nrepeat until convergence:\n    for k in 1 to N:\n        Compute gradient \u2202K/\u2202A_k using tensor contractions\n        Solve mixed-integer approximation to update A_k\n    end for\nend repeat\nReturn optimized MPS representing \u03c8_x\n\`\`\`\n\nParameter choices, such as bond dimension \\( D \\), strike a balance between accuracy and computational cost. Higher \\( D \\) allows capturing more complex correlations but increases runtime roughly as \\( O(N D^3) \\). Figures 4\u20136 (pages 6\u20138) empirically validate these trade-offs.\n\nFor American basket options pricing, the decoupled trees method first performs a Cholesky decomposition of the covariance matrix (Eq. (40), page 7) to transform correlated asset price processes into independent ones, facilitating tensor network application on multi-dimensional binomial trees. This approach, while powerful, introduces constraints on the number of assets due to computational overhead and the decoupling assumptions.\n\n---\n\n### Significance and Connections\n\nThe tensor network methods introduced are novel because they enable:\n\n- **Linear computational scaling** in the number of time steps \\(N\\) for Asian options and in the number of assets \\(m\\) for basket options, overcoming traditional exponential bottlenecks (as shown throughout Section IV).\n- A rigorous **lower bound** on the option price via the variational MPS approach, providing valuable guarantees for pricing accuracy (Section IV A 2).\n- Practical improvements demonstrated by numerical experiments where TTcross and variational methods significantly outperform Monte Carlo in high-volatility regimes (Fig. 6, page 8), highlighting robustness in challenging scenarios.\n\nThese innovations connect to a broader research landscape where tensor networks, originally developed in quantum physics, are increasingly applied to high-dimensional problems in finance [7\u201316][1]. They complement existing methods like Monte Carlo simulations and finite difference schemes by trading off statistical errors and computational cost with controlled approximation errors via bond dimensions.\n\nThe results imply that tensor networks hold great potential to become standard tools in quantitative finance for complex derivative pricing, enabling faster risk assessment and enhanced decision-making. However, the limitations\u2014such as regimes favoring traditional Monte Carlo methods and restrictions due to decoupled trees in multi-asset cases\u2014serve as essential guides for practical deployment and future methodological refinement.\n\n---\n\nIn summary, tensor network methods represent a significant methodological leap in exotic option pricing, delivering scalable and accurate algorithms. The understanding of their significance and limitations equips researchers and practitioners to effectively apply these techniques and inspire further advances at the intersection of quantum-inspired algorithms and financial engineering.\n\n---\n\n**References to the paper:**  \n- Tensor network representation and scaling: Eq. (7), page 3  \n- TTcross method and empirical performance: Fig. 2 & Fig. 3, pages 4\u20135  \n- Variational MPS approach and optimization algorithm: Eqs. (28)\u2013(37), Fig. 4, pages 5\u20137  \n- Performance comparison and volatility dependence: Fig. 5 & Fig. 6, pages 7\u20138  \n- Multi-asset decoupled trees method: Section IV B, pages 7\u20138[1]", "page_number": 10, "citations": ["https://arxiv.org/html/2505.17033v1", "https://www.ggi.infn.it/sft/SFT_2022/Banuls-TNS-Lecture_Notes_220208.pdf", "https://inspirehep.net/literature/2047116", "https://25677273.fs1.hubspotusercontent-eu1.net/hubfs/25677273/Cirdan%20Capital%20Case%20Study-Tensor%20Networks%20applied%20to%20Speeding%20up%20Exotic%20Options%20Pricing-2.pdf", "https://www.themoonlight.io/en/review/time-series-generation-for-option-pricing-on-quantum-computers-using-tensor-network"], "subsections": []}, {"id": "future-directions-and-broader-impact", "title": "Future Research and Broader Implications", "content": "## Future Research and Broader Implications\n\nThis section explores the prospective directions for extending the tensor network methods introduced in the paper, underscoring their broader impact on financial engineering and related computational fields. Understanding these future prospects is essential to appreciate the full potential of tensor network techniques beyond the current scope, and to position this work within the evolving landscape of quantitative finance and computational optimization.\n\nThe integration of tensor networks with binomial pricing methods has addressed key bottlenecks in pricing exotic options such as Asian and multi-asset American basket options by reducing computational complexity from exponential to linear scaling with respect to critical parameters like the number of time steps $N$ or number of assets $m$. Looking forward, the potential to generalize these approaches to a wider class of financial derivatives and to tackle other combinatorial optimization problems invites promising research opportunities. This broader context highlights the interdisciplinary nature of the work, bridging quantum physics, machine learning, and quantitative finance.\n\n### Core Concepts and Extensions\n\nTensor networks, and especially Matrix Product States (MPS), provide a structured way to efficiently represent high-dimensional tensors that describe financial payoffs and asset price paths (as introduced around page 3). The key innovation lies in approximating functions that depend on an exponentially large number of discrete variables (such as $N$-step asset price paths or $m$-asset baskets) using tensor factorizations with controlled bond dimension $D$. This reduces the memory and computational cost from exponential to linear in $N$ or $m$ under fixed $D$, circumventing the curse of dimensionality.\n\nFuture research can extend these tensor network parametrizations to cover a broader set of exotic options and financial derivatives that involve more complex payoff structures or additional path dependencies. For example, options with early-exercise features, barriers, or multiple interacting underlying factors can potentially be encoded in more sophisticated tensor networks such as Projected Entangled Pair States (PEPS) or Tree Tensor Networks (TTN), which have higher expressive power for complex correlation structures.\n\nImprovements in **binary MPS parametrizations**, as discussed on pages 5\u20137, are another fertile area. Current variational methods use simplified binary tensor parametrizations for option payoff indicator functions but achieving more general and expressive binary MPS representations could dramatically increase accuracy and solution tightness. Developing optimization algorithms that efficiently tune these binary MPS parameters, possibly leveraging advances in discrete optimization or quantum-inspired heuristics, will enhance practical applicability.\n\nMoreover, incorporating alternative and more realistic **asset dynamics models** beyond the standard geometric Brownian motion (Eq. (2) on page 2) will improve robustness and provide more faithful pricing under market conditions such as stochastic volatility or jump processes. Tensor networks can be adapted to these models by expanding the dimensionality of the state space and modifying transition probabilities accordingly, with the expectation that the linear scaling properties hold under suitable approximations.\n\n### Technical Implementation and Algorithmic Advances\n\nAt the technical level, the algorithms for constructing and optimizing MPS factorizations\u2014such as the Tensor-Train cross approximation (TTcross) and the variational binary MPS approach on pages 4\u20137\u2014form the backbone of current advances. These methods rely on efficient tensor contractions and sweeping optimization strategies inspired by the density matrix renormalization group (DMRG) algorithm (page 6), which update tensors locally to maximize pricing accuracy while controlling bond dimension growth.\n\nA deeper dive into implementation reveals the importance of parameter choices such as the bond dimension $D$, which trades off accuracy and computational cost, and the use of mixed-integer optimization heuristics (page 6) to maintain binary constraints in variational MPS representations. Future improvements could include more advanced decomposition algorithms that better approximate the tensors while keeping computational demands feasible, and adaptive schemes that dynamically adjust $D$ based on error estimates.\n\nThe integration of tensor network methods with existing multi-asset binomial tree decoupling techniques (pages 7\u20138) demonstrates how covariance matrix factorization (via Cholesky decomposition) transforms correlated asset price dynamics into independent trees amenable to tensor approximations. Refining these approaches by exploring alternative matrix factorizations or more sophisticated correlation models presents another path forward.\n\nPseudocode for the variational MPS optimization, inspired by DMRG, abstractly proceeds as:\n\n\`\`\`markdown\nInitialize MPS tensors {L, A_c, R} with bond dimension D\nRepeat until convergence:\n  For current tensor A_c:\n    Compute gradient \u2202K/\u2202A_c using tensor contractions\n    Update A_c to maximize cost function K with binary constraints\n    Decompose updated A_c as L_c * M, enforcing binary structure via mixed-integer optimization\n    Update tensors accordingly and move to next site c+1\n\`\`\`\n\nSuch algorithms leverage tensor network calculus for gradient evaluation and contraction, key to scaling methods to large $N$ and $m$ (see pages 5\u20137).\n\n### Significance, Novelty, and Broader Connections\n\nThe approach presented is novel in applying quantum-inspired tensor network techniques\u2014originally developed for many-body quantum physics problems\u2014to computational finance challenges, presenting a paradigm shift in how high-dimensional stochastic processes can be modeled and optimized. As shown in Figures 3, 4, and 5, tensor network methods achieve significant speed-ups and improved accuracy compared to conventional Monte Carlo sampling, especially in regimes of high volatility or large problem size, which are traditionally challenging for Monte Carlo methods.\n\nThis research opens avenues for interdisciplinary collaboration, merging techniques from quantum physics (tensor networks), advanced machine learning (tensor neural networks as in recent literature [2]), and quantitative finance. Such synergy promises to transform computational methods for pricing, hedging, and portfolio optimization. Future explorations into quantum algorithms or hybrid classical-quantum methods could further accelerate computations for complex derivatives.\n\nMoreover, the ability to frame combinatorial optimization problems with discrete constraints as tensor network factorizations extends the impact beyond finance, potentially benefiting fields such as operations research, computer science, and beyond. These connections highlight tensor networks as a universal tool for high-dimensional function approximation and optimization.\n\nIn summary, the innovations in this paper establish a robust foundation for applying tensor network methods to exotic option pricing, with promising directions to extend their applicability and improve computational efficiency. Incorporating enhanced parametrizations, richer asset models, and interdisciplinary techniques will likely usher in a new era of computational finance driven by quantum-inspired algorithms.\n\n---\n\nThis comprehensive outlook emphasizes the importance of continuing research into tensor network methods to fully exploit their potential and broaden their application spectrum within and beyond financial engineering.", "page_number": 10, "citations": ["https://arxiv.org/html/2505.17033v1", "https://arxiv.org/html/2304.09750v2", "https://inspirehep.net/literature/2047116", "https://ideas.repec.org/p/arx/papers/2505.17033.html", "https://link.aps.org/doi/10.1103/PhysRevResearch.4.013006"], "subsections": []}];
const citationsData: string[] = ["https://coursedog.freshdesk.com/en/support/solutions/articles/48001237503-requirements-json-data-structure-for-simple-requirements", "https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/intro-to-JSON/", "https://libraryjuiceacademy.com/shop/course/161-introduction-json-structured-data/", "https://developer.apple.com/documentation/applenews/json-concepts-and-article-structure", "https://monkt.com/recipies/research-paper-to-json/"];

// YouTube URL detection function
const isYouTubeUrl = (url: string): boolean => {
  return /(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)/.test(url);
};

// Extract YouTube video ID
const getYouTubeVideoId = (url: string): string | null => {
  const match = url.match(/(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)/);
  return match ? match[1] : null;
};

// Function to remove duplicate headings from markdown content
const removeDuplicateHeading = (content: string, title: string): string => {
  if (!content || !title) return content;
  
  // Create variations of the title to match against
  const titleVariations = [
    title.trim(),
    title.trim().toLowerCase(),
    title.replace(/[^a-zA-Z0-9\s]/g, '').trim(),
    title.replace(/[^a-zA-Z0-9\s]/g, '').trim().toLowerCase()
  ];
  
  // Split content into lines
  const lines = content.split('\n');
  const filteredLines = [];
  
  for (let i = 0; i < lines.length; i++) {
    const line = lines[i].trim();
    
    // Check if this line is a heading (starts with #)
    if (line.match(/^#{1,6}\s/)) {
      // Extract the heading text (remove # and whitespace)
      const headingText = line.replace(/^#{1,6}\s*/, '').trim();
      const headingTextLower = headingText.toLowerCase();
              const headingTextClean = headingText.replace(/[^a-zA-Z0-9\s]/g, '').trim();
              const headingTextCleanLower = headingTextClean.toLowerCase();
        
        // Check if this heading matches any title variation
        const isDuplicate = titleVariations.some(variation => 
          headingText === variation ||
          headingTextLower === variation ||
          headingTextClean === variation ||
          headingTextCleanLower === variation ||
          variation.includes(headingText) ||
          variation.includes(headingTextLower) ||
          headingText.includes(variation) ||
          headingTextLower.includes(variation)
        );
      
      // Skip the first heading if it's a duplicate, but keep subsequent headings
      if (isDuplicate && i < 3) {
        continue;
      }
    }
    
    filteredLines.push(lines[i]);
  }
  
  return filteredLines.join('\n');
};

// Markdown component with math support
const MarkdownContent = ({ content, title }: { content: string; title?: string }) => {
  // Remove duplicate heading if title is provided
  const processedContent = title ? removeDuplicateHeading(content, title) : content;
  
  return (
    <ReactMarkdown
      remarkPlugins={[remarkGfm, remarkMath]}
      rehypePlugins={[rehypeKatex]}
      className="prose prose-lg max-w-none text-gray-900 leading-relaxed"
      components={{
        // Custom styling for different elements
        h1: ({ children }) => <h1 className="text-3xl font-bold text-gray-900 mb-4">{children}</h1>,
        h2: ({ children }) => <h2 className="text-2xl font-semibold text-gray-900 mb-3">{children}</h2>,
        h3: ({ children }) => <h3 className="text-xl font-medium text-gray-900 mb-2">{children}</h3>,
        p: ({ children }) => <p className="text-black-900 mb-4 leading-relaxed">{children}</p>,
        ul: ({ children }) => <ul className="list-disc list-inside mb-4 text-gray-900">{children}</ul>,
        ol: ({ children }) => <ol className="list-decimal list-inside mb-4 text-gray-900">{children}</ol>,
        li: ({ children }) => <li className="mb-1">{children}</li>,
        blockquote: ({ children }) => <blockquote className="border-l-4 border-blue-500 pl-4 italic text-gray-600 mb-4">{children}</blockquote>,
        code: ({ children, className }) => {
          const isInline = !className;
          if (isInline) {
            return <code className="bg-gray-100 px-1 py-0.5 rounded text-sm font-mono text-gray-900">{children}</code>;
          }
          return <pre className="bg-black-100 p-4 rounded-lg overflow-x-auto mb-4"><code className="text-sm font-mono">{children}</code></pre>;
        },
        a: ({ children, href }) => <a href={href} className="text-blue-600 hover:text-blue-800 underline" target="_blank" rel="noopener noreferrer">{children}</a>,
      }}
    >
      {processedContent}
    </ReactMarkdown>
  );
};

export default function PaperPage() {
  const [activeContent, setActiveContent] = useState('');
  const [imagesData, setImagesData] = useState<ImageData[]>([]);
  const [imagesLoading, setImagesLoading] = useState(true);
  const [selectedImage, setSelectedImage] = useState<ImageData | null>(null);
  const [selectedPdfPage, setSelectedPdfPage] = useState<number | null>(null);
  const [youtubeModal, setYoutubeModal] = useState<{ isOpen: boolean; videoId: string | null }>({
    isOpen: false,
    videoId: null
  });
  const [mobileMenuOpen, setMobileMenuOpen] = useState(false);
  // Fetch images from API
  useEffect(() => {
    const fetchImages = async () => {
      try {
        setImagesLoading(true);
        const response = await fetch(`http://localhost:8000/api/images/${paperData.arxiv_id}`);
        if (response.ok) {
          const images = await response.json();
          setImagesData(images);
        } else {
          console.error('Failed to fetch images:', response.statusText);
          setImagesData([]);
        }
      } catch (error) {
        console.error('Error fetching images:', error);
        setImagesData([]);
      } finally {
        setImagesLoading(false);
      }
    };

    fetchImages();
  }, []);
  
  // Initialize with the first section
  useEffect(() => {
    if (sectionsData?.length > 0) {
      setActiveContent(sectionsData[0].id);
    }
  }, []);
  
  // Get current content (section or subsection)
  const getCurrentContent = () => {
    // First check if it's a main section
    const section = sectionsData?.find(section => section.id === activeContent);
    if (section) {
      return { type: 'section', content: section };
    }
    
    // Then check if it's a subsection
    for (const section of sectionsData || []) {
      const subsection = section.subsections?.find(sub => sub.id === activeContent);
      if (subsection) {
        return { type: 'subsection', content: subsection, parentSection: section };
      }
    }
    
    return null;
  };
  
  const currentContent = getCurrentContent();
  
  // Get relevant images for current content
  const getRelevantImages = (pageNumber: number | undefined): ImageData[] => {
    if (!pageNumber || !imagesData || !Array.isArray(imagesData)) return [];
    return imagesData.filter(img => img.page === pageNumber);
  };
  
  const relevantImages = getRelevantImages(currentContent?.content?.page_number);
  
  // Get citations for current content
  const getSectionCitations = (citations?: string[]): string[] => {
    if (!citations || !Array.isArray(citations)) return [];
    return citations;
  };
  
  const contentCitations = getSectionCitations(currentContent?.content?.citations);

  // Handle citation click
  const handleCitationClick = (citation: string) => {
    if (isYouTubeUrl(citation)) {
      const videoId = getYouTubeVideoId(citation);
      if (videoId) {
        setYoutubeModal({ isOpen: true, videoId });
        return;
      }
    }
    // For non-YouTube links, open in new tab
    window.open(citation, '_blank', 'noopener,noreferrer');
  };

  // Handle PDF page view - open in new tab
  const handlePdfPageView = (pageNumber: number) => {
    const pdfUrl = `https://arxiv.org/pdf/${paperData.arxiv_id}.pdf#page=${pageNumber}`;
    window.open(pdfUrl, '_blank', 'noopener,noreferrer');
  };



  return (
    <div className="min-h-screen flex flex-col bg-white">
      <style jsx global>{customStyles}</style>
      {/* Header */}
      <header className="bg-white sticky top-0 z-50">
        <div className="max-w-full mx-auto px-4">
          <div className="flex items-center justify-between h-16 lg:pl-32 md:pl-16 pl-4">
            <div className="flex items-center space-x-3">
              <Link href="/" className="flex items-center text-blue-600 hover:text-blue-700">
                <ArrowLeft className="w-6 h-6" />
              </Link>
              <h1 className="text-2xl font-bold text-gray-900 lowercase">deeprxiv</h1>
              <span className="text-lg text-gray-800 font-medium truncate max-w-md lg:max-w-2xl">
                {paperData.title}
              </span>
            </div>
            <button 
              onClick={() => setMobileMenuOpen(!mobileMenuOpen)}
              className="md:hidden p-2 text-gray-600 hover:text-gray-900"
            >
              <Menu className="w-6 h-6" />
            </button>
          </div>
        </div>
      </header>

      {/* Mobile Navigation Overlay */}
      {mobileMenuOpen && (
        <div className="fixed inset-0 bg-black bg-opacity-50 z-40 md:hidden" onClick={() => setMobileMenuOpen(false)}>
          <div className="fixed left-0 top-16 bottom-0 w-80 bg-white overflow-y-auto" onClick={(e) => e.stopPropagation()}>
            <div className="p-6">
              <nav className="space-y-1">
                {sectionsData?.map((section) => (
                  <div key={section.id} className="space-y-1">
                    <button
                      onClick={() => {
                        setActiveContent(section.id);
                        setMobileMenuOpen(false);
                      }}
                      className={`block w-full text-left px-1 py-3 rounded-md transition-colors text-sm font-medium ${
                        activeContent === section.id
                          ? 'bg-blue-50 text-blue-700'
                          : 'text-gray-900 hover:bg-gray-100'
                      }`}
                    >
                      <div className="truncate" title={section.title}>
                        {section.title}
                      </div>
                    </button>
                    
                    {section.subsections && section.subsections.length > 0 && (
                      <div className="ml-8 space-y-1">
                        {section.subsections.map((subsection) => (
                          <button
                            key={subsection.id}
                            onClick={() => {
                              setActiveContent(subsection.id);
                              setMobileMenuOpen(false);
                            }}
                            className={`block w-full text-left px-3 py-2 rounded-md text-sm transition-colors ${
                              activeContent === subsection.id
                                ? 'bg-blue-25 text-blue-600'
                                : 'text-gray-800 hover:bg-gray-50'
                            }`}
                          >
                            <div className="truncate" title={subsection.title}>
                              {subsection.title}
                            </div>
                          </button>
                        ))}
                      </div>
                    )}
                  </div>
                ))}
              </nav>
            </div>
          </div>
        </div>
      )}

      {/* Main Content */}
      <main className="flex-grow">
        <div className="max-w-full mx-auto px-4">
          <div className="flex min-h-screen">
            {/* Left Sidebar - Navigation */}
            <aside className="w-72 bg-white flex-shrink-0 fixed top-16 bottom-0 overflow-y-auto scrollbar-hide hidden md:block md:left-16 lg:left-32">
              <div className="p-6">
                <nav className="space-y-1">
              {sectionsData?.map((section) => (
                  <div key={section.id} className="space-y-1">
                    {/* Main Section */}
                <button
                      onClick={() => setActiveContent(section.id)}
                      className={`block w-full text-left px-1 py-3 rounded-md transition-colors text-sm font-medium ${
                        activeContent === section.id
                          ? 'bg-blue-50 text-blue-700'
                      : 'text-gray-900 hover:bg-gray-100'
                  }`}
                >
                      <div className="truncate" title={section.title}>
                  {section.title}
                      </div>
                    </button>
                    
                    {/* All Subsections */}
                    {section.subsections && section.subsections.length > 0 && (
                      <div className="ml-8 space-y-1">
                        {section.subsections.map((subsection) => (
                          <button
                            key={subsection.id}
                            onClick={() => setActiveContent(subsection.id)}
                            className={`block w-full text-left px-3 py-2 rounded-md text-sm transition-colors ${
                              activeContent === subsection.id
                                ? 'bg-blue-25 text-blue-600'
                                : 'text-gray-800 hover:bg-gray-50'
                            }`}
                          >
                            <div className="truncate" title={subsection.title}>
                              {subsection.title}
                            </div>
                </button>
                        ))}
                      </div>
                    )}
                  </div>
                              ))}
                </nav>
              </div>
            </aside>

            {/* Center Content Area */}
            <div className="flex-1 bg-white px-6 py-6 overflow-y-auto main-content">
              {currentContent && (
                <>
                  <h3 className="text-2xl font-semibold text-gray-900 mb-6">
                    {currentContent.content.title}
                  </h3>
                  
                  {/* Content - Proper Markdown rendering */}
                  <MarkdownContent content={currentContent.content.content} title={currentContent.content.title} />
                  
                  {/* Mobile PDF, Images, and Sources - Only visible on small screens */}
                  <div className="lg:hidden mt-8 space-y-6">
                    {/* PDF Section */}
                    <div>
                      <h4 className="text-sm font-semibold text-gray-900 mb-3 flex items-center">
                        <FileText className="w-4 h-4 mr-2" />
                        PDF Original
                      </h4>
                      {currentContent?.content?.page_number ? (
                        <div className="space-y-3">
                          <button
                            onClick={() => handlePdfPageView(currentContent.content.page_number!)}
                            className="w-full bg-blue-50 p-3 rounded-lg hover:bg-blue-100 transition-colors text-left"
                          >
                            <div className="flex items-center space-x-2">
                              <FileText className="w-4 h-4 text-blue-600" />
                              <div>
                                <p className="text-sm font-medium text-blue-700">
                                  Page {currentContent.content.page_number}
                                </p>
                                <p className="text-xs text-blue-600">
                                  Click to view full page
                                </p>
                              </div>
                            </div>
                          </button>
                        </div>
                      ) : (
                        <div className="text-center py-4">
                          <FileText className="w-8 h-8 text-gray-400 mx-auto mb-2" />
                          <p className="text-xs text-gray-500 mb-2">No page reference available</p>
                          <button
                            onClick={() => window.open(`https://arxiv.org/pdf/${paperData.arxiv_id}.pdf`, '_blank', 'noopener,noreferrer')}
                            className="px-3 py-2 bg-blue-600 text-white text-xs rounded-lg hover:bg-blue-700 transition-colors"
                          >
                            View Full PDF
                          </button>
                        </div>
                      )}
                    </div>

                    {/* Images Section */}
                    <div>
                      <h4 className="text-sm font-semibold text-gray-900 mb-3 flex items-center">
                        <ImageIcon className="w-4 h-4 mr-2" />
                        Images
                      </h4>
                      {imagesLoading ? (
                        <div className="text-center py-4">
                          <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-blue-600 mx-auto"></div>
                          <p className="text-xs text-gray-500 mt-2">Loading images...</p>
                        </div>
                      ) : relevantImages.length > 0 ? (
                        <div className="grid grid-cols-2 gap-2">
                          {relevantImages.map((image, index) => (
                            <div
                              key={image.id || index}
                              className="aspect-square bg-gray-200 rounded-lg flex items-center justify-center cursor-pointer hover:bg-gray-300 transition-colors overflow-hidden group"
                              onClick={() => setSelectedImage(image)}
                            >
                              <img
                                src={image.url || `/api/image/${image.id}`}
                                alt={`Figure ${index + 1}`}
                                className="max-w-full max-h-full object-contain p-1 group-hover:scale-105 transition-transform"
                              />
                            </div>
                          ))}
                        </div>
                      ) : (
                        <div className="text-center py-4">
                          <ImageIcon className="w-8 h-8 text-gray-400 mx-auto mb-2" />
                          <p className="text-xs text-gray-500">No images for this content</p>
                        </div>
                      )}
                    </div>

                    {/* Sources Section */}
                    <div>
                      <h4 className="text-sm font-semibold text-gray-900 mb-3 flex items-center">
                        <ExternalLink className="w-4 h-4 mr-2" />
                        Sources
                      </h4>
                      {contentCitations.length > 0 ? (
                        <div className="space-y-2">
                          {contentCitations.map((citation, index) => (
                            <div
                              key={index}
                              className="bg-gray-50 p-3 rounded-lg hover:bg-gray-100 transition-colors"
                            >
                              <div className="flex items-start space-x-2">
                                <div className="flex-1 min-w-0">
                                  <p className="text-xs font-medium text-gray-900 mb-1">
                                    Reference {index + 1}
                                  </p>
                                  <p className="text-xs text-gray-800 break-words">
                                    {citation}
                                  </p>
                                  <button
                                    onClick={() => handleCitationClick(citation)}
                                    className="inline-flex items-center text-xs text-blue-600 hover:text-blue-800 hover:underline mt-2"
                                  >
                                    {isYouTubeUrl(citation) ? (
                                      <Play className="w-3 h-3 mr-1" />
                                    ) : (
                                      <ExternalLink className="w-3 h-3 mr-1" />
                                    )}
                                    {isYouTubeUrl(citation) ? 'Watch Video' : 'View Source'}
                                  </button>
                                </div>
                              </div>
                            </div>
                          ))}
                        </div>
                      ) : (
                        <div className="text-center py-4">
                          <ExternalLink className="w-8 h-8 text-gray-400 mx-auto mb-2" />
                          <p className="text-xs text-gray-500">No citations for this content</p>
                        </div>
                      )}
                    </div>
                  </div>
                </>
              )}
            </div>

            {/* Right Sidebar - PDF, Images, and Sources */}
            <aside className="w-96 bg-white flex-shrink-0 fixed top-16 bottom-0 overflow-y-auto scrollbar-hide hidden lg:block lg:right-32">
              <div className="p-6 space-y-6">
              
              {/* PDF Section */}
              <div>
                <h4 className="text-sm font-semibold text-gray-900 mb-3 flex items-center">
                  <FileText className="w-4 h-4 mr-2" />
                  PDF Original
                </h4>
                {currentContent?.content?.page_number ? (
                  <div className="space-y-3">
                    <button
                      onClick={() => handlePdfPageView(currentContent.content.page_number!)}
                      className="w-full bg-blue-50 p-3 rounded-lg hover:bg-blue-100 transition-colors text-left"
                    >
                      <div className="flex items-center space-x-2">
                        <FileText className="w-4 h-4 text-blue-600" />
                        <div>
                          <p className="text-sm font-medium text-blue-700">
                            Page {currentContent.content.page_number}
                          </p>
                          <p className="text-xs text-blue-600">
                            Click to view full page
                          </p>
                        </div>
                      </div>
                    </button>
                    <div className="p-3 bg-gray-50 rounded-lg">
                      <p className="text-xs text-gray-600 mb-2">
                        <strong>PDF Reference:</strong>
                      </p>
                      <p className="text-xs text-gray-700">
                        This content is sourced from page {currentContent.content.page_number} of the original PDF. 
                        Click above to view the full page with figures, tables, and original formatting.
                      </p>
                    </div>
                  </div>
                ) : (
                  <div className="text-center py-4">
                    <FileText className="w-8 h-8 text-gray-400 mx-auto mb-2" />
                    <p className="text-xs text-gray-500 mb-2">No page reference available</p>
                    <button
                      onClick={() => window.open(`https://arxiv.org/pdf/${paperData.arxiv_id}.pdf`, '_blank', 'noopener,noreferrer')}
                      className="px-3 py-2 bg-blue-600 text-white text-xs rounded-lg hover:bg-blue-700 transition-colors"
                    >
                      View Full PDF
                    </button>
                  </div>
                )}
              </div>

              {/* Images Section */}
              <div>
                <h4 className="text-sm font-semibold text-gray-900 mb-3 flex items-center">
                  <ImageIcon className="w-4 h-4 mr-2" />
                  Images
                </h4>
                {imagesLoading ? (
                  <div className="text-center py-4">
                    <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-blue-600 mx-auto"></div>
                    <p className="text-xs text-gray-500 mt-2">Loading images...</p>
                  </div>
                ) : relevantImages.length > 0 ? (
                  <div className="grid grid-cols-2 gap-2">
                    {relevantImages.map((image, index) => (
                      <div
                        key={image.id || index}
                        className="aspect-square bg-gray-200 rounded-lg flex items-center justify-center cursor-pointer hover:bg-gray-300 transition-colors overflow-hidden group"
                        onClick={() => setSelectedImage(image)}
                      >
                        <img
                          src={image.url || `/api/image/${image.id}`}
                          alt={`Figure ${index + 1}`}
                          className="max-w-full max-h-full object-contain p-1 group-hover:scale-105 transition-transform"
                        />
                      </div>
                    ))}
                  </div>
                ) : (
                  <div className="text-center py-4">
                    <ImageIcon className="w-8 h-8 text-gray-400 mx-auto mb-2" />
                    <p className="text-xs text-gray-500">No images for this content</p>
                  </div>
                )}
                {relevantImages.length > 0 && (
                  <p className="text-xs text-gray-500 mt-2 text-center">
                    Click on an image to enlarge.
                  </p>
                )}
              </div>

              {/* Sources Section */}
              <div>
                <h4 className="text-sm font-semibold text-gray-900 mb-3 flex items-center">
                  <ExternalLink className="w-4 h-4 mr-2" />
                  Sources
                </h4>
                {contentCitations.length > 0 ? (
                  <div className="space-y-2">
                    {contentCitations.map((citation, index) => (
                      <div
                        key={index}
                        className="bg-gray-50 p-3 rounded-lg hover:bg-gray-100 transition-colors"
                      >
                        <div className="flex items-start space-x-2">
                          <div className="flex-1 min-w-0">
                            <p className="text-xs font-medium text-gray-900 mb-1">
                              Reference {index + 1}
                            </p>
                            <p className="text-xs text-gray-800 break-words">
                              {citation}
                            </p>
                            <button
                              onClick={() => handleCitationClick(citation)}
                              className="inline-flex items-center text-xs text-blue-600 hover:text-blue-800 hover:underline mt-2"
                            >
                              {isYouTubeUrl(citation) ? (
                                <Play className="w-3 h-3 mr-1" />
                              ) : (
                                <ExternalLink className="w-3 h-3 mr-1" />
                              )}
                              {isYouTubeUrl(citation) ? 'Watch Video' : 'View Source'}
                            </button>
                          </div>
                        </div>
                      </div>
                    ))}
                  </div>
                ) : (
                  <div className="text-center py-4">
                    <ExternalLink className="w-8 h-8 text-gray-400 mx-auto mb-2" />
                    <p className="text-xs text-gray-500">No citations for this content</p>
                  </div>
                )}
                </div>
                
              </div>
            </aside>
          </div>
        </div>
      </main>

      {/* Image Modal with Close Button */}
      {selectedImage && (
        <div 
          className="fixed inset-0 bg-black bg-opacity-75 flex items-center justify-center z-50 p-4"
          onClick={() => setSelectedImage(null)}
        >
          <div className="relative max-w-4xl max-h-full" onClick={(e) => e.stopPropagation()}>
            <button
              onClick={() => setSelectedImage(null)}
              className="absolute top-4 right-4 text-white hover:text-gray-300 z-10 bg-black bg-opacity-50 rounded-full p-2"
            >
              <X className="w-6 h-6" />
            </button>
            <img
              src={selectedImage.url || `/api/image/${selectedImage.id}`}
              alt="Enlarged figure"
              className="max-w-full max-h-full object-contain rounded-lg"
            />
          </div>
        </div>
      )}

      {/* YouTube Modal */}
      {youtubeModal.isOpen && youtubeModal.videoId && (
        <div className="fixed inset-0 bg-black bg-opacity-75 flex items-center justify-center z-50 p-4">
          <div className="relative bg-white rounded-lg max-w-4xl w-full max-h-full">
            <button
              onClick={() => setYoutubeModal({ isOpen: false, videoId: null })}
              className="absolute top-4 right-4 text-gray-600 hover:text-gray-800 z-10"
            >
              <X className="w-8 h-8" />
            </button>
            <div className="p-4">
              <iframe
                width="100%"
                height="480"
                src={`https://www.youtube.com/embed/${youtubeModal.videoId}`}
                title="YouTube video player"
                frameBorder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowFullScreen
                className="rounded-lg"
              ></iframe>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}
