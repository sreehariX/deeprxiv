'use client';

import { useState, useEffect, useRef } from 'react';
import Link from 'next/link';
import { ArrowLeft, ExternalLink, Download, ChevronRight } from 'lucide-react';

// Paper data
const paperData = {
  arxiv_id: '2505.10537',
  title: 'LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps',
  authors: 'Filippo Olimpieri, Noemi Giustini, Andrea Lacava, Salvatore Dâ€™Oro, Tommaso Melodia, Francesca Cuomo',
  abstract: 'The O-RAN architecture is transforming cellular networks by adopting Radio Access Network (RAN) softwarization and disaggregation concepts to enable data-driven monitoring and control of the network. Such management is enabled by RAN Intelligent Controllers (RICs), which facilitate near-real-time and non-real-time network control through xApps and rApps. However, they face limitations, including latency overhead in data exchange between the RAN and RIC, restricting real-time monitoring, and the inability to access user plain data due to privacy and security constraints, hindering use cases like beamforming and spectrum classification. To address these limitations, several architectural proposals have been made, including dApps, i.e., applications deployed within the RAN unit that enable real-time inference, control and Radio Frequency (RF) spectrum analysis. In this paper, we leverage the dApps concept to enable real-time RF spectrum classification with LibIQ, a novel library for RF signals that facilitates efficient spectrum monitoring and signal classification by providing functionalities to read I/Q samples as time-series, create datasets and visualize time-series data through plots and spectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to detect external RF signals, which are subsequently classified using a Convolutional Neural Network (CNN) inside the library. To achieve accurate spectrum analysis, we created an extensive dataset of time-series-based I/Q samples, representing distinct signal types captured using a custom dApp running on a 5th generation (5G) deployment over the Colosseum network emulator and an Over-The-Air (OTA) testbed. We evaluate our model by deploying LibIQ in heterogeneous scenarios with varying center frequencies, time windows, and external RF signals. In real-time analysis, the model classifies the processed I/Q samples, achieving an average accuracy of approximately 97.8% in identifying signal types across all scenarios. We pledge to release both LibIQ and the dataset created as a publicly available framework upon acceptance.',
};

// Sections data
const sectionsData = [{"id": "abstract", "title": "Abstract", "content": "Analysis of the Abstract Section:\n\nThis paper introduces LibIQ, a novel software library designed for real-time Radio Frequency (RF) spectrum classification within O-RAN disaggregated network environments, specifically leveraging dApps. The core argument is that current O-RAN RAN Intelligent Controllers (RICs) face significant limitations for real-time tasks, primarily due to high latency in data exchange with the RAN and restricted access to user-plane I/Q data. The proposed solution positions dApps within the RAN unit, close to the data source, to overcome these limitations.\n\nThe methods and techniques described involve LibIQ's functionalities for processing time-series I/Q samples. These include capabilities for reading, analyzing, visualizing, and classifying this data. The classification relies on a Convolutional Neural Network (CNN). This CNN is trained on a substantial dataset of I/Q samples representing various signal types. This dataset was compiled from data collected in both simulated environments (using the Colosseum network emulator) and over-the-air testbeds.\n\nThe primary finding presented is derived from the evaluation of the CNN model. The results indicate that the model achieves a high average classification accuracy of 97.8%. This performance was observed across diverse and heterogeneous scenarios, suggesting robustness.\n\nThe key implication of these findings is the demonstrated feasibility of conducting real-time RF spectrum analysis directly within O-RAN dApps. This approach offers a way to bypass the traditional limitations of RICs regarding latency and data access, potentially enabling new capabilities for spectrum monitoring, interference detection, and dynamic spectrum management in O-RAN networks at the RAN unit level.", "subsections": []}, {"id": "introduction", "title": "I. Introduction", "content": "== Analysis of \"I. Introduction\" Section ==\n\nThis section introduces the paper's topic by highlighting the significance of the O-RAN paradigm in transforming cellular networks through its open and modular design. It identifies critical limitations within the current O-RAN ALLIANCE standard that impede advanced real-time operations and physical layer data access. The section then proposes a solution involving dApps and a novel library, LibIQ, to overcome these challenges and enable real-time spectrum classification.\n\n=== Key Points and Arguments ===\n*   The O-RAN paradigm offers transformative potential for cellular networks due to its open and modular architecture.\n*   Two significant limitations exist in the current O-RAN ALLIANCE standard:\n    *   Insufficient support for accessing user-plane and physical-layer data (specifically I/Q samples).\n    *   Lack of support for sub-10 ms control loops necessary for real-time use cases.\n*   Access to real-time control loops and direct I/Q data is essential for use cases such as detecting anomalous signals, identifying interference, and improving dynamic spectrum management.\n*   dApps, co-located with the Central Unit (CU) and Distributed Unit (DU), are identified as a mechanism to gain access to real-time I/Q data.\n*   Processing the large volume of I/Q data in real-time within dApps presents a technical challenge.\n*   The paper introduces LibIQ as a library designed specifically to address the challenge of real-time I/Q data processing for spectrum monitoring and classification within dApps.\n*   The paper outlines the scope of the work, including LibIQ's capabilities, its integration into a dApp for real-time RFI classification using a Convolutional Neural Network (CNN), the process of creating the necessary dataset, and validating the approach experimentally.\n\n=== Methods or Techniques Described ===\n*   Leveraging the concept of dApps deployed alongside CU/DU to enable real-time data access.\n*   Development and utilization of LibIQ, a custom library for analyzing, manipulating, and labeling time-series-based I/Q samples.\n*   Real-time Radio Frequency Interference (RFI) classification using a Convolutional Neural Network (CNN) integrated within LibIQ.\n*   Dataset creation involving capturing I/Q samples from various signal types in different environments.\n*   Experimental validation performed in Software-defined Radio (SDR)-based environments: the Colosseum network emulator and an Over-The-Air (OTA) testbed.\n\n=== Important Findings or Results Highlighted ===\n*   Introduction of the LibIQ software library for I/Q sample processing and classification.\n*   Implementation of a high-performance CNN classifier for spectrum classification, achieving an average accuracy of approximately 97.8%.\n*   Realization of the first reported integration of a spectrum classification process within the dApp framework, demonstrating feasibility within real-time constraints.\n\n=== Implications of the Information ===\n*   The work directly addresses critical gaps in the current O-RAN standard concerning real-time control and access to physical layer data, paving the way for more dynamic and responsive cellular networks.\n*   Enabling real-time I/Q access and processing via dApps and LibIQ unlocks the potential for implementing advanced, low-latency use cases within the RAN, such as sophisticated interference detection, precise spectrum sharing, and potentially enhanced beamforming techniques.\n*   The proposed framework facilitates the deployment of AI/ML routines closer to the data source (CU/DU), reducing latency and potentially improving efficiency for data-driven network management.\n*   The development of LibIQ provides a practical tool for researchers and developers working on real-time spectrum analysis in O-RAN environments.\n*   The successful integration and validation within SDR testbeds demonstrate the feasibility and performance of the proposed solution in realistic scenarios.", "subsections": []}, {"id": "related-works", "title": "II. Related Works", "content": "Here is an analysis and summary of Section II, \"Related Works,\" based on the provided text:\n\nII. RELATED WORKS - Section Analysis and Summary\n\n**General Overview:**\n\nThis section serves as foundational context for the paper's contribution. It first establishes the architectural background by describing the O-RAN framework and introducing the concept of dApps as proposed solutions to current limitations. Subsequently, it reviews existing research efforts in the domain of spectrum classification, particularly focusing on methodologies employing deep learning. The section concludes by positioning the authors' proposed work within this existing landscape, highlighting its novelty and key distinctions.\n\n**1. Key Points and Arguments Presented:**\n\n*   **O-RAN Architecture:** The O-RAN paradigm is presented as a modular, disaggregated, and programmable approach for cellular networks, using RICs (RAN Intelligent Controllers) to manage CU, DU, and RU via open interfaces.\n*   **Limitations of Current O-RAN:** The existing standard lacks defined mechanisms for accessing user-plane and physical-layer data (like I/Q samples) and does not support control loops faster than 10 ms, which are essential for real-time applications.\n*   **Introduction of dApps:** dApps are introduced as a proposed concept (from O-RAN nGRG) to overcome these limitations. They are microservices co-located with CU/DU, enabling real-time exposure and processing of RAN data, including user-plane and I/Q data, which might be inaccessible to RICs due to latency or privacy concerns.\n*   **Spectrum Classification Research:** Deep learning techniques are actively being explored for spectrum sensing and signal classification, showing promise in enhancing accuracy, efficiency, and adaptability.\n*   **Authors' Position:** The authors position their work, leveraging the dApps concept to embed a CNN for real-time RF signal classification based on processed user-plane data, as the first application of the dApp framework to real-time spectrum classification within the O-RAN context.\n\n**2. Methods or Techniques Described:**\n\n*   **O-RAN Architecture:** Describes the architectural split (CU, DU, RU) and the role of RICs with xApps (near-real-time) and rApps (non-real-time).\n*   **dApps Concept:** Describes dApps as co-located microservices enabling real-time data access and processing within the RAN unit (CU/DU).\n*   **Deep Learning for Spectrum Classification:** Reviews methods used in prior works, including:\n    *   Residual CNN on power spectrum data for binary sensing [5].\n    *   CNN combined with LSTM on STFT spectrograms for wireless technology identification [6].\n    *   Hardware-efficient, low-complexity CNN architectures [7].\n    *   Transforming I/Q samples to image representations processed by object detection models (YOLOv8x) [8].\n    *   CNN-based classification using frequency-domain vs. time-domain I/Q samples [9].\n    *   U-Net with non-local block for direct I/Q processing (Spectrum Stitching) [10].\n*   **Authors' Method (Conceptual):** Describes their approach conceptually as processing frequency-domain I/Q samples directly using a CNN trained on time-series data for multinomial classification, enhanced by an Energy Peak Detector applied *before* classification.\n\n**3. Important Findings or Results:**\n\n*   **Need for Real-Time Access:** Highlights that current O-RAN RICs cannot provide the sub-10 ms access needed for real-time applications like spectrum classification, underscoring the necessity of approaches like dApps.\n*   **Previous Work Results (as reported):** Mentions results from other studies to provide context, e.g., image-based classification achieving 77.78% accuracy [8], or spectrogram-based methods reaching approximately 90% [9].\n*   **Authors' Claimed Results (as mentioned for comparison):** States that their method achieves 97.8% classification accuracy, presenting it as superior to some existing methods [8], [9] and offering better real-time adaptability compared to static spectrogram-based techniques [9].\n*   **Unique Integration:** Points out that their model is the only one discussed that has been tested within a real dApp framework interacting directly with an operating gNB, unlike others potentially relying on offline data, simulation, or substantial architectural modifications [11].\n\n**4. Implications of the Information in this Section:**\n\n*   **Enabling Real-Time RAN Control:** The limitations of current O-RAN regarding real-time data access are a significant barrier to advanced use cases. The dApp concept is presented as a crucial enabler for real-time processing and control loops directly at the RAN edge.\n*   **Advancing Spectrum Awareness:** Real-time access to I/Q samples and effective spectrum classification methods are vital for enhancing network reliability, dynamic resource management, interference detection (RFIs), and spectrum sharing in 5G and beyond.\n*   **Deep Learning Potential:** Reinforces that deep learning, particularly CNNs, is a powerful tool for analyzing complex RF signal data for classification tasks.\n*   **Importance of Data Representation and Pre-processing:** The review suggests that the choice of input features (time-domain vs. frequency-domain, raw I/Q vs. spectrograms vs. processed features) and pre-processing steps (like energy peak detection) significantly impact classification performance and efficiency.\n*   **Practical O-RAN Deployment:** The authors' emphasis on integrating their classifier within a real dApp framework suggests a path towards practical, deployable solutions for real-time spectrum management in disaggregated O-RAN architectures. This highlights the shift from theoretical exploration to practical implementation within the defined architectural constraints.", "subsections": [{"id": "related-works-o-ran-and-dapps", "title": "A. O-RAN and dApps", "content": "```\nAnalysis of Section \"A. O-RAN and dApps\":\n\nThis section provides a foundational overview of the O-RAN architecture and introduces the concept of dApps as a proposed extension to address existing limitations.\n\n1.  Key points and arguments presented:\n    *   The O-RAN paradigm is characterized by disaggregation (CU, DU, RU), a multi-vendor approach, and data-driven intelligent control facilitated by RAN Intelligent Controllers (RICs).\n    *   RICs enable near-real-time control via xApps and non-real-time control via rApps.\n    *   A significant limitation of current O-RAN standards is the lack of support for control loops requiring sub-10 ms real-time response.\n    *   Current standards also restrict direct access to low-layer data, such as I/Q samples, and face challenges accessing user-plane data due to privacy and security concerns.\n    *   These limitations hinder advanced, low-latency use cases.\n    *   The concept of dApps is introduced as a solution to overcome these limitations. dApps are defined as microservices designed to be co-located with the Central Unit (CU) and Distributed Unit (DU).\n    *   The primary purpose of dApps is to provide real-time exposure and processing of RAN data, including user-plane and physical-layer data like I/Q samples, which are not readily available to RICs.\n    *   The paper asserts that this work is the first to apply the dApp framework specifically for real-time spectrum classification within the O-RAN context.\n\n2.  Methods or techniques described:\n    *   The section describes the O-RAN architecture's control mechanism involving RICs and their associated applications (xApps for near-real-time, rApps for non-real-time).\n    *   It introduces the architectural concept of dApps as co-located microservices near the CU/DU for localized, real-time data access and processing.\n    *   While the specific method for spectrum classification itself is not detailed in this section, the section highlights the *application* of the dApp *concept* as a novel methodological approach for achieving real-time functions like spectrum classification within the O-RAN framework.\n\n3.  Important findings or results:\n    *   This section primarily lays the groundwork and presents the architectural concepts and their rationale. It does not present experimental findings or performance results in this subsection.\n    *   The key claim/result mentioned in this section is the novelty of the work: being the first to utilize the dApp framework for the specific task of real-time spectrum classification in O-RAN.\n\n4.  Implications of the information in this section:\n    *   The existing limitations in O-RAN's control loop latency and data access hinder its ability to support certain critical real-time RAN applications.\n    *   The dApp concept offers a potential architectural pathway to bypass RIC-based latency issues and privacy constraints by enabling processing directly at the data source (CU/DU).\n    *   Demonstrating real-time spectrum classification using dApps, as proposed by this work, implies that the dApp framework can enable use cases previously considered challenging or impossible under current O-RAN standards, expanding the capabilities of programmable RANs.\n    *   The introduction of dApps suggests a potential evolution or augmentation of the O-RAN architecture to support ultra-low-latency, data-intensive applications closer to the network edge.\n```"}, {"id": "related-works-spectrum-classification-with-deep-learning", "title": "B. Spectrum Classification with Deep Learning", "content": "Here is an analysis and summary of the \"B. Spectrum Classification with Deep Learning\" section:\n\n**B. Spectrum Classification with Deep Learning**\n\n**1. Key Points and Arguments:**\n\n*   This section reviews existing deep learning (DL) approaches for spectrum sensing and signal classification to provide context for the authors' proposed work.\n*   It highlights the diversity of DL techniques applied, including Convolutional Neural Networks (CNNs), combinations like CNN+LSTM, and methods adapted from computer vision (like YOLOv8x on image representations of I/Q samples).\n*   The section argues that existing methods often have limitations, such as:\n    *   Processing input formats that hinder real-time performance (e.g., static spectrograms).\n    *   Focusing on binary classification (signal vs. noise) rather than multinomial classification (identifying specific signal types).\n    *   Achieving lower accuracy compared to the authors' approach.\n    *   Lacking validation within real-time, operational O-RAN environments like a dApp interacting with a gNB.\n*   The authors position their approach as distinct and superior by directly processing frequency-domain I/Q data with a time-series-trained CNN for multinomial classification, achieving high accuracy, offering real-time adaptability, and being validated in a novel dApp context.\n\n**2. Methods or Techniques Described:**\n\n*   **Reviewed Methods:**\n    *   CNNs for binary spectrum sensing on power spectrum data [5].\n    *   CNN+LSTM models analyzing spectrograms for wireless technology identification [6].\n    *   Hardware-efficient CNN architectures [7] optimized for constrained systems.\n    *   Image-based classification using YOLOv8x applied to I/Q sample representations [8].\n    *   Studies comparing the effectiveness of time-domain vs. frequency-domain I/Q inputs for CNNs [9].\n    *   Spectrum Stitching [10], a U-Net based approach processing I/Q directly to reduce latency by avoiding spectrograms.\n    *   ChARM [11], a framework using DL for dynamic spectrum sharing in O-RAN, noted for its unclear O-RAN integration and limited signal set.\n*   **Authors' Proposed Method:**\n    *   Direct processing of frequency-domain I/Q samples.\n    *   Utilization of an Energy Peak Detector prior to classification to isolate relevant signals and reduce dimensionality.\n    *   Application of a CNN trained specifically on time-series data.\n    *   Focus on multinomial classification (identifying multiple signal types).\n    *   Integration and testing within a real dApp framework interacting with an operating gNB.\n\n**3. Important Findings or Results:**\n\n*   The authors' proposed method achieved a classification accuracy of 97.8%.\n*   This accuracy is highlighted as significantly higher than image-based methods like the YOLOv8x approach (which achieved 77.78% [8]).\n*   The approach offers superior real-time adaptability compared to methods relying on static spectrograms [9].\n*   It provides multinomial classification capabilities, contrasting with binary sensing methods [5].\n\n**4. Implications of the Information:**\n\n*   The section underscores the ongoing research effort to apply DL to spectrum analysis in wireless networks.\n*   It highlights the technical challenges related to input data format (time-domain vs. frequency-domain vs. image vs. spectrogram), computational efficiency, and real-time performance.\n*   The reported high accuracy (97.8%) suggests that directly processing frequency-domain I/Q samples with a time-series CNN is a highly effective approach for signal classification.\n*   The successful integration and testing within a real O-RAN dApp framework represents a significant step towards deploying real-time, AI-driven spectrum classification capabilities directly within the network edge, addressing limitations of traditional RIC-based approaches and paving the way for advanced use cases like dynamic spectrum sharing and interference detection in 5G and beyond networks."}]}, {"id": "system-overview", "title": "III. System Overview", "content": "Here is a detailed analysis and summary of Section III, \"System Overview\":\n\n**Analysis and Summary of Section III: System Overview**\n\nThis section provides a foundational description of LibIQ, the core software library developed in this work, and explains its integration approach within an O-RAN dApp context to achieve real-time spectrum analysis.\n\n1.  **Key points and arguments presented:**\n    *   LibIQ is a software library specifically designed for the analysis, manipulation, and labeling of time-series-based I/Q samples.\n    *   It is implemented using C++ for performance, with Python wrappers generated via SWIG to provide accessibility and ease of use.\n    *   The library follows a typical data analysis workflow structure, composed of four main components: Analyzer, Plotter, Preprocessor, and Classifier.\n    *   A key contribution is the integration of LibIQ into a dApp, enabling the classification process to operate directly within the disaggregated RAN units (CU/DU), bypassing the O-RAN RIC's latency constraints for real-time operations.\n    *   The dApp's real-time control loop feeds I/Q samples to LibIQ, which then processes, extracts features, applies a Convolutional Neural Network (CNN) for classification, and returns the predicted label to the dApp.\n    *   This dApp-based processing offers advantages by enabling local processing of user-plane data, reducing reliance on external interfaces for high-bandwidth data transfer, and enhancing efficiency and network reliability through integrated AI-driven analysis.\n\n2.  **Methods or techniques described:**\n    *   **Software Implementation:** C++ for core logic, Python wrappers using SWIG.\n    *   **Time Series Analysis:** Parsing, extraction, selection of I/Q components, Fast Fourier Transform (FFT), Power Spectral Density (PSD) calculation (within the Analyzer package).\n    *   **Data Visualization:** Generation of scatterplots (for I/Q components, magnitude, phase) and spectrograms (using windowing and FFT) (within the Plotter package).\n    *   **Data Preprocessing:** Dataset creation from binary (.bin) and CSV files, application of an Energy Peak Detector to isolate relevant signal portions and ensure frequency independence of the CNN input (within the Preprocessor package).\n    *   **Machine Learning:** Utilizing a CNN model specifically for RF signal classification based on processed time-series I/Q samples (within the Classifier class). Methods for training (`cnn_train`) and testing/prediction (`cnn_test`) are mentioned.\n    *   **System Integration:** Embedding the LibIQ processing pipeline (Energy Peak Detector, feature calculation, CNN classification) within the real-time control loop of a dApp.\n\n3.  **Important findings or results:**\n    *   This section primarily describes the *design* and *structure* of the system (LibIQ and its dApp integration) rather than presenting experimental results. It lays out the components and their roles in enabling real-time spectrum analysis. Specific performance metrics (like accuracy or latency) are not detailed within this section but are elaborated upon in later sections (e.g., Section V).\n\n4.  **Implications of the information in this section:**\n    *   The description of LibIQ's architecture and its integration strategy highlights the paper's approach to overcoming the limitations of standard O-RAN interfaces regarding real-time control and direct I/Q data access.\n    *   Implementing LibIQ with a C++/Python/SWIG combination suggests a focus on balancing high computational performance (necessary for real-time I/Q processing) with development flexibility and ease of use.\n    *   The structured design (Analyzer, Plotter, Preprocessor, Classifier) implies that LibIQ is intended as a comprehensive tool for RF signal analysis, not solely for the specific classification task presented in the paper.\n    *   The integration into a dApp is the core enabling mechanism for the paper's stated goal of *real-time* spectrum classification *within* the RAN, demonstrating a practical deployment model for low-latency AI/ML applications in O-RAN.\n    *   The inclusion of an Energy Peak Detector in the preprocessing chain implies an optimization strategy designed to make the classification both efficient and robust to variations in signal center frequency.", "subsections": [{"id": "system-overview-analyzer", "title": "A. Analyzer: Time series analysis and manipulation", "content": "Section A. Analyzer: Time series analysis and manipulation\n\nThis section introduces the Analyzer package, a core component within the LibIQ library designed for processing and analyzing I/Q sample time series data.\n\n1.  **Key points and arguments presented:**\n    The primary function of the Analyzer package is to provide a comprehensive set of tools for the initial manipulation and analysis of I/Q sample time series. It emphasizes the capability to handle raw binary data and perform fundamental operations essential for understanding the characteristics of RF signals.\n\n2.  **Methods or techniques described:**\n    The Analyzer package includes methods for:\n    *   Parsing binary data containing I/Q samples.\n    *   Extracting and selecting the real component of I/Q samples.\n    *   Extracting and selecting the imaginary component of I/Q samples.\n    *   Selecting both real and imaginary components for combined analysis.\n    *   Utilizing utility functions for frequency-domain analysis, specifically Fast Fourier Transform (FFT) calculation.\n    *   Utilizing utility functions for frequency-domain analysis, specifically Power Spectral Density (PSD) calculation.\n\n3.  **Important findings or results:**\n    This section does not present specific experimental findings or results. It describes the foundational tools provided by the Analyzer package that enable downstream analysis and classification presented in other sections of the paper.\n\n4.  **Implications of the information in this section:**\n    The capabilities provided by the Analyzer package are foundational for the entire LibIQ workflow and the paper's objective of real-time spectrum classification. By enabling the parsing of binary data and the extraction/manipulation of I/Q components, it allows researchers and applications (like dApps) to access and structure raw RF signal data. Furthermore, the inclusion of frequency-domain analysis techniques (FFT, PSD) is critical for transforming time-series data into representations suitable for identifying signal types and characteristics, directly supporting the subsequent preprocessing and classification steps described in the paper. This package establishes the necessary initial data handling pipeline."}, {"id": "system-overview-plotter", "title": "B. Plotter: Time series visualization", "content": "B. Plotter: Time series visualization\n\nThis section introduces the Plotter package within the LibIQ library, designed for the visualization of In-phase (I) and Quadrature (Q) data, which is treated as time series.\n\n1.  **Key points and arguments presented:**\n    *   The Plotter package serves the purpose of visualizing I/Q time series data.\n    *   It offers functions specifically tailored for analyzing signal distribution and spectral characteristics.\n\n2.  **Methods or techniques described:**\n    *   `scatterplot()` function: Used to generate scatterplots for analyzing data distribution. This function allows visualization of different aspects of the I/Q samples, including their individual components (I and Q), magnitude, or phase.\n    *   `spectrogram()` function: Used to generate spectrograms. The process involves dividing the I/Q time series into multiple windows of equal size, followed by applying the Fast Fourier Transform (FFT) to each window. Customization options for window size and overlap are provided, allowing users to adjust the level of detail captured in the spectrogram. Smaller windows with larger overlap highlight rapid signal variations, while larger windows with smaller overlap provide a broader view of long-term signal behavior.\n\n3.  **Important findings or results:**\n    *   This section describes the functionalities of a visualization tool and does not present specific findings or results obtained through its use.\n\n4.  **Implications of the information in this section:**\n    *   The availability of visualization tools like `scatterplot()` and `spectrogram()` is crucial for understanding the underlying I/Q data.\n    *   These tools enable developers and researchers to visually inspect the characteristics of RF signals in both the time and frequency domains.\n    *   Effective visualization supports tasks such as data debugging, feature engineering, and gaining insights into the signals being processed by other components of LibIQ (e.g., Analyzer, Preprocessor, Classifier).\n    *   Customizable spectrogram generation allows for tailored analysis based on the temporal dynamics of the signals under investigation, which is important for applications like spectrum classification."}, {"id": "system-overview-preprocessor", "title": "C. Preprocessor: Time Series Preprocessing", "content": "Section Summary: C. Preprocessor: Time Series Preprocessing\n\nThis section describes the functionalities of the Preprocessor package within the LibIQ library, focusing on preparing time series I/Q sample data for subsequent analysis and classification, particularly for the Convolutional Neural Network (CNN) model.\n\nKey Points:\n- The Preprocessor package is responsible for handling the data preprocessing phase.\n- Its primary goal is to ensure the dataset is correctly formatted and optimized for training downstream models like the CNN.\n- It provides core functions for creating datasets from raw data files in different formats.\n- It includes a crucial function for detecting and isolating RFI signals based on energy peaks.\n- This preprocessing step aims to make the CNN model's performance independent of the specific center frequency of the RFI source.\n- It also seeks to reduce the input data size, which contributes to increased efficiency and improved accuracy of the model.\n- Focusing on the informative portion of the signal after detection is stated to improve accuracy, generalization, and reduce overfitting risk.\n\nMethods/Techniques:\n- Data parsing and dataset creation: The package includes two key functions:\n    - create_dataset_from_bin(): For creating a dataset from raw binary files containing I/Q samples.\n    - create_dataset_from_csv(): For processing CSV files that contain time-series-based I/Q samples.\n- Energy Peak Detection: The energy_peak_detector() function implements an Energy Peak Detector.\n    - This technique identifies the maximum energy peak within a defined sliding window over the time series data.\n    - It then extracts a specified number of samples centered around the identified peak.\n- Dimensionality Reduction: By isolating the relevant signal portion and discarding noise or irrelevant data, the input size for the model is significantly reduced (e.g., from 1536 to 600 samples in the described experiments).\n\nIntended Outcomes/Claims (as findings are presented later):\n- The preprocessing step is designed to achieve independence of the CNN model from the RFI source's center frequency.\n- It aims to improve the efficiency of the CNN model by reducing the input data size.\n- It is intended to enhance the accuracy and generalization capability of the CNN model.\n- It is expected to reduce the risk of overfitting during CNN training by focusing on the most relevant signal features.\n\nImplications:\n- The Preprocessor is a foundational component of LibIQ, enabling the effective use of I/Q data for machine learning models.\n- The capability to create datasets from common file formats (binary, CSV) makes the library versatile for different data sources.\n- The energy peak detection technique is critical for handling spectral variations and making the classification robust to frequency shifts.\n- The dimensionality reduction achieved through peak detection is vital for enabling real-time processing in resource-constrained environments like O-RAN dApps, reducing computational load and inference latency.\n- By improving model accuracy and generalization, this preprocessing directly contributes to the overall performance and reliability of the spectrum classification system.\n- The prepared dataset serves as the basis for training and validating the CNN model, with the strategy of using different center frequencies for training and testing implying an evaluation of the detector's effectiveness in ensuring frequency independence."}, {"id": "system-overview-classifier", "title": "D. Classifier: Time Series Classification", "content": "= D. Classifier: Time Series Classification\n\nThis section introduces the `Classifier` class within the LibIQ library, which serves as the core component for applying machine learning, specifically a Convolutional Neural Network (CNN), to the task of classifying Radio Frequency (RF) signals based on their time-series I/Q samples.\n\n== 1. Key Points and Arguments\n\n*   The `Classifier` class is dedicated to handling the training and testing procedures for a CNN model used for RF signal classification.\n*   The `cnn_train()` function is responsible for training the CNN model. It takes time-series data derived from I/Q samples (including real, imaginary, magnitude, and phase components) as input.\n*   The training process allows for variation in the length of the time window applied to the I/Q samples, indicating that the model can be trained on sequences of different durations.\n*   The `cnn_test()` function enables the use of a pre-trained CNN model to predict the class label of new, unseen input time series.\n\n== 2. Methods or Techniques Described\n\n*   **Convolutional Neural Network (CNN):** The section explicitly states that a CNN model is used for the classification task.\n*   **Time Series Classification:** The approach classifies signals based on their time-ordered sequence of I/Q sample characteristics.\n*   **Training (`cnn_train()`):** Describes the process of feeding the CNN with labeled time-series data derived from I/Q samples to learn classification patterns. The real, imaginary, magnitude, and phase components are utilized as features.\n*   **Testing/Inference (`cnn_test()`):** Describes the process of using a trained CNN model to predict the class of new input time series.\n*   **Variable Time Window:** The ability to train the model using different time window lengths is noted, suggesting flexibility in capturing temporal dependencies at various scales.\n\n== 3. Important Findings or Results\n\nThis specific subsection *describes the functionality* of the `Classifier` class and its associated methods (`cnn_train()`, `cnn_test()`). It *does not present specific quantitative findings or results* obtained from training or testing the CNN model. The evaluation metrics, accuracy, latency, and loss curves are discussed in Section V (\"Results\").\n\n== 4. Implications of the Information\n\n*   This section establishes that LibIQ incorporates a dedicated machine learning component capable of performing signal classification.\n*   The use of a CNN on time-series I/Q data highlights the paper's approach to leveraging deep learning for feature extraction and classification directly from raw or minimally processed signal representations.\n*   The explicit mention of training and testing functions indicates that the library provides the necessary tools for users to train their own models or deploy pre-trained ones for the defined classification task.\n*   The capability to handle variable time windows suggests that the approach can be adapted to analyze signal characteristics that manifest over different temporal durations, potentially improving robustness and flexibility.\n*   This class is fundamental to achieving the paper's stated goal of real-time spectrum classification within an O-RAN dApp, providing the mechanism to convert processed signal data into actionable classification outputs."}, {"id": "system-overview-integration-on-dapp", "title": "E. Integration of LibIQ on dApp", "content": "Section Title: E. Integration of LibIQ on dApp\n\nAnalysis and Summary:\n\n1. Key Points and Arguments:\n- The section establishes that O-RAN's xApps and rApps, while enabling near-real-time and non-real-time control, leave a gap for truly real-time (sub-10 ms) processing, particularly for user-plane data like I/Q samples.\n- It argues that dApps, co-located with DU/CU, can bridge this real-time gap by performing direct, low-latency analysis without involving the RIC.\n- The central argument is that embedding LibIQ within the dApp's real-time control loop provides a mechanism for real-time spectrum classification using AI directly at the RAN unit.\n- This local, dApp-based processing of user-plane data is presented as advantageous for reducing latency and bandwidth usage.\n\n2. Methods or Techniques Described:\n- The described method involves integrating the LibIQ library as an embedded component within the dApp's real-time control loop.\n- I/Q samples are fed directly from the dApp measurements into the LibIQ processing pipeline.\n- Within LibIQ, the processing sequence includes applying an Energy Peak Detector to the I/Q samples, calculating relevant features from the detected peaks, and classifying these features using an internal Convolutional Neural Network (CNN).\n- The classification result (a label indicating signal type) is returned to the dApp.\n- The dApp manages the output, either forwarding it to the RIC or displaying it locally on the dApp's Graphical User Interface (GUI).\n- The overall technique relies on processing user-plane data locally at the DU/CU.\n\n3. Important Findings or Results:\n- The integration successfully facilitates real-time spectrum analysis and classification within the dApp framework.\n- It demonstrates a viable method to address the real-time processing gap for I/Q data not covered by existing xApp/rApp mechanisms.\n- The dApp-based local processing approach leads to reduced latency and lower bandwidth requirements compared to architectures requiring data transfer to external controllers.\n- The integration enhances network reliability and spectrum analysis capabilities through the combination of real-time processing and AI-driven classification at the RAN edge.\n\n4. Implications of the Information:\n- This work provides a concrete example of how dApps can enable real-time, AI-driven control and monitoring functions directly at the RAN unit, leveraging user-plane data.\n- It implies the potential for developing a new class of low-latency O-RAN applications that can react instantaneously to changes in the RF environment, such as dynamic spectrum management, interference mitigation, and advanced physical layer optimizations.\n- The local processing paradigm highlighted in this section supports the O-RAN vision of disaggregation and intelligent control by enabling sensitive and high-volume data processing at the edge, reducing reliance on backhaul capacity and central controllers for real-time tasks."}]}, {"id": "real-time-spectrum-classification", "title": "IV. Real-Time Spectrum Classification", "content": "Here is an analysis and summary of Section IV, \"Real-Time Spectrum Classification,\" based on the provided text:\n\n**IV. Real-Time Spectrum Classification**\n\nThis section details the experimental pipeline developed for achieving real-time classification of I/Q data within the O-RAN dApp framework. The pipeline encompasses two primary stages: dataset collection and preprocessing, and the data-driven classification process utilizing a Convolutional Neural Network (CNN).\n\n**1. Key Points and Arguments Presented:**\n\n*   The section argues for a comprehensive pipeline capable of managing the entire process of real-time RF signal analysis, visualization, and classification.\n*   A critical step is accessing and collecting I/Q samples in real-time using an extended dApp framework.\n*   Efficient preprocessing of the collected I/Q data is necessary to prepare it for the machine learning model.\n*   A data-driven approach, specifically using a CNN, is proposed for classifying the preprocessed I/Q samples to identify RF signal types.\n*   The pipeline is designed to integrate seamlessly within a dApp to leverage its low-latency processing capabilities directly at the RAN unit.\n\n**2. Methods or Techniques Described:**\n\n*   **Real-time I/Q Data Access:** Leveraging and extending a dApp framework [3] to periodically (approximately every 8 ms) access and collect I/Q samples directly from the 5G gNB deployment.\n*   **Dataset Collection:** Gathering I/Q samples from diverse environments (Colosseum network emulator and an Over-The-Air testbed) and scenarios (varying center frequencies, different signal types, and different time windows). The data includes complex input vectors initially containing 1,536 I/Q samples, organized by signal type and collection parameters.\n*   **Signal Generation:** Using tools like GNU Radio, siggen (uhd library), and the SCOPE framework to generate external RF signals (LTE, Jammer, No RFI, Square, Triangular, Radar) for collection.\n*   **Data Structuring:** Organizing collected data into a structured format (N, 1536\u00d7K, 4), where N is the number of time series, K is the number of I/Q samples per time window (tested values: 1, 5, 10, 15), and 4 represents the features (I, Q, magnitude, phase).\n*   **Energy Peak Detector:** A preprocessing technique applied to the I/Q samples. It identifies the maximum energy peak within a sliding window and extracts a fixed number of samples (600 in this work) centered around the peak. This reduces the input size from 1536 to 600 samples per time series.\n*   **Data-Driven Classification:** Employing a specifically designed Convolutional Neural Network (CNN) architecture (detailed in Fig. 3).\n    *   Input Layer: Receives preprocessed time series data (32, 600\u00d7K, 4).\n    *   Core Layers: Multiple Conv1D layers (64 filters), followed by Batch Normalization and ReLU activation, for feature extraction.\n    *   Pooling: Global Average Pooling to condense features.\n    *   Output Layers: A fully connected layer followed by a Softmax activation layer for multinomial classification into 6 signal classes.\n*   **Training:** The CNN is trained for 10 epochs using half of the collected dataset (17600 time series) across specified center frequencies, processing data in batches of 32.\n\n**3. Important Findings or Results (as presented or referenced in this section and Section V):**\n\n*   The Energy Peak Detector successfully reduces the input data dimensionality from 1536 to 600 samples, isolating the relevant signal portion and demonstrated to improve efficiency and accuracy (Figure 2).\n*   The dataset created is extensive, comprising approximately 35,200 time series across six signal types, two environments, and four center frequencies, enabling robust model training and evaluation.\n*   The trained CNN model, when evaluated on unseen data (different center frequencies), achieves high classification performance across varying time windows.\n*   Performance metrics (Accuracy, Precision, Recall, F1 Score) consistently exceed 97.1% across all tested time windows, with peak accuracy reaching 98.7% (Table II).\n*   The latency for a single prediction, utilizing the proposed pipeline and CNN, remains consistently below the 10 ms real-time threshold, varying between 0.90 ms and 2.23 ms depending on the time window size (Table II).\n*   Training curves show rapid convergence and alignment between training and validation accuracy/loss, indicating effective learning and absence of overfitting (Figure 4).\n*   Classification results show near-perfect accuracy with minimal misclassifications across all signal types (Figure 5).\n\n**4. Implications of the Information in this Section:**\n\n*   This section demonstrates a practical and effective methodology for performing real-time RF spectrum classification directly within the O-RAN environment, leveraging the dApp concept.\n*   It validates the feasibility of running complex AI/ML inference tasks, such as CNN-based classification, at the RAN unit (CU/DU), overcoming the latency and data access limitations of traditional RICs.\n*   The successful application of the Energy Peak Detector highlights the importance of intelligent preprocessing for optimizing real-time inference on edge devices with limited computational resources.\n*   The high classification accuracy across diverse signal types and conditions suggests the model is robust and generalizes well, which is crucial for deployment in dynamic real-world spectrum environments.\n*   Achieving classification latency well below the 10 ms threshold confirms that this pipeline can support real-time RAN control loops and low-latency use cases (e.g., interference detection, dynamic spectrum sharing) based on spectrum analysis.\n*   The work pioneers the integration of a spectrum classification process into the dApp framework, showcasing the potential of dApps for enhancing RAN awareness and control based on real-time physical layer data.", "subsections": [{"id": "real-time-spectrum-classification-dataset-collection-and-preprocessing", "title": "A. Dataset collection and preprocessing", "content": "Here is an analysis and summary of the section \"A. Dataset collection and preprocessing\":\n\n*   **Key Points:**\n    *   The dataset was collected using an extended dApp framework capable of sensing I/Q samples approximately every 8 ms.\n    *   Each sensing period yielded 1536 I/Q samples, organized into complex input vectors and stored in binary files.\n    *   Data collection occurred in two distinct environments: the Colosseum emulator and an Over-The-Air (OTA) testbed.\n    *   A 5G SA OAI gNB operating at 3.6192 GHz with 40 MHz bandwidth was used for data collection.\n    *   External signals (Sine/Radar, Triangular, Square, Uniform/Jammer, LTE) were generated using specific tools (GNU Radio, siggen, SCOPE) at various center frequencies (3.6042, 3.6142, 3.6242, 3.6342 GHz) with a 1 MHz sampling rate.\n    *   The total dataset comprises 35,200 time series.\n    *   The dataset structure is (N, 1536xK, 4), where N is the total number of time series, K is the number of samples per time series based on a time window (1, 5, 10, or 15), and the 4 features are I, Q, magnitude, and phase.\n    *   Data was collected for 6 signal types across environments and frequencies, with the exception of LTE data which was only collected in the Colosseum emulator.\n    *   An Energy Peak Detector was applied to isolate the most relevant signal portion (J=600 samples) within each time series.\n    *   The input data was reshaped after detection to (N, JxK, 4).\n    *   The dataset was split based on center frequencies: half for training the model and the other half for testing its generalization capabilities.\n\n*   **Methods/Techniques Described:**\n    *   Real-time I/Q sample collection using a dApp framework with approximately 8 ms periodicity.\n    *   Structuring of I/Q samples into complex input vectors (1536 samples per vector).\n    *   Binary file storage for collected data.\n    *   Utilizing different environments (emulator, OTA) for data diversity.\n    *   Generating controlled external interference signals using specific software tools (GNU Radio, siggen, SCOPE) at controlled frequencies and sampling rates.\n    *   Dataset organization with dimensions reflecting the number of time series, samples per series (influenced by a variable time window K), and features.\n    *   Applying an Energy Peak Detector algorithm to identify and extract the segment of the signal containing the energy peak.\n    *   Reshaping the dataset based on the detector's output size (J=600).\n    *   Stratified splitting of the dataset (specifically by center frequency) for training and testing phases to evaluate generalization.\n\n*   **Important Findings or Results:**\n    *   Collection resulted in a substantial dataset size of 35,200 time series.\n    *   The Energy Peak Detector effectively reduced the number of relevant samples per sensing period from 1536 to 600.\n    *   The preprocessing step (Energy Peak Detector) is claimed to reduce computational load and improve accuracy by focusing on the most relevant signal portion.\n\n*   **Implications of the Information:**\n    *   This section establishes the empirical foundation for the proposed real-time spectrum classification system by detailing the data collection process and characteristics.\n    *   The use of a dApp framework for data collection highlights the feasibility of accessing the necessary real-time I/Q data directly within the RAN environment, addressing a key limitation of traditional O-RAN architecture discussed in the paper.\n    *   The collection across multiple environments (emulator and OTA) and the inclusion of diverse signal types and frequencies suggest an effort to create a robust dataset representative of varied real-world conditions, crucial for training a generalizable classification model.\n    *   The design of the dataset structure, including the variable time window (K) and multiple features (I, Q, magnitude, phase), indicates considerations for exploring temporal patterns and different signal representations for classification.\n    *   The implementation of the Energy Peak Detector signifies a critical preprocessing step aimed at optimizing the input data for the classification model, implying that focusing on salient features is necessary for efficiency and performance in a real-time, resource-constrained environment like a dApp.\n    *   The strategic splitting of data by center frequency for training and testing underscores the objective of evaluating the model's ability to generalize to signals at frequencies not seen during training, a vital aspect for practical deployment."}, {"id": "real-time-spectrum-classification-data-driven-spectrum-classification", "title": "B. Data-Driven Spectrum Classification", "content": "Based on the provided initial content for the section \"B. Data-Driven Spectrum Classification\":\n\n**Analysis and Summary of Section B: Data-Driven Spectrum Classification**\n\nThis section details the Convolutional Neural Network (CNN) architecture specifically developed for spectrum classification within the LibIQ library.\n\n**1. Key Points and Arguments:**\n\n*   The primary goal of this section is to describe the machine learning model used by LibIQ for classifying RF signals based on time-series I/Q samples.\n*   The chosen approach is a tailored CNN architecture designed to process sequences of I/Q data effectively.\n*   The input to the CNN is structured to handle batches of time-series I/Q samples, including multiple features per sample point.\n*   The network is designed to output probabilities for six specific signal classes, indicating the model's task is multi-class classification.\n*   Details regarding the training process, including dataset size, batch size, number of epochs, and a strategy for splitting data based on center frequency for generalization testing, are presented.\n\n**2. Methods and Techniques Described:**\n\n*   **Convolutional Neural Network (CNN):** A deep learning architecture utilized for its ability to extract hierarchical features from structured input data. The use of 1D convolutions is appropriate for processing sequential time-series data.\n*   **1D Convolutional Layers:** Layers that apply filters across a single dimension (time in this case) to detect local patterns in the I/Q sample sequences. Three such layers with 64 filters each are stacked.\n*   **Batch Normalization:** A technique used after convolutional layers to normalize the activations, which helps stabilize and accelerate the training process.\n*   **ReLU Activation:** Rectified Linear Unit activation function, applied after batch normalization to introduce non-linearity into the model, enabling it to learn complex relationships.\n*   **Global Average Pooling:** A pooling technique that reduces the spatial dimensions of the feature maps by taking the average of each feature map across its spatial extent. This reduces the number of parameters and provides some translation invariance.\n*   **Fully Connected Layer:** A standard neural network layer connecting all inputs from the previous layer to each output neuron. It transforms the pooled features into a lower-dimensional representation suitable for classification.\n*   **Softmax Output Layer:** The final layer that converts the raw output scores from the fully connected layer into a probability distribution over the six signal classes. The unit with the highest probability is typically selected as the predicted class.\n*   **Epoch-based Training:** The training process is structured into epochs, where the entire training dataset is passed through the network multiple times (10 epochs specified).\n*   **Mini-batch Gradient Descent:** The model weights are updated iteratively using batches of data (batch size 32), which improves training efficiency and stability compared to processing the entire dataset at once.\n*   **Data Split by Center Frequency:** A specific method for splitting the dataset, where data from certain center frequencies are used for training, and others are reserved for testing. This evaluates the model's ability to generalize classification to spectral conditions not seen during training.\n\n**3. Important Findings or Results:**\n\n*   This section primarily *describes the method* (the CNN architecture and training setup) that *enables* the findings presented elsewhere in the paper (likely Section V).\n*   It defines the structure of the CNN that is expected to yield classification probabilities for 6 distinct signal classes.\n*   The design implies the ability to process time-series I/Q samples with 4 features (typically Real, Imaginary, Magnitude, Phase, as described in related sections like IV-A and IV-B, although not explicitly listed in this snippet).\n*   The training parameters (10 epochs, batch size 32, 17600 training samples) indicate the scale and duration of the learning phase for this specific model implementation.\n\n**4. Implications of the Information:**\n\n*   This section is crucial as it details the core intelligent component of LibIQ responsible for signal classification.\n*   The choice of a 1D CNN architecture suggests that the temporal structure within the I/Q sequences is considered important for classification.\n*   The specified architecture layers and hyperparameters represent design choices made to achieve effective and potentially efficient classification performance on I/Q data.\n*   The training methodology, particularly the data split strategy based on center frequency, highlights an emphasis on developing a model that can generalize well to different spectral environments, which is critical for real-time spectrum monitoring in dynamic conditions.\n*   The output layer with 6 units directly corresponds to the distinct signal types or states (e.g., specific waveforms, presence/absence of RFI) that LibIQ is designed to identify.\n*   Understanding this architecture is essential for evaluating the performance results presented later in the paper and appreciating the computational requirements and potential limitations of the classification system within the dApp framework."}]}, {"id": "results", "title": "V. Results", "content": "```plain\nSection V. Results Analysis and Summary\n\nThis section presents the empirical evaluation of the Convolutional Neural Network (CNN) model developed within the LibIQ library for real-time spectrum classification. The evaluation focuses on the model's performance across different input time window sizes (ranging from 1 to 15 input vectors) and assesses its capability to meet real-time requirements.\n\n**1. Key Points and Arguments Presented:**\n\n*   The primary objective is to present and analyze the performance metrics of the CNN model for classifying RF signals using I/Q samples.\n*   The evaluation considers the impact of varying the size of the input time window on model performance.\n*   The section argues that the CNN model achieves high accuracy and balanced classification performance across different window sizes.\n*   It highlights that the model's inference latency remains within the 10 ms threshold required for real-time operation, despite trade-offs related to window size.\n*   Training performance is demonstrated to be rapid and stable, without signs of overfitting.\n*   Classification robustness and minimal misclassifications are confirmed through a confusion matrix analysis.\n\n**2. Methods or Techniques Described (relevant to evaluation):**\n\n*   **Performance Metrics:** Accuracy, Precision, Recall, and F1 Score are used to evaluate classification effectiveness.\n*   **Latency Measurement:** Latency is assessed through six three-minute experiments conducted for each evaluated time window size.\n*   **Training/Validation Curves:** Accuracy and loss curves over 10 training epochs are presented to visualize the training process and check for convergence and overfitting.\n*   **Confusion Matrix Analysis:** A confusion matrix is used to visualize the distribution of predicted versus real labels and identify specific misclassifications, augmented with Z-scores.\n*   **Varying Time Window Sizes:** The impact of aggregating different numbers of input vectors (1, 5, 10, 15) for a single prediction is explicitly evaluated.\n\n**3. Important Findings or Results:**\n\n*   **Accuracy:** Consistently high, ranging from 97.1% to 98.7% (peak at 5-vector windows), with an average of 97.8%.\n*   **Precision, Recall, F1 Score:** All these metrics are also high, generally exceeding 97.1%, indicating effective and balanced classification performance across classes.\n*   **Latency:** The average latency per prediction varies from 0.90 ms (15-vector windows) to 2.23 ms (1-vector windows). Crucially, latency remains *below* the 10 ms real-time threshold for all tested window sizes.\n*   **Training Performance:** Training and validation accuracy and loss curves show rapid convergence within 10 epochs. The close alignment of training and validation curves indicates stable training and minimal overfitting.\n*   **Classification Specificity:** The confusion matrix demonstrates \"near-perfect classification accuracy,\" with very few misclassifications, supporting the robustness of the approach in distinguishing different signal types.\n\n**4. Implications of the Information in this Section:**\n\n*   The results strongly validate the effectiveness of the CNN model integrated within LibIQ for accurate RF spectrum classification using time-series I/Q samples.\n*   The high performance across standard classification metrics (Accuracy, Precision, Recall, F1) suggests that the model is reliable and provides balanced prediction capabilities across the different signal types in the dataset.\n*   Meeting the sub-10 ms latency requirement is critical and demonstrates the feasibility of deploying this classification approach in real-time O-RAN dApp environments. This confirms the potential for real-time decision-making based on spectrum analysis at the DU/CU.\n*   The trade-off analysis regarding window size and latency provides insights for system designers to select an optimal window size based on the specific application's requirements for temporal context versus prediction frequency.\n*   The rapid and stable training process implies that the model is well-suited for the dataset and architecture used, reducing concerns about convergence issues or generalization problems.\n*   The confusion matrix findings reinforce the model's robustness and its ability to correctly identify various interference signals, which is crucial for applications like RFI detection, dynamic spectrum management, and security monitoring in O-RAN.\n*   Overall, this section provides empirical evidence supporting the paper's core claim that LibIQ and its embedded CNN classifier can enable effective and real-time spectrum classification within an O-RAN dApp framework.\n```", "subsections": []}, {"id": "conclusions-and-future-work", "title": "VI. Conclusions and Future Work", "content": "Based on the provided text for Section \"VI. Conclusions and Future Work\", here is a detailed analysis and summary:\n\nThis section summarizes the key findings of the research and outlines directions for future work.\n\n**Key Points and Arguments:**\nThe paper argues that LibIQ is a high-performance library specifically designed for processing time-series I/Q samples. A central argument is that integrating LibIQ with dApps enables real-time spectrum analysis within the O-RAN architecture, which increases network awareness and facilitates potential control actions. The combined approach of a CNN classifier and an Energy Peak Detector is presented as a robust and accurate method for signal classification in this context. Future work is positioned as necessary to enhance the system's robustness, expand its analytical capabilities, and integrate it more deeply into the O-RAN control plane for automated actions.\n\n**Methods or Techniques Described:**\nThe section mentions several techniques employed and planned:\n*   **LibIQ Library:** Used for analyzing, manipulating, and labeling time-series I/Q samples.\n*   **Integration with dApps:** An architectural approach for enabling real-time processing within the RAN.\n*   **CNN Classifier:** A machine learning model utilized for classifying signal types.\n*   **Energy Peak Detector:** A preprocessing technique used in conjunction with the classifier to enhance performance.\n*   **Dataset Enhancement:** A planned method for future work to improve model robustness by including more signal types, technologies, and scenarios.\n*   **Anomaly Detection Algorithms:** Planned for future integration to enable deeper pattern analysis.\n*   **Direct Connection to RIC:** A future architectural plan to link the analysis module with the RAN Intelligent Controller for automated actions.\n\n**Important Findings or Results:**\nThe primary findings highlighted are:\n*   LibIQ is demonstrated to be a high-performance library for its intended purpose (I/Q sample processing).\n*   Integration with dApps successfully enables real-time spectrum analysis.\n*   The combination of the CNN classifier and Energy Peak Detector is robust and accurate.\n*   A specific quantitative result is reported: the system achieved an average of 97.8% classification accuracy across various scenarios, frequencies, and environments.\n\n**Implications of the Information:**\nThe information in this section has several implications:\n*   It demonstrates a viable approach to address the limitations of traditional O-RAN regarding real-time access to user-plane/physical-layer data and sub-10ms control loops by leveraging dApps and specialized libraries like LibIQ.\n*   Enabling real-time spectrum analysis at the RAN edge provides network operators with immediate awareness of spectrum usage and potential interference, which is crucial for dynamic spectrum management and interference mitigation.\n*   The high classification accuracy reported suggests that the system is effective in identifying different signal types under diverse conditions, laying a foundation for reliable spectrum monitoring.\n*   The outlined future work implies a roadmap toward a more sophisticated and autonomous RAN, where AI-driven insights from spectrum analysis can directly trigger automated corrective actions via the RIC, leading to enhanced network intelligence and adaptability.", "subsections": []}];

export default function PaperPage() {
  const [activeSection, setActiveSection] = useState(sectionsData[0]?.id);
  const [activeSubsection, setActiveSubsection] = useState(null);
  const activeSectionRef = useRef(null);
  
  // Scroll to the active section when it changes
  useEffect(() => {
    if (activeSectionRef.current) {
      activeSectionRef.current.scrollIntoView({ behavior: 'smooth', block: 'start' });
    }
  }, [activeSection, activeSubsection]);

  // Find the active section content
  const currentSection = sectionsData.find(section => section.id === activeSection);
  const currentSubsection = activeSubsection
    ? currentSection?.subsections?.find(sub => sub.id === activeSubsection)
    : null;
  
  const contentToDisplay = currentSubsection
    ? currentSubsection.content
    : currentSection?.content;

  return (
    <div className="flex flex-row min-h-screen bg-gray-100 dark:bg-gray-900">
      {/* Left sidebar with sections */}
      <div className="w-64 bg-white dark:bg-gray-800 border-r border-gray-200 dark:border-gray-700 py-6 px-4 hidden md:block overflow-y-auto">
        <Link 
          href="/" 
          className="inline-flex items-center text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 mb-6"
        >
          <ArrowLeft className="w-4 h-4 mr-1" />
          <span>Back to papers</span>
        </Link>

        <h3 className="text-sm uppercase tracking-wider text-gray-500 dark:text-gray-400 font-medium my-4">Sections</h3>
        <nav className="space-y-1">
          {sectionsData.map(section => (
            <div key={section.id} className="mb-3">
              <button
                onClick={() => {
                  setActiveSection(section.id);
                  setActiveSubsection(null);
                }}
                className={`flex w-full items-center pl-2 py-1.5 text-sm font-medium rounded-md ${
                  activeSection === section.id && !activeSubsection
                    ? 'bg-blue-50 dark:bg-blue-900/30 text-blue-700 dark:text-blue-400 font-semibold'
                    : 'text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700/50'
                }`}
              >
                {section.title}
              </button>
              
              {/* Subsections */}
              {section.subsections && section.subsections.length > 0 && (
                <div className="pl-4 mt-1 space-y-1">
                  {section.subsections.map(subsection => (
                    <button
                      key={subsection.id}
                      onClick={() => {
                        setActiveSection(section.id);
                        setActiveSubsection(subsection.id);
                      }}
                      className={`flex w-full items-center pl-2 py-1 text-xs font-medium rounded-md ${
                        activeSection === section.id && activeSubsection === subsection.id
                          ? 'bg-blue-50 dark:bg-blue-900/30 text-blue-600 dark:text-blue-400'
                          : 'text-gray-600 dark:text-gray-400 hover:bg-gray-50 dark:hover:bg-gray-700/50'
                      }`}
                    >
                      <ChevronRight className="w-3 h-3 mr-1 opacity-70" />
                      {subsection.title}
                    </button>
                  ))}
                </div>
              )}
            </div>
          ))}
        </nav>
      </div>

      {/* Main content */}
      <div className="flex-1 overflow-auto">
        {/* Paper header */}
        <div className="bg-white dark:bg-gray-800 border-b border-gray-200 dark:border-gray-700 py-6">
          <div className="max-w-4xl mx-auto px-4">
            <div className="mb-6">
              <h1 className="text-2xl sm:text-3xl font-bold leading-tight mb-4">{paperData.title}</h1>
              
              <div className="flex flex-wrap items-center gap-2 text-sm text-gray-500 dark:text-gray-400 mb-4">
                <span className="inline-flex items-center bg-blue-100 dark:bg-blue-900/40 text-blue-800 dark:text-blue-300 px-2.5 py-0.5 rounded-full">
                  arXiv ID: {paperData.arxiv_id}
                </span>
                
                <a 
                  href={`https://arxiv.org/abs/${paperData.arxiv_id}`}
                  target="_blank"
                  rel="noopener noreferrer"
                  className="inline-flex items-center text-gray-600 dark:text-gray-300 hover:text-blue-600 dark:hover:text-blue-400"
                >
                  <ExternalLink className="w-3.5 h-3.5 mr-1" />
                  <span>View on arXiv</span>
                </a>
                
                <a 
                  href={`https://arxiv.org/pdf/${paperData.arxiv_id}.pdf`}
                  target="_blank"
                  rel="noopener noreferrer"
                  className="inline-flex items-center text-gray-600 dark:text-gray-300 hover:text-blue-600 dark:hover:text-blue-400"
                >
                  <Download className="w-3.5 h-3.5 mr-1" />
                  <span>Download PDF</span>
                </a>
              </div>
            </div>
            
            {paperData.authors && (
              <div className="mb-4">
                <h2 className="text-sm uppercase tracking-wider text-gray-500 dark:text-gray-400 font-medium mb-1">Authors</h2>
                <p className="text-gray-800 dark:text-gray-200">{paperData.authors}</p>
              </div>
            )}
          </div>
        </div>
        
        {/* Section content */}
        <div className="max-w-4xl mx-auto px-4 py-8" ref={activeSectionRef}>
          <h2 className="text-2xl font-semibold text-gray-800 dark:text-gray-200 mb-3">
            {currentSubsection ? currentSubsection.title : currentSection?.title}
          </h2>
          
          <div className="prose dark:prose-invert max-w-none">
            {contentToDisplay && contentToDisplay.split('\n').map((paragraph, idx) => (
              <p key={idx} className="mb-4 text-gray-700 dark:text-gray-300">
                {paragraph}
              </p>
            ))}
          </div>
        </div>
      </div>
    </div>
  );
}
